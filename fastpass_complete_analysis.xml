This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: **/*.py, **/*.md, **/*.txt, **/*.toml, **/*.yaml, **/*.yml, **/*.json, **/*.cfg, **/*.ini
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
dev/fast_pass_specification.md
dev/fastpass_test_design.md
main.py
reports/coverage/status.json
requirements.txt
scripts/create_test_pdf.py
scripts/run_tests.py
src/__main__.py
src/app.py
src/cli.py
src/core/__init__.py
src/core/crypto_handlers/__init__.py
src/core/crypto_handlers/office_handler.py
src/core/crypto_handlers/pdf_handler.py
src/core/file_handler.py
src/core/password/__init__.py
src/core/password/password_manager.py
src/core/security.py
src/utils/__init__.py
src/utils/config.py
src/utils/logger.py
test_sample.txt
tests/conftest.py
tests/requirements.txt
tests/test_cli_basic.py
tests/test_integration_basic.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="reports/coverage/status.json">
{"note":"This file is an internal implementation detail to speed up HTML report generation. Its format can change at any time. You might be looking for the JSON report: https://coverage.rtfd.io/cmd.html#cmd-json","format":5,"version":"7.10.0","globals":"70d00d6dedb1758d867edfcdbc280cb2","files":{"z_145eef247bfb46b6___init___py":{"hash":"e6baa73cda2916dad605215f937a92e1","index":{"url":"z_145eef247bfb46b6___init___py.html","file":"src\\__init__.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":0,"n_excluded":0,"n_missing":0,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_145eef247bfb46b6___main___py":{"hash":"0c3d8823d93ca869134212cd83f9c14c","index":{"url":"z_145eef247bfb46b6___main___py.html","file":"src\\__main__.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":11,"n_excluded":0,"n_missing":0,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_145eef247bfb46b6_app_py":{"hash":"dd853bb3119261d0dacf3e9d118ffcf5","index":{"url":"z_145eef247bfb46b6_app_py.html","file":"src\\app.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":156,"n_excluded":0,"n_missing":30,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_145eef247bfb46b6_cli_py":{"hash":"c16e0623849eec95929dc554387520af","index":{"url":"z_145eef247bfb46b6_cli_py.html","file":"src\\cli.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":100,"n_excluded":0,"n_missing":19,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_ce21df766c911d41___init___py":{"hash":"051d3704038ecd6a2088ec78cf1aad98","index":{"url":"z_ce21df766c911d41___init___py.html","file":"src\\core\\__init__.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":3,"n_excluded":0,"n_missing":0,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_ae6ae744f2ec6f26___init___py":{"hash":"ea15b1d4189093958558135c2a62620d","index":{"url":"z_ae6ae744f2ec6f26___init___py.html","file":"src\\core\\crypto_handlers\\__init__.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":3,"n_excluded":0,"n_missing":0,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_ae6ae744f2ec6f26_office_handler_py":{"hash":"9f591573737d112a9c33a35a56e40d59","index":{"url":"z_ae6ae744f2ec6f26_office_handler_py.html","file":"src\\core\\crypto_handlers\\office_handler.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":58,"n_excluded":0,"n_missing":44,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_ae6ae744f2ec6f26_pdf_handler_py":{"hash":"8fd814c1bb5a62f89c5a24cdd96607c3","index":{"url":"z_ae6ae744f2ec6f26_pdf_handler_py.html","file":"src\\core\\crypto_handlers\\pdf_handler.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":66,"n_excluded":0,"n_missing":17,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_ce21df766c911d41_file_handler_py":{"hash":"13445d9435dde332817eddc65f1c5625","index":{"url":"z_ce21df766c911d41_file_handler_py.html","file":"src\\core\\file_handler.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":251,"n_excluded":0,"n_missing":45,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_9d0a8317fb892e58___init___py":{"hash":"44bbc17fbdf96f75b57bf7dc9b3a3a73","index":{"url":"z_9d0a8317fb892e58___init___py.html","file":"src\\core\\password\\__init__.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":2,"n_excluded":0,"n_missing":0,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_9d0a8317fb892e58_password_manager_py":{"hash":"9397bd392f682b82fe4d000661be3f2f","index":{"url":"z_9d0a8317fb892e58_password_manager_py.html","file":"src\\core\\password\\password_manager.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":66,"n_excluded":0,"n_missing":16,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_ce21df766c911d41_security_py":{"hash":"37f91521cae9ae955e7169e55ce78cac","index":{"url":"z_ce21df766c911d41_security_py.html","file":"src\\core\\security.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":93,"n_excluded":0,"n_missing":36,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_6156a86a215061be___init___py":{"hash":"eded7715ae0de196f3e2419702b4ed00","index":{"url":"z_6156a86a215061be___init___py.html","file":"src\\utils\\__init__.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":3,"n_excluded":0,"n_missing":0,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_6156a86a215061be_config_py":{"hash":"0739dfe6c4b5e97be098b7cbc42bd35b","index":{"url":"z_6156a86a215061be_config_py.html","file":"src\\utils\\config.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":52,"n_excluded":0,"n_missing":14,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}},"z_6156a86a215061be_logger_py":{"hash":"c1b3c1bff6fad28b82ca6a80475e6241","index":{"url":"z_6156a86a215061be_logger_py.html","file":"src\\utils\\logger.py","description":"","nums":{"precision":0,"n_files":1,"n_statements":41,"n_excluded":0,"n_missing":11,"n_branches":0,"n_partial_branches":0,"n_missing_branches":0}}}}}
</file>

<file path="scripts/run_tests.py">
#!/usr/bin/env python3
"""
FastPass Test Runner
Executes comprehensive test suite with reporting
Maps to: test_runner.py from test design document
"""

import subprocess
import sys
import time
from pathlib import Path


def run_test_suite():
    """Run complete test suite with coverage reporting"""
    
    print("Starting FastPass Comprehensive Test Suite")
    print("=" * 60)
    
    start_time = time.time()
    
    # Test execution phases
    test_phases = [
        ("CLI Basic Tests", "tests/test_cli_basic.py"),
        ("Integration Tests", "tests/test_integration_basic.py"),
    ]
    
    total_results = {
        "passed": 0,
        "failed": 0,
        "skipped": 0
    }
    
    for phase_name, test_path in test_phases:
        print(f"\nRunning {phase_name}")
        print("-" * 40)
        
        cmd = [
            "uv", "run", "python", "-m", "pytest",
            test_path,
            "-v",
            "--tb=short", 
            "--cov=src",
            "--cov-report=term-missing"
        ]
        
        try:
            result = subprocess.run(cmd, cwd=Path(__file__).parent.parent)
            
            if result.returncode == 0:
                print(f"SUCCESS: {phase_name} PASSED")
                total_results["passed"] += 1
            else:
                print(f"FAILED: {phase_name} FAILED")
                total_results["failed"] += 1
                
        except Exception as e:
            print(f"ERROR: {phase_name} ERROR: {e}")
            total_results["failed"] += 1
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"\nTest Suite Complete")
    print(f"Total Duration: {duration:.2f} seconds")
    print(f"Results: {total_results['passed']} passed, {total_results['failed']} failed, {total_results['skipped']} skipped")
    
    # Return exit code
    return 0 if total_results["failed"] == 0 else 1


def run_all_tests():
    """Run all tests with coverage"""
    print("Running All FastPass Tests")
    print("=" * 50)
    
    cmd = [
        "uv", "run", "python", "-m", "pytest",
        "tests/",
        "-v",
        "--cov=src",
        "--cov-report=term-missing",
        "--cov-report=html:reports/coverage/"
    ]
    
    try:
        # Ensure reports directory exists
        reports_dir = Path(__file__).parent.parent / "reports"
        reports_dir.mkdir(exist_ok=True)
        
        result = subprocess.run(cmd, cwd=Path(__file__).parent.parent)
        
        if result.returncode == 0:
            print("\nSUCCESS: All tests passed!")
            print("Coverage report: reports/coverage/index.html")
        else:
            print("\nFAILED: Some tests failed!")
        
        return result.returncode
        
    except Exception as e:
        print(f"ERROR: Error running tests: {e}")
        return 1


def demo_functionality():
    """Demonstrate FastPass functionality"""
    print("FastPass Functionality Demo")
    print("=" * 40)
    
    base_dir = Path(__file__).parent.parent
    
    # Demo commands
    demos = [
        ("Show supported formats", ["--list-supported"]),
        ("Show version", ["--version"]),
        ("Show help", ["--help"]),
    ]
    
    for demo_name, args in demos:
        print(f"\n{demo_name}:")
        print("-" * len(demo_name))
        
        cmd = ["uv", "run", "python", "-m", "src"] + args
        
        try:
            result = subprocess.run(cmd, cwd=base_dir, capture_output=True, text=True)
            if result.stdout:
                print(result.stdout)
            if result.stderr:
                print("STDERR:", result.stderr)
        except Exception as e:
            print(f"Error: {e}")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        if sys.argv[1] == "demo":
            demo_functionality()
        elif sys.argv[1] == "all":
            sys.exit(run_all_tests())
        elif sys.argv[1] == "suite":
            sys.exit(run_test_suite())
        else:
            print("Usage: python run_tests.py [demo|all|suite]")
            sys.exit(1)
    else:
        # Default: run all tests
        sys.exit(run_all_tests())
</file>

<file path="dev/fastpass_test_design.md">
# FastPass Comprehensive Test Design Document

## Overview

This document defines a comprehensive testing strategy for the FastPass CLI tool that ensures **100% coverage** of all functionality, edge cases, security features, and real-world usage scenarios. The testing approach follows enterprise-grade practices with automated unit tests, integration tests, and end-to-end tests.

**Testing Philosophy**: Test every single aspect of the program without exception. Every flowchart box, every function, every security validation, every user input scenario, and every error condition must be covered by automated tests.

---

## Test Directory Structure

```
tests/
â”œâ”€â”€ conftest.py                     # PyTest configuration and shared fixtures
â”œâ”€â”€ requirements.txt                # Test-specific dependencies
â”œâ”€â”€ pytest.ini                     # PyTest settings and markers
â”œâ”€â”€ test_runner.py                  # Main test execution script
â”œâ”€â”€ 
â”œâ”€â”€ unit/                           # Unit tests (isolated component testing)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_cli_parsing.py         # CLI argument parsing and validation
â”‚   â”œâ”€â”€ test_security_validation.py # Security hardening functions
â”‚   â”œâ”€â”€ test_file_validation.py     # File format and path validation
â”‚   â”œâ”€â”€ test_password_management.py # Password handling and memory security
â”‚   â”œâ”€â”€ test_crypto_handlers.py     # Individual crypto tool integrations
â”‚   â”œâ”€â”€ test_file_operations.py     # File processing and temporary management
â”‚   â”œâ”€â”€ test_error_handling.py      # Exception handling and recovery
â”‚   â””â”€â”€ test_utilities.py           # Helper functions and utilities
â”‚   
â”œâ”€â”€ integration/                    # Integration tests (component interaction)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_cli_to_processing.py   # Full CLI â†’ Processing pipeline
â”‚   â”œâ”€â”€ test_security_integration.py # Security validation integration
â”‚   â”œâ”€â”€ test_password_workflows.py  # Password source integration
â”‚   â”œâ”€â”€ test_file_workflows.py      # File processing workflows
â”‚   â””â”€â”€ test_error_propagation.py   # Error handling across components
â”‚   
â”œâ”€â”€ e2e/                            # End-to-end tests (full program execution)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_encrypt_operations.py  # Real encryption operations
â”‚   â”œâ”€â”€ test_decrypt_operations.py  # Real decryption operations
â”‚   â”œâ”€â”€ test_check_password.py      # Password checking operations
â”‚   â”œâ”€â”€ test_recursive_mode.py      # Recursive directory processing
â”‚   â”œâ”€â”€ test_batch_operations.py    # Multiple file processing
â”‚   â”œâ”€â”€ test_edge_cases.py          # Real-world edge cases
â”‚   â””â”€â”€ test_security_scenarios.py  # Security attack simulation
â”‚   
â”œâ”€â”€ fixtures/                       # Test data and sample files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sample_files/               # Clean test files for processing
â”‚   â”‚   â”œâ”€â”€ clean/                  # Unprotected sample files
â”‚   â”‚   â”‚   â”œâ”€â”€ sample.docx
â”‚   â”‚   â”‚   â”œâ”€â”€ sample.xlsx
â”‚   â”‚   â”‚   â”œâ”€â”€ sample.pptx
â”‚   â”‚   â”‚   â”œâ”€â”€ sample.pdf
â”‚   â”‚   â”‚   â”œâ”€â”€ empty.docx
â”‚   â”‚   â”‚   â””â”€â”€ large_file.pdf
â”‚   â”‚   â”œâ”€â”€ protected/              # Pre-encrypted sample files
â”‚   â”‚   â”‚   â”œâ”€â”€ password_123/       # Files encrypted with "123"
â”‚   â”‚   â”‚   â”œâ”€â”€ password_complex/   # Files encrypted with complex passwords
â”‚   â”‚   â”‚   â””â”€â”€ password_special/   # Files with special character passwords
â”‚   â”‚   â””â”€â”€ corrupted/              # Intentionally corrupted files
â”‚   â”‚       â”œâ”€â”€ truncated.docx
â”‚   â”‚       â”œâ”€â”€ malformed.pdf
â”‚   â”‚       â””â”€â”€ zero_bytes.xlsx
â”‚   â”œâ”€â”€ password_lists/             # Password list test files
â”‚   â”‚   â”œâ”€â”€ simple_passwords.txt
â”‚   â”‚   â”œâ”€â”€ complex_passwords.txt
â”‚   â”‚   â”œâ”€â”€ empty_passwords.txt
â”‚   â”‚   â””â”€â”€ malformed_passwords.txt
â”‚   â”œâ”€â”€ malicious/                  # Security test files
â”‚   â”‚   â”œâ”€â”€ path_traversal/         # Path traversal attack samples
â”‚   â”‚   â”œâ”€â”€ xxe_samples/            # XXE injection test files
â”‚   â”‚   â”œâ”€â”€ zip_bombs/              # ZIP bomb test files
â”‚   â”‚   â””â”€â”€ oversized/              # Oversized file attacks
â”‚   â””â”€â”€ expected_outputs/           # Expected results for validation
â”‚       â”œâ”€â”€ encryption_results/
â”‚       â”œâ”€â”€ decryption_results/
â”‚       â””â”€â”€ error_messages/
â”‚       
â”œâ”€â”€ performance/                    # Performance and stress tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_large_files.py         # Large file processing performance
â”‚   â”œâ”€â”€ test_batch_performance.py   # Batch operation performance
â”‚   â”œâ”€â”€ test_memory_usage.py        # Memory consumption validation
â”‚   â””â”€â”€ test_concurrent_operations.py # Concurrent processing tests
â”‚   
â”œâ”€â”€ security/                       # Dedicated security tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_attack_vectors.py      # All security attack simulations
â”‚   â”œâ”€â”€ test_path_traversal.py      # Path traversal attack prevention
â”‚   â”œâ”€â”€ test_command_injection.py   # Command injection prevention
â”‚   â”œâ”€â”€ test_password_security.py   # Password memory and exposure prevention
â”‚   â””â”€â”€ test_file_security.py       # File format attack prevention
â”‚   
â””â”€â”€ reports/                        # Test execution reports
    â”œâ”€â”€ coverage/                   # Code coverage reports
    â”œâ”€â”€ performance/                # Performance test results
    â””â”€â”€ security/                   # Security test results
```

---

## Unit Test Coverage Plan

### **A. CLI Argument Parsing Tests** (`test_cli_parsing.py`)

**Complete coverage of every CLI scenario from flowchart:**

```python
class TestCLIArgumentParsing:
    """Test every CLI argument combination and validation"""
    
    # A1: Basic Command Structure Tests
    def test_encrypt_mode_basic(self):
        """Test: fast_pass encrypt -i file.docx -p password"""
        
    def test_decrypt_mode_basic(self):
        """Test: fast_pass decrypt -i file.docx -p password"""
        
    def test_check_password_mode(self):
        """Test: fast_pass check-password -i file.docx -p password"""
    
    # A2: Input File Specification Tests
    def test_single_file_input(self):
        """Test: -i single_file.docx"""
        
    def test_multiple_files_input(self):
        """Test: -i file1.docx file2.pdf file3.xlsx"""
        
    def test_files_with_spaces(self):
        """Test: -i "file with spaces.docx" "another file.pdf" """
        
    def test_mixed_paths_relative_absolute(self):
        """Test: -i /abs/path/file.docx relative/file.pdf"""
        
    def test_no_input_files_error(self):
        """Test: Missing -i flag should trigger error"""
    
    # A3: Password Specification Tests  
    def test_single_password_cli(self):
        """Test: -p password123"""
        
    def test_multiple_passwords_cli(self):
        """Test: -p password1 password2 "complex pass""""
        
    def test_password_with_spaces(self):
        """Test: -p "password with spaces" """
        
    def test_password_with_special_chars(self):
        """Test: -p "p@$$w0rd!" "another&password#""""
        
    def test_password_from_file(self):
        """Test: -p @passwords.txt"""
        
    def test_password_from_stdin_tty(self):
        """Test: -p stdin with TTY input"""
        
    def test_password_from_stdin_json(self):
        """Test: -p stdin with JSON input via pipe"""
        
    def test_no_password_error(self):
        """Test: Missing -p should trigger error"""
    
    # A4: Recursive Mode Tests
    def test_recursive_decrypt_allowed(self):
        """Test: fast_pass decrypt --recursive -p password"""
        
    def test_recursive_check_password_allowed(self):
        """Test: fast_pass check-password --recursive -p password"""
        
    def test_recursive_encrypt_blocked(self):
        """Test: fast_pass encrypt --recursive should trigger security error"""
    
    # A5: Security Flag Tests
    def test_allow_cwd_flag(self):
        """Test: --allow-cwd flag enables current directory processing"""
        
    def test_cwd_blocked_without_flag(self):
        """Test: CWD processing blocked without --allow-cwd"""
    
    # A6: Utility Flag Tests
    def test_dry_run_mode(self):
        """Test: --dry-run shows operations without execution"""
        
    def test_verify_mode(self):
        """Test: --verify enables deep verification"""
        
    def test_list_supported_formats(self):
        """Test: --list-supported shows format list and exits"""
        
    def test_debug_mode(self):
        """Test: --debug enables detailed logging"""
        
    def test_help_display(self):
        """Test: -h and --help show usage information"""
    
    # A7: Argument Validation Tests
    def test_invalid_operation_mode(self):
        """Test: Invalid operation should trigger error"""
        
    def test_conflicting_flags(self):
        """Test: Conflicting flag combinations should error"""
        
    def test_malformed_arguments(self):
        """Test: Malformed argument syntax should error"""
    
    # A8: Edge Case Argument Tests
    def test_empty_string_arguments(self):
        """Test: Empty string arguments should be handled gracefully"""
        
    def test_very_long_arguments(self):
        """Test: Extremely long arguments should be validated"""
        
    def test_unicode_arguments(self):
        """Test: Unicode in file paths and passwords"""
        
    def test_argument_injection_attempts(self):
        """Test: Command injection attempts in arguments should be blocked"""
```

### **B. Security Validation Tests** (`test_security_validation.py`)

**Test every security hardening feature:**

```python
class TestSecurityHardening:
    """Test all security validation functions"""
    
    # B1: Path Traversal Protection Tests
    def test_path_traversal_attack_prevention(self):
        """Test: ../../../etc/passwd blocked"""
        
    def test_symlink_attack_prevention(self):
        """Test: Symbolic link attacks blocked"""
        
    def test_absolute_path_containment(self):
        """Test: Paths must be within allowed directories"""
        
    def test_hidden_file_access_prevention(self):
        """Test: Hidden files (.secret) blocked"""
        
    def test_cwd_security_enforcement(self):
        """Test: CWD access requires --allow-cwd flag"""
    
    # B2: Command Injection Prevention Tests
    def test_filename_injection_prevention(self):
        """Test: file.docx; rm -rf / blocked"""
        
    def test_path_injection_prevention(self):
        """Test: Path components with shell metacharacters blocked"""
        
    def test_subprocess_safety(self):
        """Test: No shell execution with user input"""
    
    # B3: File Format Security Tests
    def test_magic_number_validation(self):
        """Test: File magic numbers validated against extensions"""
        
    def test_xxe_injection_prevention(self):
        """Test: XXE attacks in Office documents blocked"""
        
    def test_zip_bomb_detection(self):
        """Test: ZIP bomb compression ratios detected"""
        
    def test_oversized_file_rejection(self):
        """Test: Files exceeding size limits rejected"""
        
    def test_malformed_pdf_rejection(self):
        """Test: Malformed PDF attacks blocked"""
    
    # B4: Password Security Tests
    def test_password_memory_clearing(self):
        """Test: Password memory cleared after use"""
        
    def test_password_length_validation(self):
        """Test: Extremely long passwords handled securely"""
        
    def test_password_character_validation(self):
        """Test: Null bytes and control characters in passwords blocked"""
        
    def test_stdin_password_security(self):
        """Test: Stdin password input doesn't expose to process list"""
    
    # B5: File Access Security Tests
    def test_permission_validation(self):
        """Test: File permissions checked before processing"""
        
    def test_write_access_validation(self):
        """Test: Output directory write access validated"""
        
    def test_temp_file_security(self):
        """Test: Temporary files created with secure permissions (0o600)"""
        
    def test_atomic_file_operations(self):
        """Test: File operations are atomic to prevent race conditions"""
```

### **C. File Validation Tests** (`test_file_validation.py`)

**Test every file format and validation scenario:**

```python
class TestFileValidation:
    """Test all file format validation and detection"""
    
    # C1: File Format Detection Tests
    def test_docx_magic_number_detection(self):
        """Test: .docx files detected by magic number"""
        
    def test_xlsx_magic_number_detection(self):
        """Test: .xlsx files detected by magic number"""
        
    def test_pptx_magic_number_detection(self):
        """Test: .pptx files detected by magic number"""
        
    def test_pdf_magic_number_detection(self):
        """Test: .pdf files detected by magic number"""
    
    # C2: File Extension Validation Tests
    def test_supported_extension_validation(self):
        """Test: Only supported extensions (.docx, .xlsx, .pptx, .pdf) allowed"""
        
    def test_legacy_office_rejection(self):
        """Test: Legacy formats (.doc, .xls, .ppt) rejected"""
        
    def test_unsupported_format_rejection(self):
        """Test: Unsupported formats (.txt, .zip, .rar) rejected"""
    
    # C3: File Content Validation Tests
    def test_empty_file_rejection(self):
        """Test: Zero-byte files rejected"""
        
    def test_corrupted_file_detection(self):
        """Test: Corrupted files detected and rejected"""
        
    def test_file_size_limits(self):
        """Test: Files exceeding size limits rejected"""
        
    def test_truncated_file_detection(self):
        """Test: Truncated files detected"""
    
    # C4: Encryption Status Detection Tests
    def test_encrypted_office_detection(self):
        """Test: Password-protected Office documents detected"""
        
    def test_unencrypted_office_detection(self):
        """Test: Unprotected Office documents detected"""
        
    def test_encrypted_pdf_detection(self):
        """Test: Password-protected PDFs detected"""
        
    def test_unencrypted_pdf_detection(self):
        """Test: Unprotected PDFs detected"""
    
    # C5: Cross-Validation Tests
    def test_magic_vs_extension_mismatch(self):
        """Test: Magic number vs extension conflicts handled"""
        
    def test_renamed_file_detection(self):
        """Test: .pdf renamed to .docx detected correctly"""
        
    def test_forged_extension_detection(self):
        """Test: Malicious files with forged extensions detected"""
```

### **D. Password Management Tests** (`test_password_management.py`)

**Test all password handling scenarios:**

```python
class TestPasswordManagement:
    """Test password handling and security"""
    
    # D1: Password Source Tests
    def test_cli_password_parsing(self):
        """Test: CLI passwords parsed correctly"""
        
    def test_password_file_loading(self):
        """Test: Password list file loading"""
        
    def test_stdin_json_password_parsing(self):
        """Test: JSON password input via stdin"""
        
    def test_stdin_tty_password_input(self):
        """Test: Interactive password input"""
    
    # D2: Password List File Tests
    def test_password_file_format_validation(self):
        """Test: Password file format requirements"""
        
    def test_empty_password_file_handling(self):
        """Test: Empty password files handled gracefully"""
        
    def test_malformed_password_file_handling(self):
        """Test: Malformed password files trigger appropriate errors"""
        
    def test_password_file_encoding_support(self):
        """Test: UTF-8 encoded password files supported"""
    
    # D3: Password Security Tests
    def test_password_memory_management(self):
        """Test: Passwords cleared from memory after use"""
        
    def test_password_logging_prevention(self):
        """Test: Passwords never appear in logs"""
        
    def test_password_process_list_prevention(self):
        """Test: Passwords don't appear in process list"""
        
    def test_secure_password_comparison(self):
        """Test: Password comparison uses secure methods"""
    
    # D4: Password Validation Tests
    def test_password_attempt_with_files(self):
        """Test: Passwords attempted against files in correct order"""
        
    def test_working_password_identification(self):
        """Test: Working password identified and cached"""
        
    def test_failed_password_handling(self):
        """Test: Failed passwords handled gracefully"""
        
    def test_password_exhaustion_handling(self):
        """Test: Behavior when all passwords fail"""
```

### **E. Crypto Handler Tests** (`test_crypto_handlers.py`)

**Test each crypto tool integration:**

```python
class TestCryptoHandlers:
    """Test crypto tool integrations"""
    
    # E1: Office Handler Tests
    def test_office_encryption_success(self):
        """Test: Office document encryption with msoffcrypto-tool"""
        
    def test_office_decryption_success(self):
        """Test: Office document decryption with msoffcrypto-tool"""
        
    def test_office_password_check(self):
        """Test: Office document password verification"""
        
    def test_office_wrong_password_handling(self):
        """Test: Wrong password for Office document handled"""
        
    def test_office_experimental_encryption_warning(self):
        """Test: Experimental encryption warning displayed"""
    
    # E2: PDF Handler Tests
    def test_pdf_encryption_success(self):
        """Test: PDF encryption with PyPDF2"""
        
    def test_pdf_decryption_success(self):
        """Test: PDF decryption with PyPDF2"""
        
    def test_pdf_password_check(self):
        """Test: PDF password verification"""
        
    def test_pdf_wrong_password_handling(self):
        """Test: Wrong password for PDF handled"""
        
    def test_pdf_permission_handling(self):
        """Test: PDF permission restrictions handled"""
    
    # E3: Handler Selection Tests
    def test_handler_selection_by_format(self):
        """Test: Correct handler selected based on file format"""
        
    def test_handler_availability_check(self):
        """Test: Handler availability checked before processing"""
        
    def test_missing_handler_error(self):
        """Test: Missing crypto tool triggers appropriate error"""
    
    # E4: Tool Integration Error Tests
    def test_msoffcrypto_tool_errors(self):
        """Test: msoffcrypto-tool errors handled gracefully"""
        
    def test_pypdf2_errors(self):
        """Test: PyPDF2 errors handled gracefully"""
        
    def test_tool_compatibility_validation(self):
        """Test: Tool version compatibility checked"""
```

---

## Integration Test Coverage Plan

### **F. CLI to Processing Pipeline Tests** (`test_cli_to_processing.py`)

**Test complete workflows from CLI input to final output:**

```python
class TestCLIProcessingIntegration:
    """Test full CLI â†’ Processing pipeline integration"""
    
    def test_encrypt_single_file_workflow(self):
        """Test: Complete encrypt workflow for single file"""
        
    def test_decrypt_single_file_workflow(self):
        """Test: Complete decrypt workflow for single file"""
        
    def test_check_password_workflow(self):
        """Test: Complete password check workflow"""
        
    def test_multiple_file_processing_workflow(self):
        """Test: Multiple files processed in sequence"""
        
    def test_password_list_integration_workflow(self):
        """Test: Password list file integration with processing"""
        
    def test_error_recovery_workflow(self):
        """Test: Error recovery in multi-file processing"""
```

---

## End-to-End Test Coverage Plan

### **G. Real File Operations Tests** (`test_encrypt_operations.py`, `test_decrypt_operations.py`)

**Test actual file encryption/decryption with real files:**

```python
class TestRealEncryptionOperations:
    """Test real encryption operations with actual files"""
    
    # G1: Single File Encryption Tests
    def test_encrypt_docx_real_file(self):
        """Test: Encrypt real .docx file, verify result can be opened with password"""
        
    def test_encrypt_xlsx_real_file(self):
        """Test: Encrypt real .xlsx file, verify result can be opened with password"""
        
    def test_encrypt_pptx_real_file(self):
        """Test: Encrypt real .pptx file, verify result can be opened with password"""
        
    def test_encrypt_pdf_real_file(self):
        """Test: Encrypt real .pdf file, verify result can be opened with password"""
    
    # G2: Encryption Verification Tests
    def test_encrypted_file_requires_password(self):
        """Test: Encrypted file cannot be opened without password"""
        
    def test_encrypted_file_opens_with_correct_password(self):
        """Test: Encrypted file opens successfully with correct password"""
        
    def test_encrypted_file_rejects_wrong_password(self):
        """Test: Encrypted file rejects incorrect password"""
        
    def test_encryption_preserves_content(self):
        """Test: File content identical after encryptâ†’decrypt cycle"""
    
    # G3: Batch Encryption Tests
    def test_encrypt_multiple_files_same_password(self):
        """Test: Multiple files encrypted with same password"""
        
    def test_encrypt_multiple_files_different_passwords(self):
        """Test: Multiple files encrypted with different passwords each"""
        
    def test_encrypt_mixed_formats_batch(self):
        """Test: Mixed file formats encrypted in single batch"""

class TestRealDecryptionOperations:
    """Test real decryption operations with actual encrypted files"""
    
    # G4: Single File Decryption Tests
    def test_decrypt_docx_real_file(self):
        """Test: Decrypt real encrypted .docx file"""
        
    def test_decrypt_xlsx_real_file(self):
        """Test: Decrypt real encrypted .xlsx file"""
        
    def test_decrypt_pptx_real_file(self):
        """Test: Decrypt real encrypted .pptx file"""
        
    def test_decrypt_pdf_real_file(self):
        """Test: Decrypt real encrypted .pdf file"""
    
    # G5: Decryption Verification Tests
    def test_decrypted_file_no_password_required(self):
        """Test: Decrypted file opens without password"""
        
    def test_decryption_preserves_content(self):
        """Test: Decrypted content matches original"""
        
    def test_decryption_with_wrong_password_fails(self):
        """Test: Decryption fails with wrong password"""
        
    def test_decryption_preserves_formatting(self):
        """Test: Document formatting preserved after decryption"""
    
    # G6: Password List Decryption Tests
    def test_decrypt_with_password_list(self):
        """Test: Decryption using password list file"""
        
    def test_decrypt_password_list_exhaustion(self):
        """Test: Behavior when password list exhausted"""
        
    def test_decrypt_password_list_mixed_success(self):
        """Test: Some files decrypt, others fail with password list"""
```

### **H. Complex Scenario Tests** (`test_batch_operations.py`, `test_edge_cases.py`)

**Test real-world usage scenarios:**

```python
class TestComplexRealWorldScenarios:
    """Test complex real-world usage scenarios"""
    
    # H1: Multi-File Multi-Password Scenarios
    def test_office_documents_different_passwords(self):
        """
        Test: Process 5 Office documents, each with different passwords
        - sample1.docx (password: "doc123")
        - sample2.xlsx (password: "sheet456") 
        - sample3.pptx (password: "slide789")
        - sample4.docx (password: "complex&password!")
        - sample5.pdf (password: "pdf#secure@2024")
        """
        
    def test_password_reuse_across_files(self):
        """
        Test: Multiple files using same password from CLI list
        - 3 files encrypted with "shared123"
        - 2 files encrypted with "common456"
        - CLI: -p shared123 common456
        """
        
    def test_mixed_encrypted_unencrypted_batch(self):
        """
        Test: Batch with mix of encrypted and unencrypted files
        - 2 files already encrypted
        - 3 files unencrypted
        - Different passwords for each encrypted file
        """
    
    # H2: Password List File Scenarios
    def test_password_list_priority_order(self):
        """
        Test: Password list file with 10 passwords, verify order
        - File with password #7 in list
        - Verify passwords 1-6 attempted first
        - Verify password #7 succeeds
        - Verify passwords 8-10 not attempted
        """
        
    def test_password_list_with_special_characters(self):
        """
        Test: Password list containing special characters
        - Passwords with spaces: "my password 123"
        - Passwords with symbols: "p@$$w0rd#2024!"
        - Unicode passwords: "Ð¿Ð°Ñ€Ð¾Ð»ÑŒ123"
        """
    
    # H3: File Path Edge Cases
    def test_files_with_spaces_in_names(self):
        """
        Test: Files with spaces in names and paths
        - "My Important Document.docx"
        - "Q3 Financial Report.xlsx"
        - "Project Presentation Final.pptx"
        """
        
    def test_long_file_paths(self):
        """
        Test: Very long file paths (approaching system limits)
        - Nested directory structure 10+ levels deep
        - File names with maximum allowed length
        """
        
    def test_unicode_file_names(self):
        """
        Test: Unicode characters in file names
        - Chinese characters: "æ–‡æ¡£.docx"
        - Emoji: "ðŸ“Š Report.xlsx"
        - Accented characters: "CafÃ© Menu.pdf"
        """
    
    # H4: Recursive Mode Real Tests
    def test_recursive_decrypt_directory_tree(self):
        """
        Test: Recursive decryption of directory tree
        - 3 levels deep directory structure
        - 15 encrypted files across all levels
        - Mixed file formats
        - Different passwords per directory level
        """
        
    def test_recursive_check_password_comprehensive(self):
        """
        Test: Recursive password check across directory tree
        - 20 files across multiple directories
        - 5 different passwords used
        - Mixed protected/unprotected files
        - Verify correct password identified for each file
        """
    
    # H5: Error Recovery Scenarios
    def test_partial_failure_recovery(self):
        """
        Test: Some files succeed, others fail in batch
        - 10 files in batch
        - 3 files have wrong passwords
        - 2 files are corrupted
        - 5 files process successfully
        - Verify successful files completed, failed files reported
        """
        
    def test_disk_space_exhaustion_handling(self):
        """
        Test: Behavior when disk space runs out during processing
        - Large files that fill available disk space
        - Verify graceful failure and cleanup
        """
        
    def test_permission_denied_recovery(self):
        """
        Test: Handle files with insufficient permissions
        - Read-only files
        - Files owned by other users
        - Files in protected directories
        """
```

### **I. Security Attack Simulation Tests** (`test_security_scenarios.py`)

**Test actual security attack scenarios:**

```python
class TestSecurityAttackSimulation:
    """Test real security attack scenarios"""
    
    # I1: Path Traversal Attack Tests
    def test_path_traversal_attack_real(self):
        """
        Test: Real path traversal attack attempts
        - Input: -i "../../../etc/passwd"
        - Input: -i "..\\..\\Windows\\System32\\config\\SAM"
        - Verify: All attempts blocked with security errors
        """
        
    def test_symlink_attack_real(self):
        """
        Test: Real symbolic link attack
        - Create symlink pointing to /etc/passwd
        - Attempt to process via FastPass
        - Verify: Attack blocked, symlink detected
        """
    
    # I2: Command Injection Attack Tests
    def test_filename_injection_attack_real(self):
        """
        Test: Real command injection via filename
        - Input: -i "file.docx; rm -rf /tmp/*"
        - Input: -i "file.pdf && cat /etc/passwd"
        - Verify: Commands not executed, filenames sanitized
        """
        
    def test_password_injection_attack_real(self):
        """
        Test: Real command injection via password
        - Input: -p "password; cat /etc/passwd"
        - Input: -p "pass && rm file.txt"
        - Verify: Commands not executed, passwords handled safely
        """
    
    # I3: File Format Attack Tests
    def test_xxe_injection_attack_real(self):
        """
        Test: Real XXE injection attack
        - Malicious .docx with XXE payload
        - XXE attempting to read local files
        - Verify: Attack blocked, XXE entities disabled
        """
        
    def test_zip_bomb_attack_real(self):
        """
        Test: Real ZIP bomb attack
        - Office document containing ZIP bomb
        - Extremely high compression ratio
        - Verify: ZIP bomb detected and blocked
        """
        
    def test_oversized_file_attack_real(self):
        """
        Test: Real oversized file attack
        - Files exceeding configured size limits
        - Memory exhaustion attempts
        - Verify: Large files rejected before processing
        """
    
    # I4: Password Security Attack Tests
    def test_password_memory_dump_simulation(self):
        """
        Test: Simulate password memory exposure
        - Process files with passwords
        - Attempt to read password from memory dumps
        - Verify: Passwords cleared from memory
        """
        
    def test_process_list_password_exposure(self):
        """
        Test: Verify passwords don't appear in process list
        - Run FastPass with passwords
        - Check ps/tasklist output for password exposure
        - Verify: Passwords not visible in process arguments
        """
```

---

## Performance and Stress Tests

### **J. Performance Validation Tests** (`test_large_files.py`, `test_batch_performance.py`)

```python
class TestPerformanceValidation:
    """Test performance requirements and limits"""
    
    # J1: Large File Performance Tests
    def test_large_pdf_processing_performance(self):
        """
        Test: Process 100MB PDF file
        - Requirement: Complete within 30 seconds
        - Verify: Memory usage stays within reasonable limits
        """
        
    def test_large_office_document_performance(self):
        """
        Test: Process 50MB Office document
        - Requirement: Complete within 20 seconds
        - Verify: Temporary file cleanup within 5 seconds
        """
    
    # J2: Batch Processing Performance Tests
    def test_batch_processing_100_files(self):
        """
        Test: Process 100 small files in batch
        - Requirement: All files processed within 60 seconds
        - Verify: Memory usage scales linearly
        """
        
    def test_concurrent_file_processing(self):
        """
        Test: Multiple FastPass instances running simultaneously
        - Run 5 FastPass processes concurrently
        - Verify: No file corruption or interference
        """
    
    # J3: Memory Usage Tests
    def test_memory_usage_large_batches(self):
        """
        Test: Memory usage with large file batches
        - Process 50 files of 10MB each
        - Verify: Memory usage < 1GB total
        - Verify: Memory released after each file
        """
        
    def test_memory_leak_detection(self):
        """
        Test: Detect memory leaks in long-running operations
        - Process 1000 small files sequentially
        - Monitor memory usage throughout
        - Verify: No continuous memory growth
        """
```

---

## Test Execution Framework

### **Test Configuration** (`conftest.py`)

```python
"""PyTest configuration and shared fixtures"""

import pytest
import tempfile
import shutil
from pathlib import Path
import subprocess
import os

@pytest.fixture(scope="session")
def test_data_dir():
    """Fixture providing test data directory"""
    return Path(__file__).parent / "fixtures"

@pytest.fixture(scope="session") 
def sample_files_dir(test_data_dir):
    """Fixture providing sample files directory"""
    return test_data_dir / "sample_files"

@pytest.fixture
def temp_work_dir():
    """Fixture providing temporary working directory for each test"""
    temp_dir = tempfile.mkdtemp(prefix="fastpass_test_")
    yield Path(temp_dir)
    shutil.rmtree(temp_dir, ignore_errors=True)

@pytest.fixture
def fastpass_executable():
    """Fixture providing path to FastPass executable"""
    # Assuming FastPass is installed or available in PATH
    return "fast_pass"

@pytest.fixture 
def encrypted_test_files(sample_files_dir, temp_work_dir):
    """Fixture providing pre-encrypted test files"""
    # Copy sample files to temp directory and encrypt them
    encrypted_files = {}
    
    sample_file = sample_files_dir / "clean" / "sample.docx"
    encrypted_file = temp_work_dir / "sample_encrypted.docx"
    
    # Use subprocess to encrypt with known password
    subprocess.run([
        "fast_pass", "encrypt", 
        "-i", str(sample_file),
        "-p", "test123",
        "--output", str(encrypted_file)
    ], check=True)
    
    encrypted_files["docx"] = {
        "file": encrypted_file,
        "password": "test123"
    }
    
    return encrypted_files

@pytest.fixture
def password_list_file(temp_work_dir):
    """Fixture providing password list file"""
    password_file = temp_work_dir / "passwords.txt"
    passwords = [
        "password123",
        "secret456", 
        "complex&password!",
        "test with spaces",
        "Ð¿Ð°Ñ€Ð¾Ð»ÑŠ123"  # Unicode password
    ]
    
    with open(password_file, 'w', encoding='utf-8') as f:
        for password in passwords:
            f.write(f"{password}\n")
    
    return password_file

# Performance test markers
pytest.mark.performance = pytest.mark.mark("performance", "Performance tests")
pytest.mark.security = pytest.mark.mark("security", "Security tests")  
pytest.mark.e2e = pytest.mark.mark("e2e", "End-to-end tests")
pytest.mark.integration = pytest.mark.mark("integration", "Integration tests")
```

### **Test Execution Script** (`test_runner.py`)

```python
#!/usr/bin/env python3
"""
FastPass Test Runner
Executes comprehensive test suite with reporting
"""

import subprocess
import sys
import time
from pathlib import Path

def run_test_suite():
    """Run complete test suite with coverage reporting"""
    
    print("ðŸš€ Starting FastPass Comprehensive Test Suite")
    print("=" * 60)
    
    start_time = time.time()
    
    # Test execution order
    test_phases = [
        ("Unit Tests", "tests/unit/"),
        ("Integration Tests", "tests/integration/"), 
        ("End-to-End Tests", "tests/e2e/"),
        ("Security Tests", "tests/security/"),
        ("Performance Tests", "tests/performance/")
    ]
    
    total_results = {
        "passed": 0,
        "failed": 0,
        "skipped": 0
    }
    
    for phase_name, test_dir in test_phases:
        print(f"\nðŸ“‹ Running {phase_name}")
        print("-" * 40)
        
        cmd = [
            "python", "-m", "pytest",
            test_dir,
            "-v",
            "--tb=short", 
            "--cov=fastpass",
            "--cov-report=html:reports/coverage/",
            "--junit-xml=reports/junit.xml",
            "--html=reports/test_report.html"
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            if result.returncode == 0:
                print(f"âœ… {phase_name} PASSED")
            else:
                print(f"âŒ {phase_name} FAILED")
                print(result.stdout)
                print(result.stderr)
                
        except Exception as e:
            print(f"ðŸ’¥ {phase_name} ERROR: {e}")
    
    end_time = time.time()
    duration = end_time - start_time
    
    print(f"\nðŸ Test Suite Complete")
    print(f"â±ï¸  Total Duration: {duration:.2f} seconds")
    print(f"ðŸ“Š Coverage Report: reports/coverage/index.html")
    print(f"ðŸ“‹ Test Report: reports/test_report.html")

if __name__ == "__main__":
    run_test_suite()
```

---

## Test Data Management

### **Sample File Creation Script** (`fixtures/create_sample_files.py`)

```python
#!/usr/bin/env python3
"""
Create comprehensive sample files for testing
"""

import os
from pathlib import Path
import shutil
from docx import Document
import openpyxl
from pptx import Presentation
from reportlab.pdfgen import canvas

def create_sample_files():
    """Create all required sample files for testing"""
    
    fixtures_dir = Path(__file__).parent
    clean_dir = fixtures_dir / "sample_files" / "clean"
    clean_dir.mkdir(parents=True, exist_ok=True)
    
    # Create sample DOCX
    doc = Document()
    doc.add_heading('Test Document', 0)
    doc.add_paragraph('This is a test document for FastPass testing.')
    doc.add_paragraph('It contains multiple paragraphs for validation.')
    doc.save(clean_dir / "sample.docx")
    
    # Create sample XLSX
    wb = openpyxl.Workbook()
    ws = wb.active
    ws['A1'] = 'Test Data'
    ws['A2'] = 'Value 1'
    ws['A3'] = 'Value 2'
    wb.save(clean_dir / "sample.xlsx")
    
    # Create sample PPTX
    prs = Presentation()
    slide = prs.slides.add_slide(prs.slide_layouts[0])
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    title.text = "Test Presentation"
    subtitle.text = "FastPass Testing Sample"
    prs.save(clean_dir / "sample.pptx")
    
    # Create sample PDF
    pdf_path = clean_dir / "sample.pdf"
    c = canvas.Canvas(str(pdf_path))
    c.drawString(100, 750, "Test PDF Document")
    c.drawString(100, 730, "This is a sample PDF for FastPass testing.")
    c.save()
    
    print("âœ… Sample files created successfully")

if __name__ == "__main__":
    create_sample_files()
```

---

## Test Quality Assurance

### **Test Coverage Requirements**

- **Minimum Code Coverage**: 95% line coverage
- **Branch Coverage**: 90% branch coverage  
- **Function Coverage**: 100% function coverage
- **Security Test Coverage**: 100% of attack vectors tested

### **Test Performance Requirements**

- **Unit Tests**: All unit tests complete within 30 seconds
- **Integration Tests**: All integration tests complete within 2 minutes
- **End-to-End Tests**: All E2E tests complete within 10 minutes
- **Full Suite**: Complete test suite finishes within 15 minutes

### **Test Data Requirements**

- **Sample Files**: Representative files for each supported format
- **Encrypted Files**: Pre-encrypted files with known passwords
- **Malicious Files**: Security test files for attack simulation
- **Edge Case Files**: Files testing format limits and edge cases

### **Continuous Integration Integration**

```yaml
# .github/workflows/test.yml
name: FastPass Test Suite

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r tests/requirements.txt
    
    - name: Run test suite
      run: python tests/test_runner.py
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v1
```

---

## Summary

This comprehensive test design provides **exhaustive coverage** of the FastPass application:

**âœ… Complete Coverage**:
- Every CLI argument combination
- Every security hardening feature  
- Every file format and validation scenario
- Every password handling method
- Every crypto tool integration
- Every error condition and recovery scenario

**âœ… Real-World Testing**:
- Actual file encryption/decryption operations
- Multi-file batch processing scenarios
- Complex password list workflows
- Performance validation with large files
- Security attack simulation with real payloads

**âœ… Automated Execution**:
- Pytest framework with comprehensive fixtures
- Automated test data generation
- Performance monitoring and reporting
- Coverage analysis and reporting
- CI/CD integration ready

**âœ… Quality Assurance**:
- 95% minimum code coverage requirement
- All tests complete within 15 minutes
- Comprehensive error scenario testing
- Security attack vector validation

The test suite ensures FastPass reliability, security, and performance meet enterprise-grade standards while maintaining rapid automated execution for continuous integration.
</file>

<file path="main.py">
#!/usr/bin/env python3
"""
Main application entry point
"""

import sys
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent / "src"))

def main():
    """Main function"""
    print("Hello from your new Python project!")
    print(f"Project root: {Path(__file__).parent}")
    
    # Your application logic goes here
    pass

if __name__ == "__main__":
    main()
</file>

<file path="scripts/create_test_pdf.py">
#!/usr/bin/env python3
"""
Create a simple test PDF file for FastPass testing
"""

try:
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import letter
    import sys
    from pathlib import Path
    
    def create_test_pdf(output_path: str):
        """Create a simple test PDF"""
        c = canvas.Canvas(output_path, pagesize=letter)
        
        # Add some content
        c.drawString(100, 750, "FastPass Test Document")
        c.drawString(100, 720, "This is a test PDF for FastPass encryption/decryption testing.")
        c.drawString(100, 690, "Created for testing purposes only.")
        
        # Add a second page
        c.showPage()
        c.drawString(100, 750, "Page 2 of Test Document")
        c.drawString(100, 720, "Additional content for testing multi-page PDFs.")
        
        c.save()
        print(f"Test PDF created: {output_path}")
    
    if __name__ == "__main__":
        output_file = Path(__file__).parent.parent / "test_sample.pdf"
        create_test_pdf(str(output_file))
        
except ImportError:
    # Fallback: create a minimal PDF manually
    import sys
    from pathlib import Path
    
    def create_minimal_pdf(output_path: str):
        """Create minimal PDF without reportlab"""
        # Very basic PDF structure
        pdf_content = """%PDF-1.4
1 0 obj
<<
/Type /Catalog
/Pages 2 0 R
>>
endobj

2 0 obj
<<
/Type /Pages
/Kids [3 0 R]
/Count 1
>>
endobj

3 0 obj
<<
/Type /Page
/Parent 2 0 R
/MediaBox [0 0 612 792]
/Contents 4 0 R
>>
endobj

4 0 obj
<<
/Length 44
>>
stream
BT
/F1 12 Tf
100 700 Td
(FastPass Test PDF) Tj
ET
endstream
endobj

xref
0 5
0000000000 65535 f 
0000000009 00000 n 
0000000058 00000 n 
0000000115 00000 n 
0000000216 00000 n 
trailer
<<
/Size 5
/Root 1 0 R
>>
startxref
310
%%EOF"""
        
        with open(output_path, 'w') as f:
            f.write(pdf_content)
        print(f"Minimal test PDF created: {output_path}")
    
    if __name__ == "__main__":
        output_file = Path(__file__).parent.parent / "test_sample.pdf"
        create_minimal_pdf(str(output_file))
</file>

<file path="src/__main__.py">
#!/usr/bin/env python3
"""
FastPass - Universal File Encryption/Decryption Tool

Makes package executable with 'python -m src'
Entry point: MAIN PROGRAM ENTRY POINT
"""

# A1a: Load System Tools
import sys
import os
from pathlib import Path

# Add src directory to path for imports
src_path = Path(__file__).parent
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

def main():
    """FastPass main entry point with complete error handling"""
    from cli import main as cli_main
    return cli_main()

if __name__ == "__main__":
    # Program Startup - FastPass application begins execution
    sys.exit(main())
</file>

<file path="src/app.py">
"""
FastPass Main Application
Maps to: A5a-A5g FastPass Application Initialization and main processing flow
"""

# A1a: Load System Tools
import sys
import atexit
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List
import logging

from utils.config import FastPassConfig
from utils.logger import sanitize_error_message


class FastPassApplication:
    """
    A5a: Create FastPassApplication Class
    Main application class that orchestrates the entire FastPass workflow
    """
    
    def __init__(self, args, logger: logging.Logger, config: Dict[str, Any]):
        """
        A5b: Initialize Instance Variables
        Store command-line arguments, logger, and configuration
        """
        self.args = args
        self.logger = logger
        self.config = config
        
        # A5c: Initialize Tracking Lists
        self.temp_files_created = []
        self.processing_results = {}
        
        # A5d: Record Operation Start Time
        self.operation_start_time = datetime.now()
        
        # A5e: Initialize Password Manager
        from core.password.password_manager import PasswordManager
        self.password_manager = PasswordManager(
            cli_passwords=getattr(args, 'password', []) or [],
            password_list_file=getattr(args, 'password_list', None),
            stdin_mapping=getattr(args, 'stdin_password_mapping', None)
        )
        
        # A5f: Set Application State Flags
        self.ready_for_processing = True
        self.cleanup_required = True
        
        # A5g: Log Application Initialized
        self.logger.debug('FastPass application initialized')
        
        # Register cleanup handler
        atexit.register(self._emergency_cleanup)
    
    def run(self) -> int:
        """
        Main execution flow following the complete flowchart
        Returns exit code (0=success, 1=error, 2=invalid args, 3=security, 4=password)
        """
        try:
            # A4a-A4e: Crypto Tool Detection
            self._check_crypto_tools()
            
            # Section B: Security & File Validation
            validated_files = self._perform_security_and_file_validation()
            
            # Section C: Crypto Tool Setup & Configuration
            crypto_handlers = self._setup_crypto_tools_and_configuration(validated_files)
            
            # Section D: File Processing & Operations
            processing_results = self._process_files_with_crypto_operations(
                validated_files, crypto_handlers
            )
            
            # Section E: Cleanup & Results Reporting
            exit_code = self._cleanup_and_generate_final_report(processing_results)
            
            return exit_code
            
        except SecurityViolationError as e:
            self.logger.error(f"Security violation: {sanitize_error_message(str(e))}")
            return 3
        except FileFormatError as e:
            self.logger.error(f"File format error: {sanitize_error_message(str(e))}")
            return 1
        except CryptoToolError as e:
            self.logger.error(f"Crypto tool error: {sanitize_error_message(str(e))}")
            return 1
        except PasswordError as e:
            self.logger.error(f"Password error: {sanitize_error_message(str(e))}")
            return 4
        except ProcessingError as e:
            self.logger.error(f"Processing error: {sanitize_error_message(str(e))}")
            self._cleanup_partial_processing_on_failure()
            return 1
        except Exception as e:
            self.logger.error(f"Unexpected error: {sanitize_error_message(str(e))}")
            self._emergency_cleanup()
            return 2
    
    def _check_crypto_tools(self) -> None:
        """
        A4a-A4e: Crypto Tool Detection
        Check if all required crypto tools are available
        """
        # A4a: Load Encryption Tool Support
        crypto_tools = {}
        missing_tools = []
        
        # A4b: Check Office Document Tool
        try:
            import msoffcrypto
            crypto_tools['msoffcrypto'] = True
            self.logger.debug("Office document tool available")
        except ImportError:
            missing_tools.append('msoffcrypto-tool')
            self.logger.warning("msoffcrypto-tool not available")
        
        # A4c: Check PDF Processing Tool
        try:
            import PyPDF2
            crypto_tools['PyPDF2'] = True
            self.logger.debug("PDF processing tool available")
        except ImportError:
            missing_tools.append('PyPDF2')
            self.logger.warning("PyPDF2 not available")
        
        # A4e: Validate All Tools Present
        if missing_tools:
            raise CryptoToolError(f"Missing required tools: {missing_tools}")
        
        self.crypto_tools = crypto_tools
    
    def _perform_security_and_file_validation(self) -> List:
        """
        Section B: Security & File Validation
        Perform comprehensive security checks and file validation
        """
        from core.security import SecurityValidator
        from core.file_handler import FileValidator
        
        # B1a-B1c: Initialize and determine files to process
        security_validator = SecurityValidator(self.logger)
        file_validator = FileValidator(self.logger, self.config)
        
        # Determine input files
        if hasattr(self.args, 'input') and self.args.input:
            files_to_process = self.args.input
        elif hasattr(self.args, 'recursive') and self.args.recursive:
            files_to_process = self._collect_files_recursively(self.args.recursive)
        else:
            raise ValueError("No input files specified")
        
        validated_files = []
        
        # Process each file
        for file_path in files_to_process:
            try:
                # B1e-B2e: Security validation
                security_validator.validate_file_path(file_path)
                
                # B3a-B5c: File format and content validation
                file_manifest = file_validator.validate_file(file_path)
                
                validated_files.append(file_manifest)
                
            except (SecurityViolationError, FileFormatError) as e:
                self.logger.error(f"Validation failed for {file_path}: {e}")
                # Continue with other files
        
        if not validated_files:
            raise FileFormatError("No valid files found to process")
        
        self.logger.info(f"Validated {len(validated_files)} files for processing")
        return validated_files
    
    def _collect_files_recursively(self, directory: Path) -> List[Path]:
        """
        B1c_Recursive: Collect Files Recursively
        Walk directory tree for supported formats
        """
        files = []
        try:
            for pattern in FastPassConfig.SUPPORTED_FORMATS.keys():
                files.extend(directory.rglob(f"*{pattern}"))
        except Exception as e:
            raise FileFormatError(f"Error collecting files from {directory}: {e}")
        
        return files
    
    def _setup_crypto_tools_and_configuration(self, validated_files: List) -> Dict:
        """
        Section C: Crypto Tool Setup & Configuration
        Initialize and configure crypto handlers
        """
        from core.crypto_handlers.office_handler import OfficeDocumentHandler
        from core.crypto_handlers.pdf_handler import PDFHandler
        
        # C1a-C1d: Analyze required tools and initialize handlers
        required_tools = set(manifest.crypto_tool for manifest in validated_files)
        crypto_handlers = {}
        
        if 'msoffcrypto' in required_tools:
            crypto_handlers['msoffcrypto'] = OfficeDocumentHandler(self.logger)
        
        if 'PyPDF2' in required_tools:
            crypto_handlers['PyPDF2'] = PDFHandler(self.logger)
        
        # C2a-C2b: Configure handlers
        for handler in crypto_handlers.values():
            handler.configure(self.config)
        
        self.logger.debug(f"Initialized {len(crypto_handlers)} crypto handlers")
        return crypto_handlers
    
    def _process_files_with_crypto_operations(self, validated_files: List, crypto_handlers: Dict) -> Dict:
        """
        Section D: File Processing & Operations
        Process files with crypto operations
        """
        from core.file_handler import FileProcessor
        
        processor = FileProcessor(
            logger=self.logger,
            config=self.config,
            password_manager=self.password_manager,
            crypto_handlers=crypto_handlers,
            temp_files_created=self.temp_files_created
        )
        
        return processor.process_files(validated_files, self.args.operation, self.args.output_dir)
    
    def _cleanup_and_generate_final_report(self, processing_results: Dict) -> int:
        """
        Section E: Cleanup & Results Reporting
        Generate reports and determine exit code
        """
        from core.file_handler import ResultsReporter
        
        # E1a-E1e: Calculate processing metrics
        reporter = ResultsReporter(self.logger, self.operation_start_time)
        
        # E2a-E2f: Enhanced cleanup
        self._perform_cleanup()
        
        # E3a-E3d: Sensitive data clearing
        self._clear_sensitive_data()
        
        # E4a-E5d: Report generation and exit code determination
        return reporter.generate_report(processing_results)
    
    def _perform_cleanup(self) -> None:
        """
        E2a-E2f: Enhanced Cleanup with Retry and Secure Deletion
        Clean up temporary files and directories
        """
        for temp_file in self.temp_files_created:
            try:
                if temp_file.exists():
                    temp_file.unlink()
                    self.logger.debug(f"Cleaned up temp file: {temp_file}")
            except Exception as e:
                self.logger.warning(f"Failed to remove temp file {temp_file}: {e}")
    
    def _clear_sensitive_data(self) -> None:
        """
        E3a-E3d: Enhanced Sensitive Data Clearing
        Clear passwords and sensitive data from memory
        """
        # Clear password manager
        if hasattr(self, 'password_manager'):
            self.password_manager.clear_passwords()
            del self.password_manager
        
        # Clear CLI arguments containing passwords
        if hasattr(self.args, 'password'):
            self.args.password = None
        
        # Force garbage collection
        import gc
        gc.collect()
    
    def _cleanup_partial_processing_on_failure(self) -> None:
        """Cleanup when processing fails partway through"""
        self._perform_cleanup()
    
    def _emergency_cleanup(self) -> None:
        """Emergency cleanup for unexpected termination"""
        try:
            self._perform_cleanup()
        except Exception:
            pass  # Ignore errors during emergency cleanup


# Custom Exception Classes
class SecurityViolationError(Exception):
    """Raised when security validation fails"""
    pass

class FileFormatError(Exception):
    """Raised when file format validation fails"""
    pass

class CryptoToolError(Exception):
    """Raised when crypto tools are unavailable"""
    pass

class PasswordError(Exception):
    """Raised when password operations fail"""
    pass

class ProcessingError(Exception):
    """Raised when file processing fails"""
    pass
</file>

<file path="src/cli.py">
"""
FastPass CLI Argument Parsing and Validation
Maps to: Section A - DETAILED CLI PARSING from flowchart
"""

# A1a: Load System Tools
import argparse
import sys
import json
from pathlib import Path
from typing import List, Optional, Dict, Any

from utils.config import FastPassConfig
from utils.logger import setup_logger, sanitize_error_message


def parse_command_line_arguments() -> argparse.Namespace:
    """
    A1b: Initialize Command Reader
    Create a system to understand user commands
    Set up FastPass name and help description
    """
    parser = argparse.ArgumentParser(
        prog="fast_pass",
        description="FastPass - Universal file encryption and decryption tool",
        epilog="""
Examples:
  fast_pass encrypt -i contract.docx -p "mypassword"
  fast_pass decrypt -i file1.pdf file2.docx -p "shared_pwd"
  fast_pass decrypt -r ./encrypted_docs/ -p "main_password"
        """,
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    # A1g: Add Helper Features with Enhanced Logging  
    parser.add_argument(
        '--list-supported',
        action='store_true',
        help='List supported file formats'
    )
    
    parser.add_argument(
        '--version',
        action='version',
        version=f'FastPass {FastPassConfig.VERSION}'
    )
    
    # A1c: Define Main Operation Choice
    # User must choose either encrypt OR decrypt
    # Cannot do both operations simultaneously
    subparsers = parser.add_subparsers(dest='operation', help='Operation to perform')
    subparsers.required = False  # Allow for info commands
    
    # Encrypt operation
    encrypt_parser = subparsers.add_parser('encrypt', help='Add password protection to files')
    setup_common_arguments(encrypt_parser)
    
    # Decrypt operation  
    decrypt_parser = subparsers.add_parser('decrypt', help='Remove password protection from files')
    setup_common_arguments(decrypt_parser)
    
    # Add recursive option to decrypt and check-password only
    decrypt_parser.add_argument(
        '-r', '--recursive',
        type=Path,
        help='Process directory recursively (decrypt/check-password only)'
    )
    
    # Check password operation
    check_parser = subparsers.add_parser('check-password', help='Check if files require passwords')
    setup_common_arguments(check_parser)
    check_parser.add_argument(
        '-r', '--recursive',
        type=Path,
        help='Process directory recursively'
    )
    
    # Note: encrypt parser deliberately does not have -r option for security
    
    
    return parser.parse_args()


def setup_common_arguments(parser: argparse.ArgumentParser) -> None:
    """Setup arguments common to all operations"""
    
    # A1d: Set Up File Input Options
    # Use -i/--input flag for space-delimited files
    # Require explicit file specification with quotes for spaced paths
    parser.add_argument(
        '-i', '--input',
        nargs='+',
        type=Path,
        help='Files to process (space-delimited, quotes for spaces)'
    )
    
    # A1e: Configure Password Options with Space Delimitation
    # Accept space-delimited passwords with -p flag
    # Support password file and JSON stdin options
    parser.add_argument(
        '-p', '--password',
        nargs='+',
        help='Passwords to try (space-delimited, quotes for spaces, or "stdin" for JSON)'
    )
    
    parser.add_argument(
        '--password-list',
        type=Path,
        help='Text file with passwords to try (one per line)'
    )
    
    # A1f: Set Output Location Options
    # Choose where processed files should be saved
    # Default: replace original files in same location
    parser.add_argument(
        '-o', '--output-dir',
        type=Path,
        help='Output directory (default: in-place modification)'
    )
    
    # A1g: Add Helper Features
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Show what would be done without making changes'
    )
    
    parser.add_argument(
        '--verify',
        action='store_true',
        help='Deep verification of processed files'
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='Enable detailed logging and debug output'
    )
    
    parser.add_argument(
        '--log-file',
        type=Path,
        help='Log file path for detailed logging'
    )


def display_information_and_exit(args: argparse.Namespace) -> int:
    """
    A1i: Handle Information Requests
    Check if user wants to see supported file formats
    Show list and exit if that's all they wanted
    """
    if getattr(args, 'list_supported', False):
        # A1i_List: Show Supported File Types
        print("FastPass Supported File Formats:")
        print("\nModern Office Documents (experimental encryption, full decryption):")
        office_formats = [ext for ext, tool in FastPassConfig.SUPPORTED_FORMATS.items() 
                         if tool == 'msoffcrypto']
        for fmt in sorted(office_formats):
            print(f"  {fmt}")
        
        print("\nPDF Documents (full encryption and decryption support):")
        pdf_formats = [ext for ext, tool in FastPassConfig.SUPPORTED_FORMATS.items() 
                      if tool == 'PyPDF2']
        for fmt in sorted(pdf_formats):
            print(f"  {fmt}")
        
        print("\nLegacy Office Formats (NOT SUPPORTED):")
        print("  .doc, .xls, .ppt (use Office to convert to modern format)")
        
        return 0
    
    return 0


def validate_arguments(args: argparse.Namespace) -> None:
    """
    A2a: Check Input Requirements
    User must specify either files or folder to process
    Cannot proceed without something to work on
    """
    
    # Skip validation for info commands
    if getattr(args, 'list_supported', False):
        return
    
    # Must have an operation for non-info commands
    if not args.operation:
        raise ValueError("Must specify an operation (encrypt, decrypt, or check-password)")
    
    # A2a_Check: Valid Input Method Provided?
    has_files = hasattr(args, 'input') and args.input
    has_recursive = hasattr(args, 'recursive') and args.recursive
    
    if not has_files and not has_recursive:
        # A2a_Error: Nothing to Process
        raise ValueError("Must specify either files (-i) or recursive directory (-r)")
    
    if has_files and has_recursive:
        # A2a_Both_Error: Conflicting Instructions
        raise ValueError("Cannot specify both individual files and recursive directory")
    
    # A2a1: Validate Recursive Mode Usage
    # Check if recursive mode used with encrypt operation
    # Recursive mode only allowed with decrypt/check-password
    if has_recursive and args.operation == 'encrypt':
        # A2a1_Error: Recursive Encryption Blocked
        raise ValueError("Recursive mode only supported for decrypt operations (security restriction)")
    
    # Validate password requirements
    has_passwords = (hasattr(args, 'password') and args.password) or \
                   (hasattr(args, 'password_list') and args.password_list)
    
    if not has_passwords and args.operation != 'check-password':
        raise ValueError("Must specify passwords (-p) or password list (--password-list)")


def handle_stdin_passwords(args: argparse.Namespace) -> None:
    """
    A3d: Handle Stdin Password Input
    Check for 'stdin' in CLI passwords
    Parse JSON password mapping from stdin if specified
    """
    if hasattr(args, 'password') and args.password and 'stdin' in args.password:
        try:
            # Read JSON from stdin
            stdin_data = sys.stdin.read().strip()
            if stdin_data:
                password_mapping = json.loads(stdin_data)
                # Store the mapping for later use
                args.stdin_password_mapping = password_mapping
                # Remove 'stdin' from password list
                args.password = [p for p in args.password if p != 'stdin']
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in stdin: {e}")
        except Exception as e:
            raise ValueError(f"Error reading passwords from stdin: {e}")


def main() -> int:
    """
    Main Control Center
    Sets up error handling for entire program
    Prepares to read user's command-line instructions
    """
    try:
        # A1h: Read User's Commands
        # Process the command-line instructions user provided
        # Handle cases where user asks for help or makes errors
        args = parse_command_line_arguments()
        
        # A1i: Handle Information Requests
        if hasattr(args, 'list_supported') and args.list_supported:
            return display_information_and_exit(args)
        
        # A3a-A3e: Enhanced Logging Setup
        logger = setup_logger(
            debug=getattr(args, 'debug', False),
            log_file=getattr(args, 'log_file', None)
        )
        
        # A3e: Record Program Startup with Config
        logger.info(f"FastPass v{FastPassConfig.VERSION} starting")
        logger.debug(f"Operation: {args.operation}")
        
        # Validate arguments
        validate_arguments(args)
        
        # Handle stdin passwords
        handle_stdin_passwords(args)
        
        # Load configuration
        config = FastPassConfig.load_configuration(args)
        logger.debug(f"Configuration loaded: {len(config)} settings")
        
        # Import and run main application
        from app import FastPassApplication
        app = FastPassApplication(args, logger, config)
        return app.run()
        
    except ValueError as e:
        # A1h_Error: Invalid User Input
        print(f"Error: {sanitize_error_message(str(e))}", file=sys.stderr)
        return 2
    except KeyboardInterrupt:
        print("\nOperation cancelled by user", file=sys.stderr)
        return 1
    except Exception as e:
        # Unexpected error
        print(f"Unexpected error: {sanitize_error_message(str(e))}", file=sys.stderr)
        return 2


if __name__ == "__main__":
    sys.exit(main())
</file>

<file path="src/core/__init__.py">
"""
FastPass Core Business Logic
"""

from .security import SecurityValidator
from .file_handler import FileValidator, FileProcessor, ResultsReporter

__all__ = ['SecurityValidator', 'FileValidator', 'FileProcessor', 'ResultsReporter']
</file>

<file path="src/core/crypto_handlers/__init__.py">
"""
FastPass Crypto Tool Integrations
"""

from .office_handler import OfficeDocumentHandler
from .pdf_handler import PDFHandler

__all__ = ['OfficeDocumentHandler', 'PDFHandler']
</file>

<file path="src/core/crypto_handlers/office_handler.py">
"""
FastPass Office Document Handler
Maps to: C1c_Office, C2a_Config - msoffcrypto-tool integration
"""

# A1a: Load System Tools
import logging
from pathlib import Path
from typing import Dict, Any
import tempfile
import shutil

try:
    import msoffcrypto
except ImportError:
    msoffcrypto = None


class OfficeDocumentHandler:
    """
    Microsoft Office document encryption/decryption handler
    Uses msoffcrypto-tool for crypto operations
    """
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        
        if msoffcrypto is None:
            raise ImportError("msoffcrypto-tool is required for Office document processing")
        
        # C2a_Config: Configure Office Settings
        self.timeout = 30
        self.encryption_algorithm = 'AES-256'
        
        self.logger.debug("Office document handler initialized")
    
    def configure(self, config: Dict[str, Any]) -> None:
        """
        C2a: Configure Office Handler
        Set Office-specific configuration options
        """
        self.timeout = config.get('office_timeout', self.timeout)
        
        # Log experimental encryption warning
        if config.get('debug', False):
            self.logger.warning(
                "Office document encryption is EXPERIMENTAL. "
                "Decryption is fully supported."
            )
    
    def test_password(self, file_path: Path, password: str) -> bool:
        """
        Test if password works for Office document
        Returns True if password is correct, False otherwise
        """
        try:
            with open(file_path, 'rb') as f:
                office_file = msoffcrypto.OfficeFile(f)
                
                if not office_file.is_encrypted():
                    # File is not encrypted, so any password "works" for decryption
                    return True
                
                # Try to load with password
                office_file.load_key(password=password)
                
                # Try to decrypt a small portion to verify password
                with tempfile.NamedTemporaryFile() as temp_file:
                    office_file.decrypt(temp_file)
                    temp_file.seek(0)
                    # If we can read some data, password is correct
                    data = temp_file.read(100)
                    return len(data) > 0
                    
        except Exception as e:
            self.logger.debug(f"Password test failed for {file_path}: {e}")
            return False
    
    def encrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """
        Encrypt Office document with password
        Note: This is experimental functionality
        """
        
        # Log experimental warning
        self.logger.warning(
            f"EXPERIMENTAL: Encrypting {input_path.name} with Office encryption"
        )
        
        try:
            # For Office encryption, we need to use a different approach
            # msoffcrypto-tool primarily supports decryption
            # For encryption, we would need to use Office automation or other tools
            
            # This is a placeholder implementation
            # In a real implementation, you might use:
            # - Office COM automation (Windows only)
            # - LibreOffice command line tools
            # - Or other encryption methods
            
            raise NotImplementedError(
                "Office document encryption is not yet implemented. "
                "Use Microsoft Office or LibreOffice to encrypt documents manually."
            )
            
        except Exception as e:
            raise Exception(f"Failed to encrypt Office document {input_path}: {e}")
    
    def decrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """
        Decrypt Office document with password
        Full decryption support using msoffcrypto-tool
        """
        try:
            with open(input_path, 'rb') as f:
                office_file = msoffcrypto.OfficeFile(f)
                
                if not office_file.is_encrypted():
                    # File is not encrypted, just copy it
                    shutil.copy2(input_path, output_path)
                    self.logger.info(f"File {input_path.name} was not encrypted, copied as-is")
                    return
                
                # Load the password
                office_file.load_key(password=password)
                
                # Decrypt to output file
                with open(output_path, 'wb') as output_file:
                    office_file.decrypt(output_file)
                
                self.logger.info(f"Successfully decrypted {input_path.name}")
                
        except Exception as e:
            raise Exception(f"Failed to decrypt Office document {input_path}: {e}")
    
    def cleanup(self) -> None:
        """
        E2d: Call Handler Cleanup
        Clean up any handler-specific resources
        """
        # Office handler doesn't maintain persistent resources
        pass
</file>

<file path="src/core/crypto_handlers/pdf_handler.py">
"""
FastPass PDF Handler
Maps to: C1d_PDF, C2b_Config - PyPDF2 integration
"""

# A1a: Load System Tools
import logging
from pathlib import Path
from typing import Dict, Any

try:
    import PyPDF2
except ImportError:
    PyPDF2 = None


class PDFHandler:
    """
    PDF document encryption/decryption handler
    Uses PyPDF2 for crypto operations
    """
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        
        if PyPDF2 is None:
            raise ImportError("PyPDF2 is required for PDF document processing")
        
        # C2b_Config: Configure PDF Settings
        self.encryption_method = 'AES-256'
        self.user_password_length = 128
        
        self.logger.debug("PDF handler initialized")
    
    def configure(self, config: Dict[str, Any]) -> None:
        """
        C2b: Configure PDF Handler
        Set PDF-specific configuration options
        """
        self.encryption_method = config.get('pdf_encryption_method', self.encryption_method)
        self.user_password_length = config.get('pdf_password_length', self.user_password_length)
    
    def test_password(self, file_path: Path, password: str) -> bool:
        """
        Test if password works for PDF document
        Returns True if password is correct, False otherwise
        """
        try:
            with open(file_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                
                if not pdf_reader.is_encrypted:
                    # PDF is not encrypted, so any password "works" for decryption
                    return True
                
                # Try to decrypt with password
                result = pdf_reader.decrypt(password)
                
                # PyPDF2 returns:
                # 0: Failed
                # 1: Succeeded with user password
                # 2: Succeeded with owner password
                return result > 0
                
        except Exception as e:
            self.logger.debug(f"Password test failed for {file_path}: {e}")
            return False
    
    def encrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """
        Encrypt PDF document with password
        Full encryption support using PyPDF2
        """
        try:
            with open(input_path, 'rb') as input_file:
                pdf_reader = PyPDF2.PdfReader(input_file)
                pdf_writer = PyPDF2.PdfWriter()
                
                # Copy all pages from input to output
                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    pdf_writer.add_page(page)
                
                # Encrypt the PDF with password
                pdf_writer.encrypt(
                    user_password=password,
                    owner_password=password,  # Use same password for both
                    use_128bit=True
                )
                
                # Write encrypted PDF to output file
                with open(output_path, 'wb') as output_file:
                    pdf_writer.write(output_file)
                
                self.logger.info(f"Successfully encrypted {input_path.name}")
                
        except Exception as e:
            raise Exception(f"Failed to encrypt PDF {input_path}: {e}")
    
    def decrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """
        Decrypt PDF document with password
        Full decryption support using PyPDF2
        """
        try:
            with open(input_path, 'rb') as input_file:
                pdf_reader = PyPDF2.PdfReader(input_file)
                
                if not pdf_reader.is_encrypted:
                    # PDF is not encrypted, just copy it
                    import shutil
                    shutil.copy2(input_path, output_path)
                    self.logger.info(f"PDF {input_path.name} was not encrypted, copied as-is")
                    return
                
                # Decrypt with password
                decrypt_result = pdf_reader.decrypt(password)
                if decrypt_result == 0:
                    raise Exception(f"Incorrect password for PDF {input_path}")
                
                # Create writer and copy all pages
                pdf_writer = PyPDF2.PdfWriter()
                
                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    pdf_writer.add_page(page)
                
                # Write decrypted PDF to output file
                with open(output_path, 'wb') as output_file:
                    pdf_writer.write(output_file)
                
                self.logger.info(f"Successfully decrypted {input_path.name}")
                
        except Exception as e:
            raise Exception(f"Failed to decrypt PDF {input_path}: {e}")
    
    def cleanup(self) -> None:
        """
        E2d: Call Handler Cleanup
        Clean up any handler-specific resources
        """
        # PDF handler doesn't maintain persistent resources
        pass
</file>

<file path="src/core/file_handler.py">
"""
FastPass File Handler Module
Maps to: Section B3a-B6h File Validation and Section D File Processing
"""

# A1a: Load System Tools
import filetype
import tempfile
import shutil
import hashlib
import os
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime
import logging

from utils.config import FastPassConfig


# Custom Exception Classes
class FileFormatError(Exception):
    """Raised when file format validation fails"""
    pass

class ProcessingError(Exception):
    """Raised when file processing fails"""
    pass


@dataclass
class FileManifest:
    """
    B6a: Create FileManifest Object
    Data structure to hold file metadata and processing information
    """
    path: Path
    format: str
    size: int
    is_encrypted: bool
    crypto_tool: str
    security_checked: bool = False
    access_verified: bool = False


class FileValidator:
    """
    File format validation and detection
    Maps to B3a-B6h from flowchart
    """
    
    def __init__(self, logger: logging.Logger, config: Dict[str, Any]):
        self.logger = logger
        self.config = config
        self.max_file_size = config.get('max_file_size', FastPassConfig.MAX_FILE_SIZE)
    
    def validate_file(self, file_path: Path) -> FileManifest:
        """
        B3a-B6e: Complete file validation pipeline
        Validate file format, content, and create manifest
        """
        
        # B1f: Verify File Actually Exists
        if not file_path.exists():
            raise FileFormatError(f"File not found: {file_path}")
        
        if not file_path.is_file():
            raise FileFormatError(f"Path is not a file: {file_path}")
        
        # B3a-B3e: Enhanced File Format Validation
        file_format = self._detect_file_format(file_path)
        
        # B4a-B4d: File Access and Size Validation
        self._validate_file_access_and_size(file_path)
        
        # B5a-B5c: Encryption Status Detection
        is_encrypted = self._detect_encryption_status(file_path, file_format)
        
        # B6a-B6e: Build File Manifest
        manifest = FileManifest(
            path=file_path,
            format=file_format,
            size=file_path.stat().st_size,
            is_encrypted=is_encrypted,
            crypto_tool=FastPassConfig.SUPPORTED_FORMATS[file_format],
            security_checked=True,
            access_verified=True
        )
        
        # B6f: Log File Validation
        self.logger.debug(f"Validated: {file_path} (format: {file_format}, encrypted: {is_encrypted})")
        
        return manifest
    
    def _detect_file_format(self, file_path: Path) -> str:
        """
        B3b-B3e: Enhanced File Format Validation (Magic Number Priority)
        Detect file format using magic numbers with extension fallback
        """
        
        # B3b: Detect Format via Magic Numbers (Primary)
        try:
            detected_type = filetype.guess(str(file_path))
            if detected_type:
                # Convert MIME type to extension
                mime_to_ext = {
                    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
                    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': '.xlsx',
                    'application/vnd.openxmlformats-officedocument.presentationml.presentation': '.pptx',
                    'application/pdf': '.pdf'
                }
                
                detected_ext = mime_to_ext.get(detected_type.mime)
                if detected_ext:
                    # B3b_Success: Use Magic Number Result
                    file_ext = file_path.suffix.lower()
                    if file_ext != detected_ext:
                        # B3e_Mismatch: Format Mismatch
                        self.logger.warning(f"Extension {file_ext} != detected {detected_ext} for {file_path}")
                    return detected_ext
        except Exception as e:
            # B3b_Fallback: Use Extension Validation
            self.logger.warning(f"Magic number detection failed for {file_path}: {e}")
        
        # B3c: Validate Extension Against Supported Formats
        file_ext = file_path.suffix.lower()
        
        # B3d: Verify FastPass Can Handle This Format
        if file_ext not in FastPassConfig.SUPPORTED_FORMATS:
            # B3d_Unsupported: File Type Not Supported
            raise FileFormatError(
                f"Unsupported file format: {file_ext}. "
                f"Supported formats: {list(FastPassConfig.SUPPORTED_FORMATS.keys())}"
            )
        
        return file_ext
    
    def _validate_file_access_and_size(self, file_path: Path) -> None:
        """
        B4a-B4d: File Access Validation
        Check file readability, size limits, and permissions
        """
        
        # B4a: Test File Reading Capability
        try:
            with open(file_path, 'rb') as f:
                # Read a small sample to verify access
                f.read(1024)
        except Exception as e:
            # B4a_Read: File Reading Blocked
            raise FileFormatError(f"Cannot read file {file_path}: {e}")
        
        # B4b: Check File Size Limits
        file_size = file_path.stat().st_size
        
        if file_size == 0:
            # B4b_Empty: File Contains No Data
            raise FileFormatError(f"File is empty: {file_path}")
        
        if file_size > self.max_file_size:
            # B4b_Large: File Exceeds Size Limit
            raise FileFormatError(
                f"File too large: {file_size} bytes (limit: {self.max_file_size} bytes)"
            )
        
        # B4c: Check File Modification Permission
        parent_dir = file_path.parent
        if not os.access(parent_dir, os.W_OK):
            # B4c_Write: File Modification Blocked
            raise FileFormatError(f"No write permission for directory: {parent_dir}")
    
    def _detect_encryption_status(self, file_path: Path, file_format: str) -> bool:
        """
        B5a-B5c: Encryption Status Detection
        Determine if file is password-protected
        """
        
        # B5a: Determine File Type Handler
        crypto_tool = FastPassConfig.SUPPORTED_FORMATS[file_format]
        
        try:
            # B5b: Test Encryption Status
            with open(file_path, 'rb') as f:
                if crypto_tool == 'msoffcrypto':
                    # B5a_Office: Office Document Detection
                    import msoffcrypto
                    office_file = msoffcrypto.OfficeFile(f)
                    return office_file.is_encrypted()
                
                elif crypto_tool == 'PyPDF2':
                    # B5a_PDF: PDF Document Detection
                    import PyPDF2
                    pdf_reader = PyPDF2.PdfReader(f)
                    return pdf_reader.is_encrypted
                
        except Exception as e:
            # B5b_Failed: Encryption Detection Failed
            self.logger.warning(f"Cannot detect encryption for {file_path}: {e}")
            # Assume unencrypted and proceed with caution
            return False
        
        return False


class FileProcessor:
    """
    File processing pipeline with crypto operations
    Maps to Section D from flowchart
    """
    
    def __init__(self, logger: logging.Logger, config: Dict[str, Any], 
                 password_manager, crypto_handlers: Dict, temp_files_created: List):
        self.logger = logger
        self.config = config
        self.password_manager = password_manager
        self.crypto_handlers = crypto_handlers
        self.temp_files_created = temp_files_created
    
    def process_files(self, validated_files: List[FileManifest], 
                     operation: str, output_dir: Optional[Path]) -> Dict:
        """
        D2a-D4g: Main File Processing Pipeline
        Process all validated files with crypto operations
        """
        
        # D1a-D1f: Initialize TempFileManager and secure temp directory
        with tempfile.TemporaryDirectory(prefix=self.config['temp_dir_prefix']) as temp_dir_str:
            temp_dir = Path(temp_dir_str)
            
            # D1c: Set Enhanced Secure Permissions
            temp_dir.chmod(0o700)
            
            # Create processing subdirectories
            processing_dir = temp_dir / 'processing'
            output_temp_dir = temp_dir / 'output'
            processing_dir.mkdir(mode=0o700)
            output_temp_dir.mkdir(mode=0o700)
            
            # D2a: Initialize Processing Results
            successful_files = []
            failed_files = []
            
            # D2b: Start Main Processing Loop
            for file_manifest in validated_files:
                try:
                    result = self._process_single_file(
                        file_manifest, operation, output_dir,
                        processing_dir, output_temp_dir
                    )
                    successful_files.append(result)
                    
                except Exception as e:
                    error = FileProcessingError(file_manifest.path, str(e))
                    failed_files.append(error)
                    self.logger.error(f"Failed to process {file_manifest.path}: {e}")
            
            return {
                'successful_files': successful_files,
                'failed_files': failed_files,
                'total_files': len(validated_files)
            }
    
    def _process_single_file(self, file_manifest: FileManifest, operation: str,
                           output_dir: Optional[Path], processing_dir: Path,
                           output_temp_dir: Path) -> 'FileProcessingResult':
        """
        D2c-D4g: Process single file through complete pipeline
        """
        
        # D2c: Get Crypto Handler
        handler = self.crypto_handlers[file_manifest.crypto_tool]
        
        # D2d: Find Working Password
        if operation in ['decrypt', 'check-password'] and file_manifest.is_encrypted:
            password = self.password_manager.find_working_password(file_manifest.path, handler)
            if not password:
                raise ProcessingError(f"No working password found for {file_manifest.path}")
        elif operation == 'encrypt':
            # For encryption, use first available password
            passwords = self.password_manager.get_password_candidates(file_manifest.path)
            if not passwords:
                raise ProcessingError(f"No password specified for encryption of {file_manifest.path}")
            password = passwords[0]
        else:
            password = None
        
        # D2e-D2f: Setup Temp File Paths and Copy Input
        temp_input = processing_dir / f'input_{file_manifest.path.name}'
        temp_output = output_temp_dir / f'output_{file_manifest.path.name}'
        
        shutil.copy2(file_manifest.path, temp_input)
        
        # D2g-D2h: Perform Crypto Operation
        if operation == 'encrypt':
            handler.encrypt_file(temp_input, temp_output, password)
        elif operation == 'decrypt':
            handler.decrypt_file(temp_input, temp_output, password)
        elif operation == 'check-password':
            # For check-password, just verify we can open with password
            if file_manifest.is_encrypted:
                if not handler.test_password(temp_input, password):
                    raise ProcessingError(f"Password verification failed for {file_manifest.path}")
            # No output file needed for check-password
            temp_output = None
        
        # D3a-D3d: Output Validation (if output file was created)
        if temp_output and operation != 'check-password':
            self._validate_output_file(temp_output, file_manifest, operation)
        
        # D4a-D4g: File Movement and Final Result
        if operation != 'check-password':
            final_path = self._move_to_final_location(
                temp_output, file_manifest.path, output_dir
            )
        else:
            final_path = file_manifest.path  # No file movement for check-password
        
        # D4f-D4g: Create Processing Result
        return FileProcessingResult(
            original_path=file_manifest.path,
            final_path=final_path,
            operation=operation,
            password_used=password is not None,
            checksum=self._calculate_checksum(final_path) if final_path.exists() else None
        )
    
    def _validate_output_file(self, temp_output: Path, file_manifest: FileManifest, operation: str) -> None:
        """
        D3a-D3d: Output Validation
        Validate the processed output file
        """
        
        # D3a: Validate Output File Exists
        if not temp_output.exists():
            raise ProcessingError("Crypto operation did not create output file")
        
        # D3b: Check Output File Size
        output_size = temp_output.stat().st_size
        if output_size == 0:
            raise ProcessingError("Output file is empty")
        
        # D3c: Format-Specific Validation
        try:
            if file_manifest.crypto_tool == 'msoffcrypto':
                # D3c_Office: Validate Office Document
                import msoffcrypto
                with open(temp_output, 'rb') as f:
                    office_file = msoffcrypto.OfficeFile(f)
                    # Try to read document structure
                    
            elif file_manifest.crypto_tool == 'PyPDF2':
                # D3c_PDF: Validate PDF Document
                import PyPDF2
                with open(temp_output, 'rb') as f:
                    pdf_reader = PyPDF2.PdfReader(f)
                    # Try to read PDF structure
                    
        except Exception as e:
            raise ProcessingError(f"Output file validation failed: {e}")
        
        # D3d: Validate Encryption Status Changed
        current_encrypted = self._detect_encryption_status_for_validation(temp_output, file_manifest.format)
        expected_encrypted = operation == 'encrypt'
        
        if current_encrypted != expected_encrypted:
            raise ProcessingError(f"Encryption status not changed correctly (expected: {expected_encrypted}, actual: {current_encrypted})")
    
    def _detect_encryption_status_for_validation(self, file_path: Path, file_format: str) -> bool:
        """Helper to detect encryption status for validation"""
        crypto_tool = FastPassConfig.SUPPORTED_FORMATS[file_format]
        
        try:
            with open(file_path, 'rb') as f:
                if crypto_tool == 'msoffcrypto':
                    import msoffcrypto
                    office_file = msoffcrypto.OfficeFile(f)
                    return office_file.is_encrypted()
                elif crypto_tool == 'PyPDF2':
                    import PyPDF2
                    pdf_reader = PyPDF2.PdfReader(f)
                    return pdf_reader.is_encrypted
        except Exception:
            return False
        
        return False
    
    def _move_to_final_location(self, temp_output: Path, original_path: Path, 
                              output_dir: Optional[Path]) -> Path:
        """
        D4a-D4e: Enhanced File Movement with Error Handling
        Move processed file to final location
        """
        
        # D4a: Determine Final Output Path with Validation
        if output_dir:
            final_path = output_dir / original_path.name
        else:
            # In-place modification
            final_path = original_path
        
        # D4b: Handle Filename Conflicts
        if final_path.exists() and final_path != original_path:
            # Generate unique name for output directory
            counter = 1
            base = final_path.stem
            suffix = final_path.suffix
            while final_path.exists():
                final_path = final_path.parent / f"{base}_{counter}{suffix}"
                counter += 1
        
        # D4c: Atomic Move with Error Handling
        try:
            # Ensure target directory exists
            final_path.parent.mkdir(parents=True, exist_ok=True)
            
            # Atomic move
            shutil.move(str(temp_output), str(final_path))
            
        except Exception as e:
            raise ProcessingError(f"Failed to move file to final location: {e}")
        
        # D4d: Update File Permissions
        final_path.chmod(self.config['secure_permissions'])
        
        return final_path
    
    def _calculate_checksum(self, file_path: Path) -> str:
        """
        D4e: Generate File Checksum
        Calculate SHA256 checksum for file integrity
        """
        try:
            return hashlib.sha256(file_path.read_bytes()).hexdigest()
        except Exception:
            return None


@dataclass
class FileProcessingResult:
    """Result of processing a single file"""
    original_path: Path
    final_path: Path
    operation: str
    password_used: bool
    checksum: Optional[str] = None


@dataclass
class FileProcessingError:
    """Error during file processing"""
    path: Path
    message: str


class ResultsReporter:
    """
    Results reporting and exit code determination
    Maps to Section E4a-E5d from flowchart
    """
    
    def __init__(self, logger: logging.Logger, start_time: datetime):
        self.logger = logger
        self.start_time = start_time
    
    def generate_report(self, processing_results: Dict) -> int:
        """
        E4a-E5d: Report generation and exit code determination
        Generate comprehensive report and determine exit code
        """
        
        # E1a-E1e: Calculate Processing Metrics
        end_time = datetime.now()
        duration = end_time - self.start_time
        
        successful_files = processing_results['successful_files']
        failed_files = processing_results['failed_files']
        total_files = processing_results['total_files']
        
        # E4b-E4d: Generate Report
        self._print_results_summary(successful_files, failed_files, total_files, duration)
        
        # E5a-E5d: Exit Code Determination
        return self._determine_exit_code(successful_files, failed_files)
    
    def _print_results_summary(self, successful_files: List, failed_files: List, 
                             total_files: int, duration) -> None:
        """
        E4b-E4e: Print comprehensive results summary
        """
        
        print(f"\nFastPass Processing Complete")
        print(f"{'=' * 40}")
        print(f"Total files processed: {total_files}")
        print(f"Successful: {len(successful_files)}")
        print(f"Failed: {len(failed_files)}")
        print(f"Processing time: {duration.total_seconds():.2f} seconds")
        
        if successful_files:
            print(f"\nSuccessful files:")
            for result in successful_files:
                print(f"  SUCCESS: {result.original_path}")
        
        if failed_files:
            print(f"\nFailed files:")
            for error in failed_files:
                print(f"  FAILED: {error.path}: {error.message}")
    
    def _determine_exit_code(self, successful_files: List, failed_files: List) -> int:
        """
        E5a-E5d: Exit Code Determination
        Determine appropriate exit code based on results
        """
        
        success_count = len(successful_files)
        failure_count = len(failed_files)
        
        if failure_count == 0 and success_count > 0:
            # E5b_Success: Exit Code 0
            self.logger.info("All operations successful")
            return 0
        elif success_count > 0 and failure_count > 0:
            # E5b_Mixed: Exit Code 1
            self.logger.warning("Some operations failed")
            return 1
        else:
            # E5b_Failure: Exit Code 1
            self.logger.error("All operations failed")
            return 1
</file>

<file path="src/core/password/__init__.py">
"""
FastPass Password Handling Modules
"""

from .password_manager import PasswordManager

__all__ = ['PasswordManager']
</file>

<file path="src/core/password/password_manager.py">
"""
FastPass Password Management System
Maps to: C3a-C5d Password Management and Testing from flowchart
"""

# A1a: Load System Tools
from pathlib import Path
from typing import List, Optional, Dict, Any
import logging


class PasswordManager:
    """
    Password handling with multiple sources and priority algorithm
    Maps to: C3a-C5d from flowchart
    """
    
    def __init__(self, cli_passwords: List[str] = None, 
                 password_list_file: Optional[Path] = None,
                 stdin_mapping: Optional[Dict[str, str]] = None):
        """
        C3a-C3c: Initialize PasswordManager Class
        Set up password storage and management
        """
        
        # C3b: Remember User's Passwords
        self.cli_passwords = cli_passwords or []
        self.password_list_file = password_list_file
        self.stdin_mapping = stdin_mapping or {}
        
        # C3c: Prepare Password Storage
        self.password_list = []
        
        # C3d: Load Passwords from File
        if self.password_list_file:
            self._load_password_list()
    
    def _load_password_list(self) -> None:
        """
        C3d_Load: Read Passwords from File
        Load passwords from text file, one per line
        """
        try:
            with open(self.password_list_file, 'r', encoding='utf-8') as f:
                self.password_list = [line.strip() for line in f if line.strip()]
            
            # C3d_Load_Success: Passwords Successfully Loaded
            print(f"Loaded {len(self.password_list)} passwords from file")
            
        except FileNotFoundError:
            # C3d_Load_Error: Cannot Read Password File
            print(f"Warning: Password list file not found: {self.password_list_file}")
            self.password_list = []
        except Exception as e:
            print(f"Warning: Error reading password file {self.password_list_file}: {e}")
            self.password_list = []
    
    def get_password_candidates(self, file_path: Path) -> List[str]:
        """
        C4a-C4e: Get prioritized list of passwords to try for a file
        Build password list with priority ordering
        """
        
        # C4a: Start Building Password List
        candidates = []
        
        # Check for file-specific password from stdin mapping
        if self.stdin_mapping:
            file_name = file_path.name
            if file_name in self.stdin_mapping:
                candidates.append(self.stdin_mapping[file_name])
        
        # C4b: Add Command-Line Passwords First
        # Put passwords user typed in command first
        candidates.extend(self.cli_passwords)
        
        # C4c: Add File Passwords Second
        # Add passwords from password file after command-line ones
        candidates.extend(self.password_list)
        
        # C4d: Remove Duplicate Passwords
        # Eliminate passwords that appear multiple times
        seen = set()
        unique_candidates = []
        
        # C4d_Loop: Check Each Password for Duplicates
        for password in candidates:
            if password not in seen:
                # C4d_Add: Add New Password to List
                seen.add(password)
                unique_candidates.append(password)
        
        # C4e: Finalize Password List
        return unique_candidates
    
    def find_working_password(self, file_path: Path, crypto_handler) -> Optional[str]:
        """
        C5a-C5d: Find working password for file by trying all candidates
        Password testing mechanism
        """
        
        # C5a-C5b: Set Up Password Testing System and get passwords
        candidates = self.get_password_candidates(file_path)
        
        if not candidates:
            return None
        
        # C5c-C5d: Begin Trying Passwords
        for password in candidates:
            try:
                # C5d: Try Current Password
                if crypto_handler.test_password(file_path, password):
                    # C5d_Success: Found Working Password
                    return password
                    
            except Exception as e:
                # Continue trying other passwords
                continue
        
        # C5d_Failed: No Password Works
        return None
    
    def clear_passwords(self) -> None:
        """
        E3a-E3d: Clear passwords from memory for security
        Overwrite password memory
        """
        
        # E3a_Loop: Overwrite Password Memory
        if self.cli_passwords:
            for i in range(len(self.cli_passwords)):
                if self.cli_passwords[i]:
                    # E3a_Overwrite: Overwrite Password
                    self.cli_passwords[i] = 'X' * len(self.cli_passwords[i])
            self.cli_passwords.clear()
        
        if self.password_list:
            for i in range(len(self.password_list)):
                if self.password_list[i]:
                    self.password_list[i] = 'X' * len(self.password_list[i])
            self.password_list.clear()
        
        if self.stdin_mapping:
            for key in self.stdin_mapping:
                if self.stdin_mapping[key]:
                    self.stdin_mapping[key] = 'X' * len(self.stdin_mapping[key])
            self.stdin_mapping.clear()
        
        # E3c: Force Garbage Collection
        import gc
        gc.collect()
</file>

<file path="src/core/security.py">
"""
FastPass Security Validation Module
Maps to: Section B2a-B2e Enhanced Security Validation from flowchart
"""

# A1a: Load System Tools
import os
import stat
from pathlib import Path
from typing import Set
import logging

from app import SecurityViolationError


class SecurityValidator:
    """
    Security validation and path checking
    Implements comprehensive security hardening
    """
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
        
        # B2d: Set Security Boundaries
        # Define which folders the program is allowed to access
        self.allowed_directories = self._get_allowed_directories()
    
    def _get_allowed_directories(self) -> Set[Path]:
        """
        B2d: Set Security Boundaries
        Define allowed security zones for file access
        """
        allowed = set()
        
        # User's home directory
        try:
            allowed.add(Path.home().resolve())
        except Exception:
            pass
        
        # Current working directory (with explicit allow flag)
        # Note: CWD access should require --allow-cwd flag in production
        try:
            allowed.add(Path.cwd().resolve())
        except Exception:
            pass
        
        return allowed
    
    def validate_file_path(self, file_path: Path) -> Path:
        """
        B2a-B2e: Complete path security validation
        Comprehensive security checks for file paths
        """
        
        # B2a: Resolve Absolute Paths for Security
        # Use Path.resolve() to get canonical paths
        try:
            resolved_path = file_path.resolve()
        except Exception as e:
            raise SecurityViolationError(f"Cannot resolve path: {file_path}")
        
        # B2b: Validate Against Allowed Directories
        # Check if resolved path is within approved locations
        if not self._is_path_within_allowed_directories(resolved_path):
            # B2b_Danger: Security Violation Detected
            raise SecurityViolationError(
                f"File path outside approved security boundaries: {file_path}"
            )
        
        # B2c: Check Each Path Element
        # Examine every folder and file name in the path
        self._validate_path_components(resolved_path)
        
        # B2e: Verify File Within Safe Zone
        # Final verification that file is in safe area
        if not self._is_file_in_safe_zone(resolved_path):
            # B2e_Security: File Access Blocked
            raise SecurityViolationError(
                f"File access blocked by security policy: {file_path}"
            )
        
        self.logger.debug(f"Security validation passed: {resolved_path}")
        return resolved_path
    
    def _is_path_within_allowed_directories(self, resolved_path: Path) -> bool:
        """
        B2b_Check: Path Within Security Boundaries?
        Check if path is contained within approved locations
        """
        for allowed_dir in self.allowed_directories:
            try:
                # Use relative_to() to check containment
                resolved_path.relative_to(allowed_dir)
                return True
            except ValueError:
                # Path is not relative to this allowed directory
                continue
        
        return False
    
    def _validate_path_components(self, resolved_path: Path) -> None:
        """
        B2c: Check Each Path Element
        Examine every folder and file name for security violations
        """
        
        # B2c_Loop: Examine Path Elements One by One
        for part in resolved_path.parts:
            if not self._is_path_component_safe(part):
                # B2c_Invalid: Unsafe Path Element Found
                raise SecurityViolationError(
                    f"Unsafe path component detected: {part}"
                )
    
    def _is_path_component_safe(self, component: str) -> bool:
        """
        B2c_Check: Path Element Safe?
        Check individual path components for safety
        """
        
        # Skip drive letters on Windows (e.g., "C:", "D:")
        if len(component) == 2 and component[1] == ':' and component[0].isalpha():
            return True
        
        # Skip root directory
        if component in ['/', '\\']:
            return True
        
        # Check for dangerous patterns
        dangerous_patterns = [
            '..', '..',  # Path traversal
            'CON', 'PRN', 'AUX', 'NUL',  # Windows reserved names
            'COM1', 'COM2', 'COM3', 'COM4', 'COM5', 'COM6', 'COM7', 'COM8', 'COM9',
            'LPT1', 'LPT2', 'LPT3', 'LPT4', 'LPT5', 'LPT6', 'LPT7', 'LPT8', 'LPT9'
        ]
        
        component_upper = component.upper()
        if component_upper in dangerous_patterns:
            return False
        
        # Check for dangerous characters (but allow colon for drive letters already handled above)
        dangerous_chars = '<>"|?*'
        if any(char in component for char in dangerous_chars):
            return False
        
        # Check for control characters
        if any(ord(char) < 32 for char in component):
            return False
        
        # Check for leading/trailing spaces or dots (Windows issues)
        if component != component.strip(' .'):
            return False
        
        return True
    
    def _is_file_in_safe_zone(self, resolved_path: Path) -> bool:
        """
        B2e_Check: File in Safe Area?
        Final security zone verification
        """
        
        # Additional checks for symbolic links
        try:
            if resolved_path.is_symlink():
                # Check if symlink target is also in safe zone
                target = resolved_path.readlink()
                if target.is_absolute():
                    return self._is_path_within_allowed_directories(target)
                else:
                    # Relative symlink - resolve relative to symlink location
                    target_resolved = (resolved_path.parent / target).resolve()
                    return self._is_path_within_allowed_directories(target_resolved)
        except Exception:
            # If we can't validate symlink, reject it
            return False
        
        # Check file permissions for additional security
        try:
            file_stat = resolved_path.stat()
            
            # On Unix-like systems, check for world-writable files
            if hasattr(stat, 'S_IWOTH') and file_stat.st_mode & stat.S_IWOTH:
                self.logger.warning(f"World-writable file detected: {resolved_path}")
                # Continue but log warning
        except Exception:
            # If we can't check permissions, continue
            pass
        
        return True
    
    def validate_output_directory(self, output_dir: Path) -> Path:
        """
        Additional validation for output directories
        """
        if output_dir is None:
            return None
        
        try:
            resolved_output = output_dir.resolve()
        except Exception as e:
            raise SecurityViolationError(f"Cannot resolve output directory: {output_dir}")
        
        # Check if output directory is within allowed boundaries
        if not self._is_path_within_allowed_directories(resolved_output):
            raise SecurityViolationError(
                f"Output directory outside security boundaries: {output_dir}"
            )
        
        # Create directory if it doesn't exist
        try:
            resolved_output.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            raise SecurityViolationError(f"Cannot create output directory: {output_dir}")
        
        return resolved_output
</file>

<file path="src/utils/__init__.py">
"""
FastPass Utility Modules
"""

from .config import FastPassConfig
from .logger import setup_logger

__all__ = ['FastPassConfig', 'setup_logger']
</file>

<file path="src/utils/config.py">
"""
FastPass Configuration Management System
Maps to: CONFIGURATION MANAGEMENT SYSTEM from flowchart
"""

# A1a: Load System Tools
import json
import os
from pathlib import Path
from typing import Dict, Any
import argparse


class FastPassConfig:
    """Configuration management with multiple sources and precedence"""
    
    # CONFIGURATION MANAGEMENT SYSTEM constants
    VERSION = "1.0.0"
    MAX_FILE_SIZE = 500 * 1024 * 1024  # 500MB
    TEMP_DIR_PREFIX = "fastpass_"
    SECURE_FILE_PERMISSIONS = 0o600
    SUPPORTED_FORMATS = {
        '.docx': 'msoffcrypto',
        '.xlsx': 'msoffcrypto', 
        '.pptx': 'msoffcrypto',
        '.docm': 'msoffcrypto',
        '.xlsm': 'msoffcrypto',
        '.pptm': 'msoffcrypto',
        '.dotx': 'msoffcrypto',
        '.xltx': 'msoffcrypto',
        '.potx': 'msoffcrypto',
        '.pdf': 'PyPDF2'
    }
    
    # Configuration file locations (in order of precedence)
    CONFIG_LOCATIONS = [
        Path.home() / '.fastpass' / 'config.json',  # User config
        Path.cwd() / 'fastpass.json',               # Project config
        Path(__file__).parent.parent / 'config.json'  # Default config
    ]
    
    @classmethod
    def load_configuration(cls, cli_args: argparse.Namespace) -> Dict[str, Any]:
        """Load configuration from multiple sources with precedence"""
        config = cls._get_default_config()
        
        # 1. Load from config files (lowest precedence)
        for config_path in cls.CONFIG_LOCATIONS:
            if config_path.exists():
                try:
                    with open(config_path, 'r') as f:
                        file_config = json.load(f)
                        config.update(file_config)
                except (json.JSONDecodeError, IOError) as e:
                    print(f"Warning: Could not load config from {config_path}: {e}")
        
        # 2. Load from environment variables
        env_config = cls._load_from_environment()
        config.update(env_config)
        
        # 3. Override with CLI arguments (highest precedence)
        cli_config = cls._extract_cli_config(cli_args)
        config.update(cli_config)
        
        return config
    
    @classmethod
    def _get_default_config(cls) -> Dict[str, Any]:
        """Default configuration values"""
        return {
            'max_file_size': cls.MAX_FILE_SIZE,
            'temp_dir_prefix': cls.TEMP_DIR_PREFIX,
            'secure_permissions': cls.SECURE_FILE_PERMISSIONS,
            'supported_formats': cls.SUPPORTED_FORMATS.copy(),
            'debug': False,
            'verify': False,
            'dry_run': False
        }
    
    @classmethod
    def _load_from_environment(cls) -> Dict[str, Any]:
        """Load configuration from environment variables"""
        env_config = {}
        
        # Check for FASTPASS_* environment variables
        if os.getenv('FASTPASS_DEBUG'):
            env_config['debug'] = os.getenv('FASTPASS_DEBUG').lower() in ('1', 'true', 'yes')
        
        if os.getenv('FASTPASS_MAX_FILE_SIZE'):
            try:
                env_config['max_file_size'] = int(os.getenv('FASTPASS_MAX_FILE_SIZE'))
            except ValueError:
                pass
        
        return env_config
    
    @classmethod
    def _extract_cli_config(cls, cli_args: argparse.Namespace) -> Dict[str, Any]:
        """Extract configuration from CLI arguments"""
        cli_config = {}
        
        if hasattr(cli_args, 'debug') and cli_args.debug:
            cli_config['debug'] = True
        
        if hasattr(cli_args, 'verify') and cli_args.verify:
            cli_config['verify'] = True
            
        if hasattr(cli_args, 'dry_run') and cli_args.dry_run:
            cli_config['dry_run'] = True
        
        return cli_config
</file>

<file path="src/utils/logger.py">
"""
FastPass Logging Configuration
Maps to: A3a-A3e Enhanced Logging Setup with TTY Detection
"""

# A1a: Load System Tools
import logging
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Optional


def setup_logger(name: str = "fastpass", 
                debug: bool = False, 
                log_file: Optional[Path] = None) -> logging.Logger:
    """
    A3a: Configure Console and File Logging
    Detect TTY for appropriate log formatting
    Set up both console and optional file logging
    """
    logger = logging.getLogger(name)
    
    # Clear any existing handlers
    logger.handlers.clear()
    
    # Set log level
    logger.setLevel(logging.DEBUG if debug else logging.INFO)
    
    # A3b: Set Up TTY-Aware Progress Tracking
    # TTY: Full timestamp format for console display
    # Non-TTY: Simple format for file redirection
    is_tty = sys.stdout.isatty()
    
    if is_tty:
        # A3c: Initialize Multi-Handler Logger - TTY format
        console_format = "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
        date_format = "%Y-%m-%d %H:%M:%S"
    else:
        # Non-TTY: Simple format for file redirection
        console_format = "[%(levelname)s] %(message)s"
        date_format = None
    
    # Create console handler
    console_handler = logging.StreamHandler(sys.stdout)
    console_formatter = logging.Formatter(console_format, datefmt=date_format)
    console_handler.setFormatter(console_formatter)
    logger.addHandler(console_handler)
    
    # A3c: Add file handler if --log-file specified
    if log_file:
        try:
            # Ensure log directory exists
            log_file.parent.mkdir(parents=True, exist_ok=True)
            
            file_handler = logging.FileHandler(log_file)
            file_format = "%(asctime)s [%(levelname)s] %(name)s:%(lineno)d: %(message)s"
            file_formatter = logging.Formatter(file_format, datefmt="%Y-%m-%d %H:%M:%S")
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)
        except Exception as e:
            logger.warning(f"Could not create log file {log_file}: {e}")
    
    # A3e: Record Program Startup with Config
    logger.debug(f"FastPass logger initialized (TTY: {is_tty})")
    
    return logger


def sanitize_error_message(message: str) -> str:
    """
    E3a: Sanitize Error Messages
    Apply sanitize_error_message() to all errors
    Remove paths, passwords, sensitive patterns
    """
    import re
    
    # E3a_Sanitize: Pattern-Based Sanitization
    # Remove password=<value>, IP addresses, email addresses
    sanitized = message
    
    # Remove password patterns
    sanitized = re.sub(r'password[=:\s]+[^\s,]+', 'password=<REDACTED>', sanitized, flags=re.IGNORECASE)
    
    # Remove file paths (keep just filename)
    sanitized = re.sub(r'[A-Za-z]:[\\\/][^\\\/\s]*[\\\/]([^\\\/\s]+)', r'<path>/\1', sanitized)
    sanitized = re.sub(r'\/[^\/\s]*\/([^\/\s]+)', r'<path>/\1', sanitized)
    
    # Remove potential IP addresses
    sanitized = re.sub(r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b', '<IP_ADDRESS>', sanitized)
    
    # Remove email addresses
    sanitized = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '<EMAIL>', sanitized)
    
    return sanitized
</file>

<file path="test_sample.txt">
This is a test file for FastPass functionality testing.
</file>

<file path="tests/conftest.py">
"""
FastPass Test Configuration and Fixtures
PyTest configuration and shared fixtures
"""

import pytest
import tempfile
import shutil
from pathlib import Path
import subprocess
import os

@pytest.fixture(scope="session")
def test_data_dir():
    """Fixture providing test data directory"""
    return Path(__file__).parent / "fixtures"

@pytest.fixture(scope="session") 
def sample_files_dir(test_data_dir):
    """Fixture providing sample files directory"""
    return test_data_dir / "sample_files"

@pytest.fixture
def temp_work_dir():
    """Fixture providing temporary working directory for each test"""
    temp_dir = tempfile.mkdtemp(prefix="fastpass_test_")
    yield Path(temp_dir)
    shutil.rmtree(temp_dir, ignore_errors=True)

@pytest.fixture
def fastpass_executable():
    """Fixture providing path to FastPass executable"""
    # Return the module path for running FastPass
    return ["uv", "run", "python", "-m", "src"]

@pytest.fixture
def simple_test_pdf(temp_work_dir):
    """Create a simple test PDF"""
    pdf_content = """%PDF-1.4
1 0 obj
<<
/Type /Catalog
/Pages 2 0 R
>>
endobj

2 0 obj
<<
/Type /Pages
/Kids [3 0 R]
/Count 1
>>
endobj

3 0 obj
<<
/Type /Page
/Parent 2 0 R
/MediaBox [0 0 612 792]
/Contents 4 0 R
>>
endobj

4 0 obj
<<
/Length 44
>>
stream
BT
/F1 12 Tf
100 700 Td
(Test PDF Content) Tj
ET
endstream
endobj

xref
0 5
0000000000 65535 f 
0000000009 00000 n 
0000000058 00000 n 
0000000115 00000 n 
0000000216 00000 n 
trailer
<<
/Size 5
/Root 1 0 R
>>
startxref
310
%%EOF"""
    
    test_pdf = temp_work_dir / "test.pdf"
    with open(test_pdf, 'w') as f:
        f.write(pdf_content)
    
    return test_pdf

@pytest.fixture
def password_list_file(temp_work_dir):
    """Fixture providing password list file"""
    password_file = temp_work_dir / "passwords.txt"
    passwords = [
        "password123",
        "secret456", 
        "complex&password!",
        "test with spaces"
    ]
    
    with open(password_file, 'w', encoding='utf-8') as f:
        for password in passwords:
            f.write(f"{password}\n")
    
    return password_file
</file>

<file path="tests/requirements.txt">
# Test dependencies
pytest>=7.0.0
pytest-cov>=4.0.0
</file>

<file path="tests/test_cli_basic.py">
"""
Basic CLI Tests for FastPass
Test core CLI functionality and argument parsing
Maps to: test_cli_parsing.py from test design
"""

import subprocess
import pytest
from pathlib import Path
import os

class TestCLIBasicFunctionality:
    """Test basic CLI operations and help functions"""
    
    def test_help_display(self, fastpass_executable):
        """Test: -h and --help show usage information"""
        # A1h_Help: Show Help Information
        result = subprocess.run(
            fastpass_executable + ["--help"], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 0
        assert "FastPass" in result.stdout
        assert "encrypt" in result.stdout
        assert "decrypt" in result.stdout
        assert "check-password" in result.stdout
    
    def test_version_display(self, fastpass_executable):
        """Test: --version shows version information"""
        result = subprocess.run(
            fastpass_executable + ["--version"], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 0
        assert "FastPass" in result.stdout
        assert "1.0.0" in result.stdout
    
    def test_list_supported_formats(self, fastpass_executable):
        """Test: --list-supported shows format list and exits"""
        # A1i_List: Show Supported File Types
        result = subprocess.run(
            fastpass_executable + ["--list-supported"], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 0
        assert "FastPass Supported File Formats" in result.stdout
        assert ".pdf" in result.stdout
        assert ".docx" in result.stdout
        assert "Modern Office Documents" in result.stdout
        assert "PDF Documents" in result.stdout
        assert "Legacy Office Formats" in result.stdout
    
    def test_no_operation_error(self, fastpass_executable):
        """Test: Missing operation should trigger error"""
        result = subprocess.run(
            fastpass_executable + ["-i", "test.pdf", "-p", "password"], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 2
        assert "Must specify an operation" in result.stderr
    
    def test_no_input_files_error(self, fastpass_executable):
        """Test: Missing -i flag should trigger error"""
        # A2a_Error: Nothing to Process
        result = subprocess.run(
            fastpass_executable + ["encrypt", "-p", "password"], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 2
        assert "Must specify either files" in result.stderr
    
    def test_no_password_error(self, fastpass_executable):
        """Test: Missing -p should trigger error for encrypt/decrypt"""
        result = subprocess.run(
            fastpass_executable + ["encrypt", "-i", "test.pdf"], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 2
        assert "Must specify passwords" in result.stderr

class TestCLIArgumentValidation:
    """Test CLI argument validation logic"""
    
    def test_conflicting_input_methods(self, fastpass_executable, temp_work_dir):
        """Test: Conflicting input methods should error"""
        # A2a_Both_Error: Conflicting Instructions
        result = subprocess.run(
            fastpass_executable + [
                "decrypt", 
                "-i", "test.pdf", 
                "-r", str(temp_work_dir),
                "-p", "password"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 2
        assert "Cannot specify both individual files and recursive directory" in result.stderr
    
    def test_recursive_encrypt_blocked(self, fastpass_executable, temp_work_dir):
        """Test: Recursive mode with encrypt should be blocked"""
        # A2a1_Error: Recursive Encryption Blocked
        result = subprocess.run(
            fastpass_executable + [
                "encrypt", 
                "-r", str(temp_work_dir),
                "-p", "password"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 2
        assert "Recursive mode only supported for decrypt operations" in result.stderr
    
    def test_recursive_decrypt_allowed(self, fastpass_executable, temp_work_dir):
        """Test: Recursive mode with decrypt should be allowed"""
        result = subprocess.run(
            fastpass_executable + [
                "decrypt", 
                "-r", str(temp_work_dir),
                "-p", "password"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        # Should not error on argument validation
        # May error later on file processing, but that's expected
        assert "Recursive mode only supported for decrypt operations" not in result.stderr

class TestCLIPasswordHandling:
    """Test password argument handling"""
    
    def test_single_password_cli(self, fastpass_executable, simple_test_pdf):
        """Test: -p password123"""
        result = subprocess.run(
            fastpass_executable + [
                "check-password",
                "-i", str(simple_test_pdf),
                "-p", "testpassword"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        # Should accept the password argument without validation errors
        assert "Must specify passwords" not in result.stderr
    
    def test_multiple_passwords_cli(self, fastpass_executable, simple_test_pdf):
        """Test: -p password1 password2 "complex pass" """
        result = subprocess.run(
            fastpass_executable + [
                "check-password",
                "-i", str(simple_test_pdf),
                "-p", "password1", "password2", "complex pass"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        # Should accept multiple passwords without validation errors
        assert "Must specify passwords" not in result.stderr
    
    def test_password_list_file(self, fastpass_executable, simple_test_pdf, password_list_file):
        """Test: --password-list passwords.txt"""
        result = subprocess.run(
            fastpass_executable + [
                "check-password",
                "-i", str(simple_test_pdf),
                "--password-list", str(password_list_file)
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        # Should accept password list file without validation errors
        assert "Must specify passwords" not in result.stderr

class TestFileFormatValidation:
    """Test file format validation"""
    
    def test_unsupported_file_format(self, fastpass_executable, temp_work_dir):
        """Test: Unsupported formats (.txt, .zip) should be rejected"""
        # Create a test txt file
        test_txt = temp_work_dir / "test.txt"
        test_txt.write_text("Test content")
        
        result = subprocess.run(
            fastpass_executable + [
                "encrypt",
                "-i", str(test_txt),
                "-p", "password"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 1
        assert "Unsupported file format" in result.stderr
        assert ".txt" in result.stderr
    
    def test_nonexistent_file(self, fastpass_executable):
        """Test: Non-existent files should be handled gracefully"""
        result = subprocess.run(
            fastpass_executable + [
                "encrypt",
                "-i", "nonexistent_file.pdf",
                "-p", "password"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert result.returncode == 1
        # Should report file not found error
</file>

<file path="tests/test_integration_basic.py">
"""
Basic Integration Tests for FastPass
Test end-to-end functionality with real files
Maps to: test_encrypt_operations.py and test_decrypt_operations.py from test design
"""

import subprocess
import pytest
from pathlib import Path
import shutil

class TestPDFOperations:
    """Test real PDF encryption and decryption operations"""
    
    def test_pdf_encrypt_decrypt_cycle(self, fastpass_executable, temp_work_dir):
        """Test: Complete encryptâ†’decrypt cycle preserves content"""
        
        # Use existing test PDF
        source_pdf = Path(__file__).parent.parent / "dev" / "pdf" / "test1_docx.pdf"
        if not source_pdf.exists():
            pytest.skip("Test PDF not available")
        
        # Copy to temp directory for testing
        test_pdf = temp_work_dir / "test_cycle.pdf"
        shutil.copy2(source_pdf, test_pdf)
        
        # Get original file size for comparison
        original_size = test_pdf.stat().st_size
        
        # Step 1: Encrypt the PDF
        encrypt_result = subprocess.run(
            fastpass_executable + [
                "encrypt",
                "-i", str(test_pdf),
                "-p", "test_password_123"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert encrypt_result.returncode == 0, f"Encryption failed: {encrypt_result.stderr}"
        assert "Successfully encrypted" in encrypt_result.stdout
        
        # Verify file still exists and size changed
        assert test_pdf.exists()
        encrypted_size = test_pdf.stat().st_size
        # Encrypted file should be different size (usually larger)
        
        # Step 2: Verify file is now encrypted (check-password should succeed)
        check_result = subprocess.run(
            fastpass_executable + [
                "check-password",
                "-i", str(test_pdf),
                "-p", "test_password_123"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert check_result.returncode == 0, f"Password check failed: {check_result.stderr}"
        
        # Step 3: Decrypt the PDF
        decrypt_result = subprocess.run(
            fastpass_executable + [
                "decrypt",
                "-i", str(test_pdf),
                "-p", "test_password_123"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert decrypt_result.returncode == 0, f"Decryption failed: {decrypt_result.stderr}"
        assert "Successfully decrypted" in decrypt_result.stdout
        
        # Verify file still exists and is accessible
        assert test_pdf.exists()
        final_size = test_pdf.stat().st_size
        
        # File should be accessible without password now
        check_no_password = subprocess.run(
            fastpass_executable + [
                "check-password",
                "-i", str(test_pdf)
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        # Should complete successfully (no password needed for unencrypted file)
        assert check_no_password.returncode == 0
    
    def test_pdf_wrong_password_fails(self, fastpass_executable, temp_work_dir):
        """Test: Wrong password should fail gracefully"""
        
        # Use existing test PDF
        source_pdf = Path(__file__).parent.parent / "dev" / "pdf" / "test1_docx.pdf"
        if not source_pdf.exists():
            pytest.skip("Test PDF not available")
        
        # Copy to temp directory
        test_pdf = temp_work_dir / "test_wrong_password.pdf"
        shutil.copy2(source_pdf, test_pdf)
        
        # Encrypt with one password
        encrypt_result = subprocess.run(
            fastpass_executable + [
                "encrypt",
                "-i", str(test_pdf),
                "-p", "correct_password"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert encrypt_result.returncode == 0
        
        # Try to decrypt with wrong password
        decrypt_result = subprocess.run(
            fastpass_executable + [
                "decrypt",
                "-i", str(test_pdf),
                "-p", "wrong_password"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        # Should fail with password error
        assert decrypt_result.returncode != 0
        # Should contain password-related error message
    
    def test_multiple_files_same_password(self, fastpass_executable, temp_work_dir):
        """Test: Multiple files with same password"""
        
        source_pdf = Path(__file__).parent.parent / "dev" / "pdf" / "test1_docx.pdf"
        if not source_pdf.exists():
            pytest.skip("Test PDF not available")
        
        # Create multiple test files
        test_files = []
        for i in range(3):
            test_file = temp_work_dir / f"test_multi_{i}.pdf"
            shutil.copy2(source_pdf, test_file)
            test_files.append(test_file)
        
        # Encrypt all files with same password
        encrypt_result = subprocess.run(
            fastpass_executable + [
                "encrypt",
                "-i"] + [str(f) for f in test_files] + [
                "-p", "shared_password_123"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert encrypt_result.returncode == 0
        assert "Total files processed: 3" in encrypt_result.stdout
        assert "Successful: 3" in encrypt_result.stdout
        assert "Failed: 0" in encrypt_result.stdout
        
        # Decrypt all files with same password
        decrypt_result = subprocess.run(
            fastpass_executable + [
                "decrypt",
                "-i"] + [str(f) for f in test_files] + [
                "-p", "shared_password_123"
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert decrypt_result.returncode == 0
        assert "Total files processed: 3" in decrypt_result.stdout
        assert "Successful: 3" in decrypt_result.stdout

class TestPasswordListFunctionality:
    """Test password list file functionality"""
    
    def test_password_list_file_usage(self, fastpass_executable, temp_work_dir, password_list_file):
        """Test: Password list file works correctly"""
        
        source_pdf = Path(__file__).parent.parent / "dev" / "pdf" / "test1_docx.pdf"
        if not source_pdf.exists():
            pytest.skip("Test PDF not available")
        
        test_pdf = temp_work_dir / "test_password_list.pdf"
        shutil.copy2(source_pdf, test_pdf)
        
        # Encrypt with first password from our list
        encrypt_result = subprocess.run(
            fastpass_executable + [
                "encrypt",
                "-i", str(test_pdf),
                "-p", "password123"  # This should be first in password_list_file
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert encrypt_result.returncode == 0
        
        # Try to decrypt using password list (should find the correct password)
        decrypt_result = subprocess.run(
            fastpass_executable + [
                "decrypt",
                "-i", str(test_pdf),
                "--password-list", str(password_list_file)
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert decrypt_result.returncode == 0
        assert "Successfully decrypted" in decrypt_result.stdout

class TestOutputDirectory:
    """Test output directory functionality"""
    
    def test_output_directory_creation(self, fastpass_executable, temp_work_dir):
        """Test: Output directory is created and files are placed correctly"""
        
        source_pdf = Path(__file__).parent.parent / "dev" / "pdf" / "test1_docx.pdf"
        if not source_pdf.exists():
            pytest.skip("Test PDF not available")
        
        test_pdf = temp_work_dir / "input" / "test_output.pdf"
        test_pdf.parent.mkdir(exist_ok=True)
        shutil.copy2(source_pdf, test_pdf)
        
        output_dir = temp_work_dir / "output"
        
        # Encrypt with output directory
        encrypt_result = subprocess.run(
            fastpass_executable + [
                "encrypt",
                "-i", str(test_pdf),
                "-p", "output_test_password",
                "-o", str(output_dir)
            ], 
            capture_output=True, 
            text=True,
            cwd=Path(__file__).parent.parent
        )
        
        assert encrypt_result.returncode == 0
        
        # Verify output directory was created
        assert output_dir.exists()
        assert output_dir.is_dir()
        
        # Verify file was created in output directory
        output_file = output_dir / test_pdf.name
        assert output_file.exists()
        
        # Original file should still exist
        assert test_pdf.exists()
</file>

<file path="requirements.txt">
# A1a: Load System Tools - Required dependencies
msoffcrypto-tool>=5.0.0    # Office document encryption/decryption
PyPDF2>=3.0.0              # PDF processing and encryption
filetype>=1.2.0            # File type detection (replaces python-magic)
</file>

<file path="dev/fast_pass_specification.md">
# FastPass - Complete Project Specification

> **Document Purpose & Maintenance Protocol:**
> This document serves as the authoritative, self-documenting specification for FastPass.
> It provides complete context to future AI instances and developers about:
>
> - **Current project status** and implementation details
> - **Architecture decisions** and technical solutions  
> - **Lessons learned** from development challenges
> - **Usage patterns** and deployment instructions
> - **Complete change history** and evolution of the project
>
> **Maintenance Requirement:** This document MUST be updated whenever significant changes are made to the codebase, architecture, or functionality. It should always reflect the current state of the project and serve as the single source of truth for understanding the entire system.

## Project Mission & Purpose

**FastPass** is a command-line tool that provides universal file encryption and decryption capabilities across multiple file formats. It serves as a unified front-end wrapper for specialized crypto tools (msoffcrypto-tool, PyPDF2) to add or remove password protection from Microsoft Office documents and PDF files.

**Core Problem Solved:** Eliminates the need to learn and manage multiple separate tools for file encryption/decryption across different formats. Provides a consistent, secure interface for password protection operations while maintaining file integrity and implementing enterprise-grade security practices.

**Key Differentiator:** Unified CLI interface with enterprise security patterns including file isolation, in-memory validation, password list support, and secure password handling. Follows proven architecture patterns with "it just works" simplicity for reliability and security.

---

## Product Requirements Document (PRD)

### Project Overview

- **Project Name:** FastPass
- **Version:** v1.0
- **Target Platform:** Windows Desktop (CLI) with cross-platform Python support
- **Technology Stack:** Python, msoffcrypto-tool, PyPDF2, filetype library, pathlib
- **Timeline:** Development in progress
- **Team Size:** Single developer maintained

### Target Users

- **Primary Users:** IT administrators, security professionals, business users
- **Secondary Users:** Developers, system integrators, automation script writers
- **User Experience Level:** Intermediate (comfortable with command-line tools)
- **Use Cases:** Batch file encryption, automated security workflows, document protection

### Feature Specifications

#### Core Functionality
- [x] Universal file encryption/decryption interface
- [x] Microsoft Office document password protection (modern and legacy formats)
- [x] PDF password protection and removal  
- [x] Batch processing for multiple files
- [x] Recursive directory processing with in-place or copy modes
- [x] Automatic file format detection using filetype library
- [x] Direct import strategy for simplified code management

#### Security & File Safety
- [x] File format validation using filetype library (simplified magic number checking)
- [x] Path traversal attack prevention with whitelist approach
- [x] Secure temporary file creation with proper permissions (0o600)
- [x] Password memory clearing and secure handling
- [x] Error message sanitization to prevent information disclosure
- [x] Legacy Office format protection (decrypt-only limitation documented)

#### Password Management
- [x] Per-file password specification with automatic pairing
- [x] Password management with multiple password support
- [x] Password list file support for batch operations
- [x] JSON password input via stdin for GUI integration
- [x] Secure password handling and memory cleanup
- [x] Password validation before file processing

#### File Operations
- [x] In-place modification with validation-based safety
- [x] Output directory specification for batch operations
- [x] File integrity verification after operations
- [x] Duplicate filename handling and conflict resolution
- [x] Comprehensive cleanup of temporary files

#### Utility Features
- [x] Dry-run mode for testing operations
- [x] File format support detection
- [x] Password requirement checking
- [x] Batch operation progress reporting
- [x] Detailed logging with debug mode

### Success Metrics

- **Performance Targets:** File processing < 10 seconds for typical business documents
- **User Experience:** Zero data loss through validation, "it just works" simplicity, clear error messages
- **Reliability:** 99.9% successful completion rate for valid inputs
- **Security:** No password exposure in logs, secure temporary file handling

### Constraints & Assumptions

- **Technical Constraints:** Requires underlying crypto libraries (msoffcrypto-tool, PyPDF2) to be available
- **Platform Constraints:** Cross-platform compatible with pure Python dependencies
- **Security Constraints:** Must maintain file confidentiality and integrity throughout operations
- **User Constraints:** Must have appropriate file permissions for input and output directories
- **Assumptions:** Users understand file encryption concepts and password management practices

---

## Project Directory Structure

```
fast_pass/
â”œâ”€â”€ src/                          # Main source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py               # Makes package executable with 'python -m src'
â”‚   â”œâ”€â”€ cli.py                    # CLI argument parsing and validation
â”‚   â”œâ”€â”€ core/                     # Core business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_handler.py       # File processing pipeline
â”‚   â”‚   â”œâ”€â”€ security.py           # Security validation and path checking
â”‚   â”‚   â”œâ”€â”€ crypto_handlers/      # Crypto tool integrations
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ office_handler.py # msoffcrypto-tool integration
â”‚   â”‚   â”‚   â””â”€â”€ pdf_handler.py    # PyPDF2 integration
â”‚   â”‚   â””â”€â”€ password/             # Password handling modules
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ password_manager.py # Password validation and management
â”‚   â”‚       â””â”€â”€ password_list.py    # Password list file handling
â”‚   â””â”€â”€ utils/                    # Utility modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py             # Logging configuration
â”‚       â””â”€â”€ config.py             # Configuration management
â”œâ”€â”€ tests/                        # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_cli.py
â”‚   â”œâ”€â”€ test_core.py
â”‚   â”œâ”€â”€ test_crypto_handlers.py
â”‚   â”œâ”€â”€ test_security.py
â”‚   â”œâ”€â”€ test_password_handling.py
â”‚   â””â”€â”€ test_integration.py
â”œâ”€â”€ dev/                          # Development documentation
â”‚   â””â”€â”€ fast_pass_specification.md
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ requirements-dev.txt          # Development dependencies
â”œâ”€â”€ setup.py                      # Package setup
â””â”€â”€ README.md                     # User documentation
```

### **Python Dependencies**

**Requirements (requirements.txt):**
```
msoffcrypto-tool>=5.0.0    # Office document encryption/decryption
PyPDF2>=3.0.0              # PDF processing and encryption
filetype>=1.2.0            # File type detection (replaces python-magic)
```

**PyInstaller Integration Notes:**
- All Python packages will be bundled into executable
- No external binaries required - pure Python dependencies
- Direct imports for simplified code management

### **Password Handling Architecture**

**Simplified password management without reuse concept:**

```python
# Password handling with multiple sources and priority algorithm
class PasswordManager:
    def __init__(self):
        self.cli_passwords = []  # Space-delimited passwords from CLI
        self.password_list_file = None  # Path to password list file
        self.password_list = []  # Passwords loaded from file
        
    def load_password_sources(self, args):
        """Load passwords from all sources"""
        # Space-delimited passwords from CLI
        if hasattr(args, 'cli_passwords') and args.cli_passwords:
            self.cli_passwords = [p for p in args.cli_passwords if p != 'stdin']
            
        # Password list file
        if args.password_list:
            self.password_list_file = args.password_list
            self.password_list = self._load_password_list()
            
    def get_password_candidates(self, file_path):
        """Get prioritized list of passwords to try for a file"""
        candidates = []
        
        # Priority 1: CLI -p passwords (in order provided)
        candidates.extend(self.cli_passwords)
        
        # Priority 2: Password list file (line by line)
        candidates.extend(self.password_list)
            
        # Remove duplicates while preserving order
        return list(dict.fromkeys(candidates))
        
    def _load_password_list(self):
        """Load passwords from text file, one per line"""
        try:
            with open(self.password_list_file, 'r', encoding='utf-8') as f:
                return [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            self.log_error(f"Password list file not found: {self.password_list_file}")
            return []
            
    def find_working_password(self, file_path, crypto_handler):
        """Find working password for file by trying all candidates"""
        candidates = self.get_password_candidates(file_path)
        
        for password in candidates:
            if crypto_handler.test_password(file_path, password):
                return password
        
        return None
```

---

## Command Line Reference

```
Usage: fast_pass {encrypt|decrypt} [options]

Required Arguments:
  encrypt                  Add password protection to files
  decrypt                  Remove password protection from files

File Input Options:
  -i, --input FILE...      Files to process (space-delimited, quotes for spaces)
  -r, --recursive DIR      Process directory recursively (decrypt/check-password only)

Password Options:
  -p, --password PASS...   Passwords to try (space-delimited, quotes for spaces)
  --password-list FILE     Text file with passwords to try (one per line)
  -p stdin                 Read passwords from JSON via stdin (GUI integration)
  --check-password [FILE]  Check if file requires password (dry-run mode)

Output Options:
  -o, --output-dir DIR     Output directory (default: in-place modification)

Utility Options:
  --dry-run               Show what would be done without making changes
  --verify                Deep verification of processed files
  --list-supported        List supported file formats
  --debug                 Enable detailed logging and debug output
  -h, --help              Show this help message
  -v, --version           Show version information

Supported File Formats:
  Modern Office:     .docx, .xlsx, .pptx, .docm, .xlsm, .pptm, .dotx, .xltx, .potx
                     (Encryption: experimental support, Decryption: full support)
  Legacy Office:     .doc, .xls, .ppt (NOT SUPPORTED - use Office to convert to modern format)
  PDF Files:         .pdf (Full encryption and decryption support)
Examples:
  # Encrypt single file with password
  fast_pass encrypt -i contract.docx -p "mypassword"
  
  # Decrypt multiple files with same password
  fast_pass decrypt -i file1.pdf file2.docx file3.xlsx -p "shared_pwd"
  
  # Multiple passwords via CLI (space-delimited, tries all passwords on all files)
  fast_pass decrypt -i file1.pdf file2.docx -p "password123" "secret456" "admin789"
  
  # Passwords with spaces (quoted)
  fast_pass decrypt -i protected.pdf -p "password1" "password 2" "ps3"
  
  # Password list file for batch operations
  fast_pass decrypt -i "archive_folder/report1.pdf" "archive_folder/report2.pdf" --password-list common_passwords.txt
  
  # Combined approach: specific password + password list fallback
  fast_pass decrypt -i urgent.pdf "archive1.pdf" "archive2.pdf" -p "urgent_pwd" --password-list common_passwords.txt
  
  # Passwords from stdin JSON (GUI integration)
  fast_pass decrypt -i file1.pdf file2.docx -p stdin < passwords.json
  # JSON format: {"file1.pdf": "secret1", "file2.docx": "secret2"}
  
  # Recursively process directory (decrypt only)
  fast_pass decrypt -r ./encrypted_docs/ -p "main_password"
  
  # Recursive with password list
  fast_pass decrypt -r ./archive/ --password-list passwords.txt
  
  # Check password protection status (dry-run)
  fast_pass --check-password -r ./documents/ --password-list test_passwords.txt
  
  # Mixed file types with output directory
  fast_pass encrypt -i report.pdf data.xlsx presentation.pptx -p "secret" -o ./secured/
  
  # Security: Allow current directory access (use with caution)
  fast_pass decrypt -i ./docs/report.pdf --allow-cwd -p "password123"

Exit Codes:
  0  Success
  1  General error (file access, crypto tool failure)
  2  Invalid arguments or command syntax
  3  Security violation (path traversal, invalid format)
  4  Password error (wrong password, authentication failure)
```

---

## High-Level Architecture Overview - Core Processing Flow

> ðŸ’¡ **IMPLEMENTATION CRITICAL**: This pseudocode provides the master reference for code organization. Every code block must map to a specific element ID (e.g., `# A1a`, `# B3c`, etc.)

```python
# MAIN PROGRAM ENTRY POINT
def main():
    """FastPass main entry point with complete error handling"""
    try:
        # A: CLI Parsing & Initialization
        args = parse_command_line_arguments()
        if args.help or args.version or args.list_supported:
            display_information_and_exit(args)  # Exit code 0
        
        # B: Security & File Validation  
        validated_files = perform_security_and_file_validation(args)
        
        # C: Crypto Tool Selection & Configuration
        crypto_handlers = setup_crypto_tools_and_configuration(validated_files)
        
        # D: File Processing & Operations
        processing_results = process_files_with_crypto_operations(
            validated_files, crypto_handlers, args
        )
        
        # E: Cleanup & Results Reporting
        exit_code = cleanup_and_generate_final_report(processing_results)
        sys.exit(exit_code)
        
    except SecurityViolationError as e:
        log_sanitized_error(e)
        sys.exit(3)  # Security violation
    except FileFormatError as e:
        log_error(f"File format error: {e}")
        sys.exit(1)  # Format/access error
    except CryptoToolError as e:
        log_error(f"Crypto tool unavailable: {e}")
        sys.exit(1)  # Tool availability error
    except ProcessingError as e:
        cleanup_partial_processing_on_failure()
        sys.exit(1)  # Processing failure
    except Exception as e:
        log_error(f"Unexpected error: {e}")
        sys.exit(2)  # General error

# CONFIGURATION MANAGEMENT SYSTEM
class FastPassConfig:
    """Configuration management with multiple sources and precedence"""
    VERSION = "1.0.0"
    MAX_FILE_SIZE = 500 * 1024 * 1024  # 500MB
    TEMP_DIR_PREFIX = "fastpass_"
    SECURE_FILE_PERMISSIONS = 0o600
    SUPPORTED_FORMATS = {
        '.docx': 'msoffcrypto',
        '.xlsx': 'msoffcrypto', 
        '.pptx': 'msoffcrypto',
        '.docm': 'msoffcrypto',
        '.xlsm': 'msoffcrypto',
        '.pptm': 'msoffcrypto',
        '.dotx': 'msoffcrypto',
        '.xltx': 'msoffcrypto',
        '.potx': 'msoffcrypto',
        '.pdf': 'PyPDF2'
    }
    
    # Configuration file locations (in order of precedence)
    CONFIG_LOCATIONS = [
        Path.home() / '.fastpass' / 'config.json',  # User config
        Path.cwd() / 'fastpass.json',               # Project config
        Path(__file__).parent / 'config.json'      # Default config
    ]
    
    @classmethod
    def load_configuration(cls, cli_args: argparse.Namespace) -> Dict[str, Any]:
        """Load configuration from multiple sources with precedence"""
        config = cls._get_default_config()
        
        # 1. Load from config files (lowest precedence)
        for config_path in cls.CONFIG_LOCATIONS:
            if config_path.exists():
                try:
                    with open(config_path, 'r') as f:
                        file_config = json.load(f)
                        config.update(file_config)
                except (json.JSONDecodeError, IOError) as e:
                    print(f"Warning: Could not load config from {config_path}: {e}")
        
        # 2. Load from environment variables
        env_config = cls._load_from_environment()
        config.update(env_config)
        
        # 3. Override with CLI arguments (highest precedence)
        cli_config = cls._extract_cli_config(cli_args)
        config.update(cli_config)
        
        return config
    
    @classmethod
    def _get_default_config(cls) -> Dict[str, Any]:
        """Default configuration values"""
        return {
            'max_file_size': cls.MAX_FILE_SIZE,
            'temp_dir_prefix': cls.TEMP_DIR_PREFIX,
            'secure_permissions': cls.SECURE_FILE_PERMISSIONS,
            'supported_formats': cls.SUPPORTED_FORMATS.copy(),
            'log_level': 'INFO',
            'log_file': None,
            'cleanup_on_error': True,
            # Security hardening settings
            'allow_cwd': False,  # Default: do not allow current directory access
            'max_password_length': 1024,
            'max_json_size': 1024 * 1024,  # 1MB limit for password JSON
            'max_path_length': 4096,
            'enable_secure_deletion': True,
            'symlink_protection': True,
            'xml_entity_protection': True
        }
    
    @classmethod
    def _load_from_environment(cls) -> Dict[str, Any]:
        """Load configuration from environment variables"""
        import os
        config = {}
        
        # Environment variable mapping
        env_mapping = {
            'FASTPASS_MAX_FILE_SIZE': ('max_file_size', int),
            'FASTPASS_LOG_LEVEL': ('log_level', str),
            'FASTPASS_LOG_FILE': ('log_file', str),
            'FASTPASS_CLEANUP_ON_ERROR': ('cleanup_on_error', bool),
            # Security environment variables
            'FASTPASS_ALLOW_CWD': ('allow_cwd', bool),
            'FASTPASS_MAX_PASSWORD_LENGTH': ('max_password_length', int),
            'FASTPASS_MAX_JSON_SIZE': ('max_json_size', int),
            'FASTPASS_ENABLE_SECURE_DELETION': ('enable_secure_deletion', bool),
            'FASTPASS_SYMLINK_PROTECTION': ('symlink_protection', bool),
            'FASTPASS_XML_ENTITY_PROTECTION': ('xml_entity_protection', bool)
        }
        
        for env_var, (config_key, type_func) in env_mapping.items():
            if env_var in os.environ:
                try:
                    if type_func == bool:
                        config[config_key] = os.environ[env_var].lower() in ('true', '1', 'yes')
                    else:
                        config[config_key] = type_func(os.environ[env_var])
                except ValueError as e:
                    print(f"Warning: Invalid environment variable {env_var}: {e}")
        
        return config
    
    @classmethod
    def _extract_cli_config(cls, cli_args: argparse.Namespace) -> Dict[str, Any]:
        """Extract configuration from CLI arguments"""
        config = {}
        
        if hasattr(cli_args, 'debug') and cli_args.debug:
            config['log_level'] = 'DEBUG'
            
        if hasattr(cli_args, 'output_dir') and cli_args.output_dir:
            config['output_directory'] = cli_args.output_dir
        
        return config
    
# CUSTOM EXCEPTION CLASSES
class SecurityViolationError(Exception): pass
class FileFormatError(Exception): pass  
class CryptoToolError(Exception): pass
class ProcessingError(Exception): pass
```

---

## Section A: CLI Parsing & Initialization

> **CODE MAPPING CRITICAL**: Each element below corresponds to specific code blocks that must be labeled with the exact IDs shown (e.g., `# A1a: sys.argv processing`)

```python
# A1: COMMAND LINE ARGUMENT PARSING
def parse_command_line_arguments() -> argparse.Namespace:
    import sys
    import argparse
    from pathlib import Path
    from typing import List, Optional
    
    # A1a: Create argument parser with custom actions
    parser = argparse.ArgumentParser(
        prog='fast_pass',
        description='FastPass - Secure file encryption/decryption tool',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
Examples:
  fast_pass encrypt -i file.docx -p mypassword
  fast_pass decrypt -i file.pdf --password-list passwords.txt
  fast_pass encrypt -i "file1.xlsx" "file2.xlsx" -o ./encrypted/
        '''
    )
    
    # A1b: Operation mode (encrypt XOR decrypt)
    operation_group = parser.add_mutually_exclusive_group(required=True)
    operation_group.add_argument('-e', '--encrypt', action='store_true',
                                help='Encrypt files')
    operation_group.add_argument('-d', '--decrypt', action='store_true', 
                                help='Decrypt files')
    
    # A1c: File input options (explicit file specification required)
    parser.add_argument('-i', '--input', nargs='*', type=str, dest='files',
                       help='Files to process (space-delimited, quotes for spaces)')
    parser.add_argument('-r', '--recursive', type=Path, metavar='DIR',
                       help='Process directory recursively (decrypt/check-password only)')
    
    # A1d: Password options with space-delimited support
    parser.add_argument('-p', '--password', nargs='*', type=str, dest='cli_passwords',
                       help='Passwords to try (space-delimited, quotes for spaces, or "stdin" for JSON input)')
    parser.add_argument('--password-list', type=Path,
                       help='File containing passwords (one per line)')
    
    # A1e: Output options  
    parser.add_argument('-o', '--output-dir', type=Path,
                       help='Output directory (default: in-place)')
    
    # A1f: Utility options
    parser.add_argument('--dry-run', action='store_true',
                       help='Show what would be done without making changes')
    parser.add_argument('--verify', action='store_true',
                       help='Deep verification of processed files')
    parser.add_argument('--list-supported', action='store_true',
                       help='List supported file formats')
    parser.add_argument('--debug', action='store_true',
                       help='Enable detailed logging')
    parser.add_argument('--log-file', type=Path,
                       help='Write logs to specified file')
    parser.add_argument('--report-format', choices=['text', 'json', 'csv'],
                       default='text', help='Output report format')
    
    # A1g: Security options
    parser.add_argument('--allow-cwd', action='store_true',
                       help='Allow file operations in current working directory (security: use with caution)')
    parser.add_argument('-v', '--version', action='version',
                       version=f'FastPass {FastPassConfig.VERSION}')
    
    # A1h: Parse arguments with error handling
    try:
        args = parser.parse_args()
    except SystemExit as e:
        if e.code != 0:
            sys.exit(2)  # Invalid arguments
        raise
    
    # A1h: Handle special modes
    if args.list_supported:
        display_supported_formats()
        sys.exit(0)
    
    return args

# A2: ARGUMENT VALIDATION AND NORMALIZATION
def validate_operation_mode_and_arguments(args: argparse.Namespace) -> argparse.Namespace:
    from pathlib import Path
    
    # A2a: Ensure files or recursive specified
    if not args.files and not args.recursive:
        raise ValueError("Must specify files or --recursive directory")
    
    if args.files and args.recursive:
        raise ValueError("Cannot specify both files and --recursive")
    
    # A2a1: Restrict recursive mode to decrypt and check-password only
    if args.recursive and args.encrypt:
        raise ValueError("Recursive mode is only supported for decrypt operations (security restriction)")
    
    # A2b: Process explicit file paths and normalize (no glob pattern support)
    if args.files:
        # Convert to Path objects and resolve (explicit file specification only)
        args.files = [Path(f).expanduser().resolve() for f in args.files]
    
    if args.recursive:
        args.recursive = Path(args.recursive).expanduser().resolve()
        if not args.recursive.is_dir():
            raise ValueError(f"Recursive path is not a directory: {args.recursive}")
    
    # A2c: Validate output directory
    if args.output_dir:
        args.output_dir = Path(args.output_dir).expanduser().resolve()
        if args.output_dir.exists() and not args.output_dir.is_dir():
            raise ValueError(f"Output path exists but is not a directory: {args.output_dir}")
    
    # A2d: Set operation mode flag
    args.operation = 'encrypt' if args.encrypt else 'decrypt'
    
    return args

# A3: LOGGING SYSTEM INITIALIZATION
def setup_logging_and_debug_infrastructure(args: argparse.Namespace) -> logging.Logger:
    import logging
    import sys
    from datetime import datetime
    
    # A3a: Configure logging with TTY detection
    log_level = logging.DEBUG if args.debug else logging.INFO
    
    # A3a-1: Configure console logging
    console_handler = logging.StreamHandler(sys.stderr)
    
    # Check if stderr is a TTY for appropriate formatting
    if sys.stderr.isatty():
        console_format = '%(asctime)s - %(levelname)s - %(message)s'
    else:
        # Non-TTY output (e.g., redirected to file) - simpler format
        console_format = '%(levelname)s: %(message)s'
    
    console_handler.setFormatter(logging.Formatter(console_format))
    console_handler.setLevel(log_level)
    
    # A3a-2: Configure file logging if specified
    handlers = [console_handler]
    
    if hasattr(args, 'log_file') and args.log_file:
        try:
            # Ensure log directory exists
            args.log_file.parent.mkdir(parents=True, exist_ok=True)
            
            file_handler = logging.FileHandler(args.log_file, mode='a')
            file_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            file_handler.setFormatter(logging.Formatter(file_format))
            file_handler.setLevel(logging.DEBUG)  # Always debug level for files
            handlers.append(file_handler)
            
        except Exception as e:
            print(f"Warning: Could not set up file logging to {args.log_file}: {e}")
    
    # A3a-3: Configure root logger
    logger = logging.getLogger('fastpass')
    logger.setLevel(log_level)
    logger.handlers.clear()  # Remove any existing handlers
    
    for handler in handlers:
        logger.addHandler(handler)
    
    logger = logging.getLogger('fastpass')
    
    # A3b: Log startup
    logger.info(f"FastPass v{FastPassConfig.VERSION} starting - operation: {args.operation}")
    
    return logger

def handle_password_input_sources(args: argparse.Namespace) -> None:
    """A3c: Handle TTY detection and stdin password input"""
    import sys
    import json
    
    # Check if 'stdin' is specified in CLI passwords
    if args.cli_passwords and 'stdin' in args.cli_passwords:
        if sys.stdin.isatty():
            raise ValueError("Cannot read JSON from stdin: terminal input detected")
        
        try:
            # Read JSON password mapping from stdin
            stdin_data = sys.stdin.read()
            password_mapping = json.loads(stdin_data)
            
            # Remove 'stdin' from CLI passwords and store mapping
            args.cli_passwords.remove('stdin')
            args.stdin_password_mapping = password_mapping
            
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in stdin password input: {e}")
        except Exception as e:
            raise ValueError(f"Error reading password input from stdin: {e}")
    else:
        args.stdin_password_mapping = {}

# A4: CRYPTO TOOL AVAILABILITY DETECTION
def initialize_crypto_tool_detection() -> Dict[str, bool]:
    import subprocess
    import importlib
    
    crypto_tools = {}
    
    # A4a: Test msoffcrypto-tool availability
    try:
        result = subprocess.run(['python', '-m', 'msoffcrypto.cli', '--version'], 
                              capture_output=True, timeout=10)
        crypto_tools['msoffcrypto'] = result.returncode == 0
    except (subprocess.TimeoutExpired, FileNotFoundError):
        crypto_tools['msoffcrypto'] = False
    
    # A4b: Test PyPDF2 availability
    try:
        importlib.import_module('PyPDF2')
        crypto_tools['PyPDF2'] = True
    except ImportError:
        crypto_tools['PyPDF2'] = False
    
    # A4c: Check for missing required tools
    required_tools = []
    if not crypto_tools.get('msoffcrypto'):
        required_tools.append('msoffcrypto-tool')
    if not crypto_tools.get('PyPDF2'):
        required_tools.append('PyPDF2')
    
    if required_tools:
        raise CryptoToolError(f"Missing required tools: {', '.join(required_tools)}")
    
    return crypto_tools

# A5: FASTPASS APPLICATION CLASS
class FastPassApplication:
    def __init__(self, args: argparse.Namespace, logger: logging.Logger):
        # A5a: Initialize instance variables
        self.args = args
        self.logger = logger
        self.operation_mode = args.operation
        self.crypto_tools = initialize_crypto_tool_detection()
        
        # A5b: File tracking lists
        self.temp_files_created: List[Path] = []
        self.processing_results: Dict[Path, str] = {}
        self.operation_start_time = datetime.now()
        
        # A5c: Load configuration and initialize secure password manager
        self.config = FastPassConfig.load_configuration(args)
        self.password_manager = SecurePasswordManager()
        self.password_manager.load_password_sources(args)
        
        # A5d: Initialize secure temporary file manager
        self.temp_file_manager = SecureTempFileManager()
        
        # A5e: State flags
        self.ready_for_processing = True
        
        self.logger.debug("FastPass application initialized successfully")
```

**What's Actually Happening:**
- **A1: Command Line Argument Processing**
  - `sys.argv` processing with explicit file specification
  - Individual file paths specified directly: `fast_pass encrypt "file1.docx" "file2.pdf"`
  - Quoted paths for files with spaces: `fast_pass encrypt "my documents/file.txt"`
  - `args.operation` contains 'encrypt' or 'decrypt' as positional argument
  - `args.files` becomes list of explicitly specified file paths
  - `args.cli_passwords` contains space-delimited passwords from -p flag
  - `args.stdin_password_mapping` contains JSON password mapping if '-p stdin' used

- **A2: Operation Mode & File Path Validation**
  - Validate operation: `args.operation` must be 'encrypt' or 'decrypt'
  - Input validation: must have `args.files` or `args.recursive` (not both unless combining)
  - File existence check: `os.path.exists(file_path)` for each input file or directory
  - Path normalization: `os.path.abspath(os.path.expanduser(file_path))`
  - Per-file password pairing: associate each file with its -p password argument
  - Password source validation: ensure passwords available from CLI, list file, or stdin
  - Build file list: `self.input_files = [{'path': Path, 'password': str, 'source': str}]`
  - Special modes: `--check-password`, `--list-supported` bypass normal password requirements

- **A3: Logging System Configuration with TTY Detection**
  - `sys.stderr.isatty()` detection for appropriate log formatting
  - TTY output: Full timestamp format `'%(asctime)s - %(levelname)s - %(message)s'`
  - Non-TTY output: Simple format `'%(levelname)s: %(message)s'` for file redirection
  - `logging.basicConfig()` with `level=logging.DEBUG` if `args.debug` enabled
  - Handler: `sys.stderr` for console output, doesn't interfere with stdout
  - Password input validation: Check `sys.stdin.isatty()` when '-p stdin' specified
  - JSON password parsing: Parse stdin JSON for per-file password mapping
  - TTY safety: Prevent accidental password exposure in terminal input

- **A4: Crypto Library Availability Detection**
  - Test msoffcrypto-tool: `import msoffcrypto` with ImportError handling
  - Test PyPDF2: `import PyPDF2` with version compatibility check
  - Store availability: `self.crypto_tools = {'msoffcrypto': bool, 'pypdf2': bool}`
  - If required libraries missing: exit with helpful installation instructions

- **A5: Configuration & Default Setup**
  - `self.config = {'backup_suffix': '_backup_{timestamp}', 'temp_dir_prefix': 'FastPass_'}`
  - `self.config['secure_permissions'] = 0o600` (read/write owner only)
  - `self.config['max_file_size'] = 500 * 1024 * 1024` (500MB limit)
  - `self.config['supported_formats'] = {'.docx': 'msoffcrypto', '.pdf': 'pypdf2'}`
  - Password policy: `self.config['min_password_length'] = 1` (no minimum enforced)
  - Cleanup settings: `self.config['cleanup_on_error'] = True`

- **A6: FastPass Application Object Creation**
  - Main `FastPass(args)` object instantiated with parsed arguments
  - `self.operation_mode = args.operation` ('encrypt' or 'decrypt')
  - `self.password_manager = PasswordManager()`
  - `self.file_processors = {}` (will map files to appropriate crypto handlers)
  - `self.temp_files_created = []` (tracking for cleanup)
  - `self.operation_start_time = datetime.now()` for timing
  - State flags: `self.ready_for_processing = True`, `self.cleanup_required = False`

---

## Security Hardening & Attack Vector Mitigation

> **SECURITY CRITICAL**: This section addresses comprehensive security hardening based on threat analysis and attack vector identification. Every mitigation must be implemented exactly as specified to prevent exploitation.

### **Attack Vector Analysis & Mitigations**

#### **1. Path Traversal Attack Prevention**

**Attack Scenario**: Attacker uses paths like `../../../../etc/passwd` to access files outside allowed directories.

**Hardened Validation**:
```python
def validate_path_security_hardened(file_path: Path, explicit_allow_cwd: bool = False) -> None:
    """Enhanced path traversal protection with strict validation"""
    import os
    from pathlib import Path
    
    # B1-SEC-1: Canonical path resolution with symlink detection
    try:
        original_path = file_path
        resolved_path = file_path.resolve(strict=True)  # Fail if path doesn't exist
        
        # B1-SEC-2: Symlink detection and protection
        if resolved_path != original_path.resolve():
            if original_path.is_symlink() or any(p.is_symlink() for p in original_path.parents):
                raise SecurityViolationError("Symlink access denied for security")
        
        # B1-SEC-3: Restricted allowed directories (NO current directory by default)
        allowed_dirs = [Path.home().resolve()]
        
        # Only allow current directory if explicitly enabled
        if explicit_allow_cwd:
            allowed_dirs.append(Path.cwd().resolve())
        
        # B1-SEC-4: Strict containment checking
        is_allowed = False
        for base_dir in allowed_dirs:
            try:
                relative_path = resolved_path.relative_to(base_dir)
                # Additional check: no parent directory references in resolved path
                if '..' in str(relative_path):
                    raise SecurityViolationError("Path traversal in resolved path")
                is_allowed = True
                break
            except ValueError:
                continue
        
        if not is_allowed:
            raise SecurityViolationError("File access outside permitted directories")
            
        # B1-SEC-5: Path component analysis (enhanced)
        forbidden_components = ['..', '.', '', '~']
        for component in original_path.parts:
            if component in forbidden_components:
                raise SecurityViolationError(f"Forbidden path component: {component}")
            if component.startswith('.') and component not in ['.docx', '.xlsx', '.pptx', '.pdf']:
                raise SecurityViolationError("Hidden file/directory access denied")
            
        # B1-SEC-6: Path length and character validation
        if len(str(resolved_path)) > 4096:  # Reasonable path length limit
            raise SecurityViolationError("Path length exceeds security limit")
            
        # Check for null bytes and other dangerous characters
        dangerous_chars = ['\x00', '\n', '\r', '\t']
        if any(char in str(original_path) for char in dangerous_chars):
            raise SecurityViolationError("Dangerous characters in file path")
            
    except (OSError, FileNotFoundError) as e:
        raise SecurityViolationError(f"Invalid or inaccessible file path: {e}")
```

#### **2. Command Injection Prevention**

**Attack Scenario**: Malicious file paths with shell metacharacters like `; rm -rf /` injected into subprocess calls.

**Secure Implementation**:
```python
def encrypt_file_secure(self, input_path: Path, output_path: Path, password: str) -> None:
    """Secure Office encryption using direct library calls (no subprocess)"""
    
    # B2-SEC-1: Legacy format validation
    file_extension = input_path.suffix.lower()
    if file_extension in ['.doc', '.xls', '.ppt']:
        raise FileFormatError(f"Legacy Office format {file_extension} not supported")
    
    # B2-SEC-2: Path validation before processing
    validate_path_security_hardened(input_path)
    validate_path_security_hardened(output_path.parent)
    
    # B2-SEC-3: Password sanitization
    if len(password) > 1024:  # Reasonable password length limit
        raise ValueError("Password exceeds maximum length")
    if '\x00' in password:
        raise ValueError("Null byte in password")
    
    # B2-SEC-4: Use direct library calls instead of subprocess
    try:
        import msoffcrypto
        
        # Use msoffcrypto library directly for encryption (when available)
        # This eliminates subprocess command injection risks
        with open(input_path, 'rb') as input_file:
            # Note: Direct encryption may require different approach
            # Fall back to subprocess with strict argument validation only if necessary
            if self._direct_encryption_available():
                self._encrypt_direct(input_file, output_path, password)
            else:
                self._encrypt_subprocess_secure(input_path, output_path, password)
                
    except Exception as e:
        raise ProcessingError(f"Secure Office encryption failed: {e}")

def _encrypt_subprocess_secure(self, input_path: Path, output_path: Path, password: str) -> None:
    """Fallback secure subprocess implementation with strict validation"""
    
    # B2-SEC-5: Strict argument validation for subprocess
    import subprocess
    import shlex
    
    # Validate all paths are within allowed directories
    validate_path_security_hardened(input_path)
    validate_path_security_hardened(output_path.parent)
    
    # Use argument list (not shell) to prevent injection
    cmd_args = [
        'python', '-m', 'msoffcrypto.cli',
        '-e', '-p', password,
        str(input_path.resolve()),  # Use absolute paths
        str(output_path.resolve())
    ]
    
    # B2-SEC-6: Secure subprocess execution
    try:
        result = subprocess.run(
            cmd_args,
            capture_output=True,
            text=True,
            timeout=60,
            shell=False,  # CRITICAL: Never use shell=True
            cwd=None,     # Don't inherit current directory
            env={'PATH': os.environ.get('PATH', '')},  # Minimal environment
            check=False
        )
        
        if result.returncode != 0:
            # Sanitize error output to prevent information disclosure
            sanitized_error = self._sanitize_error_message(result.stderr)
            raise ProcessingError(f"Office encryption failed: {sanitized_error}")
            
    except subprocess.TimeoutExpired:
        raise ProcessingError("Office encryption timed out")
```

#### **3. Password Security & Memory Protection**

**Attack Scenarios**: Password exposure in process lists, memory dumps, swap files, or shell history.

**Secure Implementation**:
```python
class SecurePasswordManager:
    """Enhanced password manager with memory protection"""
    
    def __init__(self):
        self.cli_passwords = []
        self.password_list_file = None
        self.password_list = []
        self._memory_regions = []  # Track memory for secure clearing
        
    # B3-SEC-1: Secure password input without command line exposure
    def get_password_secure(self, prompt: str = "Password: ") -> str:
        """Get password without exposing in process list or history"""
        import getpass
        import sys
        
        if sys.stdin.isatty():
            # Interactive mode - use secure password prompt
            password = getpass.getpass(prompt)
        else:
            # Non-interactive mode - read from stdin (for automation)
            password = sys.stdin.readline().rstrip('\n\r')
        
        if not password:
            raise ValueError("Empty password not allowed")
            
        return password
    
    # B3-SEC-2: Secure memory clearing for passwords
    def clear_password_memory(self, password_str: str) -> None:
        """Attempt to clear password from memory (best effort)"""
        import ctypes
        
        try:
            # Get string object memory location
            address = id(password_str)
            size = len(password_str)
            
            # Overwrite memory with zeros (best effort in Python)
            ctypes.memset(address, 0, size)
            
        except Exception:
            # Memory clearing is best effort - don't fail operation
            pass
    
    # B3-SEC-3: Secure JSON password parsing with validation
    def parse_stdin_passwords_secure(self, stdin_data: str) -> Dict[str, str]:
        """Secure JSON password parsing with strict validation"""
        import json
        
        # Validate JSON size to prevent DoS
        if len(stdin_data) > 1024 * 1024:  # 1MB limit
            raise ValueError("Password JSON exceeds size limit")
        
        try:
            password_mapping = json.loads(stdin_data)
            
            if not isinstance(password_mapping, dict):
                raise ValueError("Password input must be JSON object")
            
            # Validate each entry
            validated_mapping = {}
            for filename, password in password_mapping.items():
                if not isinstance(filename, str) or not isinstance(password, str):
                    raise ValueError("Password mapping must contain only strings")
                
                # Validate filename for security
                file_path = Path(filename)
                validate_path_security_hardened(file_path)
                
                # Validate password
                if len(password) > 1024:
                    raise ValueError(f"Password for {filename} exceeds length limit")
                if '\x00' in password:
                    raise ValueError(f"Invalid characters in password for {filename}")
                
                validated_mapping[filename] = password
            
            return validated_mapping
            
        except json.JSONDecodeError as e:
            raise ValueError(f"Invalid JSON in password input: {e}")
        finally:
            # Clear input data from memory
            self.clear_password_memory(stdin_data)
```

#### **4. Secure Temporary File Operations**

**Attack Scenarios**: Race conditions, symlink attacks, predictable file names, insecure permissions.

**Secure Implementation**:
```python
class SecureTempFileManager:
    """Enhanced temporary file manager with security hardening"""
    
    def __init__(self):
        self.temp_directories = []
        self.temp_files = []
        self.cleanup_registered = False
        
    # B4-SEC-1: Secure temporary directory creation
    def create_secure_temp_directory(self) -> Path:
        """Create cryptographically secure temporary directory"""
        import tempfile
        import secrets
        import os
        from datetime import datetime
        
        # B4-SEC-2: Cryptographically secure random naming
        random_suffix = secrets.token_hex(16)  # 32 character hex string
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        pid = os.getpid()
        
        # Combine multiple entropy sources
        temp_name = f"fastpass_sec_{timestamp}_{pid}_{random_suffix}"
        
        # B4-SEC-3: Create with most restrictive permissions
        old_umask = os.umask(0o077)  # Ensure only owner can access
        try:
            temp_dir = Path(tempfile.mkdtemp(prefix=temp_name))
            
            # Set extremely restrictive permissions
            os.chmod(temp_dir, 0o700)  # Owner read/write/execute only
            
            # Create subdirectories with same restrictive permissions
            for subdir in ['processing', 'output']:
                subdir_path = temp_dir / subdir
                subdir_path.mkdir(mode=0o700)
                
            self.temp_directories.append(temp_dir)
            
            # Register cleanup if not already done
            if not self.cleanup_registered:
                import atexit
                atexit.register(self.emergency_cleanup)
                self.cleanup_registered = True
                
            return temp_dir
            
        finally:
            os.umask(old_umask)  # Restore original umask
    
    # B4-SEC-4: Secure atomic file operations
    def atomic_file_write(self, content: bytes, target_path: Path) -> None:
        """Secure atomic file write to prevent race conditions"""
        import secrets
        import os
        
        # Create temporary file in same directory as target (for atomic move)
        temp_name = f".tmp_{secrets.token_hex(8)}_{target_path.name}"
        temp_path = target_path.parent / temp_name
        
        try:
            # Write to temporary file with secure permissions
            with open(temp_path, 'wb') as f:
                os.chmod(temp_path, 0o600)  # Restrictive permissions before writing
                f.write(content)
                f.flush()
                os.fsync(f.fileno())  # Ensure data is written to disk
            
            # Atomic move to final location
            temp_path.replace(target_path)
            
        except Exception:
            # Clean up temporary file on failure
            if temp_path.exists():
                try:
                    temp_path.unlink()
                except Exception:
                    pass
            raise
    
    # B4-SEC-5: Secure file deletion with overwriting
    def secure_delete_file(self, file_path: Path) -> None:
        """Securely delete file with overwriting (best effort)"""
        import os
        
        try:
            if file_path.exists() and file_path.is_file():
                file_size = file_path.stat().st_size
                
                # Overwrite with random data (best effort)
                if file_size > 0 and file_size < 100 * 1024 * 1024:  # Only for files < 100MB
                    with open(file_path, 'r+b') as f:
                        # Multiple passes with different patterns
                        patterns = [b'\x00', b'\xFF', secrets.token_bytes(min(file_size, 1024))]
                        for pattern in patterns:
                            f.seek(0)
                            if len(pattern) == 1:
                                f.write(pattern * file_size)
                            else:
                                # Write random pattern
                                remaining = file_size
                                while remaining > 0:
                                    chunk_size = min(remaining, len(pattern))
                                    f.write(pattern[:chunk_size])
                                    remaining -= chunk_size
                            f.flush()
                            os.fsync(f.fileno())
                
                # Remove file
                file_path.unlink()
                
        except Exception:
            # Don't fail operation if secure deletion fails
            try:
                file_path.unlink()  # Fallback to normal deletion
            except Exception:
                pass
```

#### **5. File Format Attack Prevention**

**Attack Scenarios**: XXE injection, ZIP bombs, malicious macros, polyglot files.

**Secure Implementation**:
```python
def validate_file_format_secure(file_path: Path) -> str:
    """Enhanced file format validation with attack prevention"""
    import filetype
    import zipfile
    import xml.etree.ElementTree as ET
    
    # B5-SEC-1: File size validation (prevent DoS)
    file_size = file_path.stat().st_size
    if file_size > FastPassConfig.MAX_FILE_SIZE:
        raise FileFormatError(f"File too large: {file_size} bytes")
    if file_size == 0:
        raise FileFormatError("Empty file not allowed")
    
    # B5-SEC-2: Magic number validation (primary authority)
    detected_type = filetype.guess(str(file_path))
    file_extension = file_path.suffix.lower()
    
    # Allowed magic number mappings
    allowed_magic_types = {
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': '.xlsx',
        'application/vnd.openxmlformats-officedocument.presentationml.presentation': '.pptx',
        'application/pdf': '.pdf'
    }
    
    detected_format = None
    if detected_type and detected_type.mime in allowed_magic_types:
        detected_format = allowed_magic_types[detected_type.mime]
        
        # B5-SEC-3: Cross-validate magic number vs extension
        if file_extension != detected_format:
            raise FileFormatError(f"File format mismatch: extension {file_extension} vs detected {detected_format}")
    
    # B5-SEC-4: Extension-based validation (fallback)
    if not detected_format:
        if file_extension in FastPassConfig.SUPPORTED_FORMATS:
            detected_format = file_extension
        else:
            raise FileFormatError(f"Unsupported file format: {file_extension}")
    
    # B5-SEC-5: Office document security validation
    if detected_format in ['.docx', '.xlsx', '.pptx']:
        validate_office_document_security(file_path)
    
    # B5-SEC-6: PDF security validation  
    elif detected_format == '.pdf':
        validate_pdf_document_security(file_path)
    
    return detected_format

def validate_office_document_security(file_path: Path) -> None:
    """Validate Office document against security threats"""
    import zipfile
    import xml.etree.ElementTree as ET
    
    try:
        # B5-SEC-7: ZIP bomb protection
        with zipfile.ZipFile(file_path, 'r') as zip_file:
            total_uncompressed = 0
            file_count = 0
            
            for info in zip_file.infolist():
                file_count += 1
                total_uncompressed += info.file_size
                
                # Prevent ZIP bombs
                if file_count > 1000:  # Reasonable file count limit
                    raise FileFormatError("Office document contains too many files")
                
                if total_uncompressed > 100 * 1024 * 1024:  # 100MB uncompressed limit
                    raise FileFormatError("Office document uncompressed size too large")
                
                # Check compression ratio for ZIP bomb detection
                if info.file_size > 0 and info.compress_size > 0:
                    ratio = info.file_size / info.compress_size
                    if ratio > 100:  # High compression ratio indicates potential ZIP bomb
                        raise FileFormatError("Suspicious compression ratio in Office document")
            
            # B5-SEC-8: XML content validation (prevent XXE)
            xml_files = [name for name in zip_file.namelist() if name.endswith('.xml')]
            for xml_file in xml_files[:10]:  # Limit XML files checked
                try:
                    with zip_file.open(xml_file) as f:
                        xml_content = f.read(1024 * 1024)  # Limit XML size read
                        validate_xml_security(xml_content)
                except Exception:
                    # Don't fail on XML parsing errors, but log suspicion
                    continue
                    
    except zipfile.BadZipFile:
        raise FileFormatError("Corrupted Office document")

def validate_xml_security(xml_content: bytes) -> None:
    """Validate XML content for security threats"""
    
    # B5-SEC-9: XXE prevention - check for entity declarations
    xml_str = xml_content.decode('utf-8', errors='ignore')
    
    # Look for suspicious patterns
    suspicious_patterns = [
        '<!ENTITY',     # Entity declarations
        'SYSTEM',       # System entity references
        'file://',      # File protocol
        'http://',      # HTTP requests in XML
        'https://',     # HTTPS requests in XML
        '&lt;!ENTITY', # HTML-encoded entity declarations
    ]
    
    xml_lower = xml_str.lower()
    for pattern in suspicious_patterns:
        if pattern.lower() in xml_lower:
            raise FileFormatError("Potentially malicious XML content detected")
    
    # Additional size check
    if len(xml_content) > 10 * 1024 * 1024:  # 10MB XML limit
        raise FileFormatError("XML content too large")

def validate_pdf_document_security(file_path: Path) -> None:
    """Validate PDF document against security threats"""
    
    # B5-SEC-10: Basic PDF structure validation
    with open(file_path, 'rb') as f:
        header = f.read(1024)
        
        # Check PDF header
        if not header.startswith(b'%PDF-'):
            raise FileFormatError("Invalid PDF header")
        
        # Look for suspicious content
        suspicious_content = [
            b'/JavaScript',  # JavaScript in PDF
            b'/JS',         # JavaScript abbreviation
            b'/Launch',     # Launch actions
            b'/GoToR',      # Go to remote actions
        ]
        
        content_sample = f.read(10 * 1024)  # Read first 10KB for scanning
        for suspicious in suspicious_content:
            if suspicious in content_sample:
                raise FileFormatError("Potentially malicious PDF content detected")
```

---

## Section B: Security & File Validation

> **SECURITY CRITICAL**: Every security check must map to specific code with proper error handling and sanitization. Label each implementation block with the exact ID shown.

```python
# B1: FILE PATH RESOLUTION AND SECURITY VALIDATION
def perform_security_and_file_validation(args: argparse.Namespace) -> List[FileManifest]:
    import os
    import filetype
    from pathlib import Path
    from typing import List, Dict, Any
    
    validated_files: List[FileManifest] = []
    
    # B1a: Collect all files to process
    files_to_process = []
    if args.files:
        files_to_process = args.files
    elif args.recursive:
        files_to_process = collect_files_recursively(args.recursive)
    
    for file_path in files_to_process:
        # B1b: Path resolution and normalization
        resolved_path = Path(file_path).expanduser().resolve()
        
        # B1c: Security validation - hardened path traversal protection
        validate_path_security_hardened(resolved_path, explicit_allow_cwd=args.allow_cwd)
        
        # B1d: File existence and access validation
        validate_file_access(resolved_path)
        
        # B1e: File format validation with security hardening
        file_format = validate_file_format_secure(resolved_path)
        
        # B1f: Encryption status detection
        encryption_status = detect_encryption_status(resolved_path, file_format)
        
        # B1g: Build file manifest entry
        manifest_entry = FileManifest(
            path=resolved_path,
            format=file_format,
            size=resolved_path.stat().st_size,
            is_encrypted=encryption_status,
            crypto_tool=FastPassConfig.SUPPORTED_FORMATS[file_format.suffix]
        )
        
        validated_files.append(manifest_entry)
    
    if not validated_files:
        raise FileFormatError("No valid files found to process")
    
    return validated_files

def validate_path_security(file_path: Path) -> None:
    """B2: Path traversal and security validation"""
    import os
    from pathlib import Path
    
    # B2a: Resolve absolute path and check for dangerous patterns
    try:
        # Get the absolute path of the intended base directories
        user_home = Path.home().resolve()
        current_dir = Path.cwd().resolve()
        allowed_dirs = [user_home, current_dir]
        
        # Get the absolute path of the user-provided file path
        resolved_path = file_path.resolve()
        
        # B2b: Check if the resolved path is within allowed directories
        is_allowed = False
        for base_dir in allowed_dirs:
            try:
                # Check if the resolved path is within the base directory
                resolved_path.relative_to(base_dir)
                is_allowed = True
                break
            except ValueError:
                # Path is not relative to this base directory, try next
                continue
        
        if not is_allowed:
            raise SecurityViolationError("File access outside allowed directories")
            
        # B2c: Additional component analysis for dangerous patterns
        for component in file_path.parts:
            if component in ['..', '.', ''] or component.startswith('.'):
                raise SecurityViolationError("Path traversal attempt detected")
                
    except (OSError, ValueError) as e:
        raise SecurityViolationError("Invalid file path")

def validate_file_access(file_path: Path) -> None:
    """B3: File access and permission validation"""
    # B3a: Existence check
    if not file_path.exists():
        raise FileNotFoundError(f"File not found: {file_path}")
    
    # B3b: Read permission check
    if not os.access(file_path, os.R_OK):
        raise PermissionError(f"No read permission: {file_path}")
    
    # B3c: Size limit check
    file_size = file_path.stat().st_size
    if file_size > FastPassConfig.MAX_FILE_SIZE:
        raise FileFormatError(f"File too large: {file_size} bytes")
    
    # B3d: Write permission check for in-place operations
    parent_dir = file_path.parent
    if not os.access(parent_dir, os.W_OK):
        raise PermissionError(f"No write permission in directory: {parent_dir}")

def validate_file_format(file_path: Path) -> str:
    """B4: File format validation using magic number detection first"""
    import filetype
    
    # B4a: Primary validation - magic number detection
    detected_type = filetype.guess(str(file_path))
    file_extension = file_path.suffix.lower()
    
    # B4b: Magic number to format mapping (primary authority)
    magic_to_format = {
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': '.xlsx', 
        'application/vnd.openxmlformats-officedocument.presentationml.presentation': '.pptx',
        'application/pdf': '.pdf',
    }
    
    if detected_type and detected_type.mime in magic_to_format:
        # Magic number detected - use this as authoritative format
        authoritative_format = magic_to_format[detected_type.mime]
        
        # B4c: Cross-validate with file extension
        if file_extension != authoritative_format:
            # Log warning but trust magic number over extension
            print(f"Warning: Extension mismatch for {file_path.name}: {file_extension} vs detected {authoritative_format}")
        
        # Check if detected format is supported
        if authoritative_format not in FastPassConfig.SUPPORTED_FORMATS:
            raise FileFormatError(f"Detected file format not supported: {authoritative_format}")
            
        return authoritative_format
    
    # B4d: Fallback to extension-based validation
    if file_extension in FastPassConfig.SUPPORTED_FORMATS:
        print(f"Warning: Could not detect magic number for {file_path.name}, trusting extension: {file_extension}")
        return file_extension
    
    # B4e: Neither magic number nor extension indicate supported format
    raise FileFormatError(f"Unsupported or undetectable file format: {file_extension}")

def detect_encryption_status(file_path: Path, file_format: str) -> bool:
    """B5: Detect if file is password protected"""
    if file_format in ['.docx', '.xlsx', '.pptx']:
        # B5a: Office document encryption detection
        import msoffcrypto
        with open(file_path, 'rb') as f:
            office_file = msoffcrypto.OfficeFile(f)
            return office_file.is_encrypted()
    
    elif file_format == '.pdf':
        # B5b: PDF encryption detection
        import PyPDF2
        with open(file_path, 'rb') as f:
            pdf_reader = PyPDF2.PdfReader(f)
            return pdf_reader.is_encrypted
    
    return False

@dataclass
class FileManifest:
    """File manifest entry for processing pipeline"""
    path: Path
    format: str
    size: int
    is_encrypted: bool
    crypto_tool: str
```

**What's Actually Happening:**
- **B1: File Path Processing & Normalization**
  - Input processing: `args.files` list or `args.recursive` directory path
  - Path expansion: `os.path.expanduser('~/Documents/file.docx')` â†’ `/home/user/Documents/file.docx`
  - Canonical paths: `pathlib.Path.resolve()` resolves symlinks and relative paths
  - File existence: `os.path.exists(file_path)` for each target file
  - Build file list: `validated_files = [Path objects with metadata]`
  - Missing files tracked: `missing_files = []` for error reporting
  - If any files missing: exit with detailed error message listing all missing files

- **B2: Path Traversal Security Analysis**
  - Absolute path resolution: `file_path.resolve()` to get canonical path with symlinks resolved
  - Base directory validation: Check if resolved path is within `Path.home().resolve()` or `Path.cwd().resolve()`
  - Containment checking: Use `resolved_path.relative_to(base_dir)` to verify path is within allowed boundaries
  - Component analysis: Reject paths containing `..`, `.`, hidden files, or empty components
  - System paths: Automatic rejection of paths outside user home and current working directory
  - Error handling: Convert OSError/ValueError to SecurityViolationError with sanitized messages
  - Critical exit: if security violations detected, `sys.exit(3)` with generic "security violation" message

- **B3: File Format Magic Number Validation (Primary Authority)**
  - **Priority 1**: Magic number detection via `filetype.guess(file_path)` - authoritative format detection
  - **Priority 2**: File extension validation as fallback when magic number undetectable
  - Magic number mapping (trusted authority):
    ```python
    magic_to_format = {
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document': '.docx',
        'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': '.xlsx',
        'application/vnd.openxmlformats-officedocument.presentationml.presentation': '.pptx',
        'application/pdf': '.pdf',
        'application/zip': '.zip'
    }
    ```
  - Cross-validation: When magic number and extension disagree, trust magic number but log warning
  - Fallback strategy: If magic number undetectable, validate extension against supported formats
  - Format violations: Unsupported formats (by either method) trigger `FileFormatError`

- **B4: File Access & Permission Verification**
  - Read access test: `open(file_path, 'rb')` with exception handling
  - Sample read: read first 1024 bytes to verify file accessibility and detect corruption
  - Size validation: `os.path.getsize(file_path)` vs `max_file_size = 500MB` limit
  - Empty file check: `file_size == 0` indicates potential corruption or invalid file
  - Output directory access: if `--output-dir` specified, test write access to target directory
  - Permission violations: collected in `access_violations = []`
  - If access violations: `sys.exit(1)` with detailed permission error messages

- **B5: Password Protection Status Detection**
  - **Office Documents**: `msoffcrypto.OfficeFile(file_stream).is_encrypted()` returns boolean
  - **PDF Files**: `PyPDF2.PdfReader(file_stream).is_encrypted` property check
  - Store status: `password_status = {'file_path': bool}` for each file
  - **Special case**: If operation is 'encrypt' and file already encrypted, add to warnings
  - **Special case**: If operation is 'decrypt' and file not encrypted, add to warnings

- **B6: Validated File Manifest Creation**  
  - Build manifest: `file_manifest = []` containing complete file metadata
  - Manifest entry structure:
    ```python
    manifest_entry = {
        'path': Path,
        'extension': str,
        'format': str, 
        'size': int,
        'is_password_protected': bool,
        'crypto_tool': str,  # 'msoffcrypto', 'pypdf2'
        'temp_file_needed': bool
    }
    ```
  - Tool assignment: map file extension to appropriate crypto tool
  - Summary calculation: `total_files = len(file_manifest)`, `protected_files = count(is_password_protected)`
  - If critical errors: `sys.exit(3)` with validation summary
  - Success state: `validation_complete = True`, ready for crypto tool setup

---

## Section C: Crypto Tool Selection & Configuration

> **TOOL INTEGRATION CRITICAL**: Each crypto tool handler must be implemented exactly as diagrammed. Label each handler class and method with corresponding IDs.

```python
# C1: CRYPTO TOOL HANDLER SETUP
def setup_crypto_tools_and_configuration(validated_files: List[FileManifest]) -> Dict[str, Any]:
    """Initialize and configure crypto tool handlers based on file types"""
    
    # C1a: Determine required tools
    required_tools = set(manifest.crypto_tool for manifest in validated_files)
    
    crypto_handlers = {}
    
    # C1b: Initialize Office document handler
    if 'msoffcrypto' in required_tools:
        crypto_handlers['msoffcrypto'] = OfficeDocumentHandler()
    
    # C1c: Initialize PDF handler  
    if 'PyPDF2' in required_tools:
        crypto_handlers['PyPDF2'] = PDFHandler()
    
    return crypto_handlers

class OfficeDocumentHandler:
    """Handler for Office document encryption/decryption using msoffcrypto"""
    
    def __init__(self):
        import msoffcrypto
        self.msoffcrypto = msoffcrypto
        
    def encrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """C2a: Secure Office document encryption with hardened security"""
        # Use the secure implementation that includes all security validations
        encrypt_file_secure(self, input_path, output_path, password)
    
    def decrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """C2b: Decrypt Office document"""
        with open(input_path, 'rb') as input_file:
            office_file = self.msoffcrypto.OfficeFile(input_file)
            office_file.load_key(password=password)
            
            with open(output_path, 'wb') as output_file:
                office_file.save(output_file)
    
    def test_password(self, file_path: Path, password: str) -> bool:
        """C2c: Test if password works for Office document"""
        try:
            with open(file_path, 'rb') as f:
                office_file = self.msoffcrypto.OfficeFile(f)
                office_file.load_key(password=password)
                return True
        except Exception:
            return False

class PDFHandler:
    """Handler for PDF encryption/decryption using PyPDF2"""
    
    def __init__(self):
        import PyPDF2
        self.PyPDF2 = PyPDF2
        
    def encrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """C3a: Encrypt PDF document"""
        with open(input_path, 'rb') as input_file:
            pdf_reader = self.PyPDF2.PdfReader(input_file)
            pdf_writer = self.PyPDF2.PdfWriter()
            
            # Copy all pages
            for page in pdf_reader.pages:
                pdf_writer.add_page(page)
            
            # Encrypt with password
            pdf_writer.encrypt(password)
            
            with open(output_path, 'wb') as output_file:
                pdf_writer.write(output_file)
    
    def decrypt_file(self, input_path: Path, output_path: Path, password: str) -> None:
        """C3b: Decrypt PDF document"""
        with open(input_path, 'rb') as input_file:
            pdf_reader = self.PyPDF2.PdfReader(input_file)
            
            if pdf_reader.is_encrypted:
                pdf_reader.decrypt(password)
            
            pdf_writer = self.PyPDF2.PdfWriter()
            
            # Copy all pages
            for page in pdf_reader.pages:
                pdf_writer.add_page(page)
            
            with open(output_path, 'wb') as output_file:
                pdf_writer.write(output_file)
    
    def test_password(self, file_path: Path, password: str) -> bool:
        """C3c: Test if password works for PDF"""
        try:
            with open(file_path, 'rb') as f:
                pdf_reader = self.PyPDF2.PdfReader(f)
                if pdf_reader.is_encrypted:
                    return pdf_reader.decrypt(password) == 1
                return True
        except Exception:
            return False

# C4: PASSWORD MANAGEMENT SYSTEM
class PasswordManager:
    """Manages password priority system and validation"""
    
    def __init__(self, cli_passwords: List[str], password_list_file: Optional[Path]):
        self.cli_passwords = cli_passwords or []
        self.password_list_file = password_list_file
        self.password_list: List[str] = []
        
        # C4a: Load password list from file
        if password_list_file:
            self.load_password_list()
    
    def load_password_list(self) -> None:
        """C4b: Load passwords from file"""
        try:
            with open(self.password_list_file, 'r', encoding='utf-8') as f:
                self.password_list = [line.strip() for line in f if line.strip()]
        except FileNotFoundError:
            raise FileNotFoundError(f"Password list file not found: {self.password_list_file}")
    
    def get_password_candidates(self, file_path: Path) -> List[str]:
        """C4c: Get password candidates in priority order"""
        candidates = []
        
        # Priority 1: CLI passwords
        candidates.extend(self.cli_passwords)
        
        # Priority 2: Password list file
        candidates.extend(self.password_list)
        
        # Remove duplicates while preserving order
        seen = set()
        unique_candidates = []
        for pwd in candidates:
            if pwd not in seen:
                seen.add(pwd)
                unique_candidates.append(pwd)
        
        return unique_candidates
    
    def find_working_password(self, file_path: Path, crypto_handler: Any) -> Optional[str]:
        """C4d: Find working password for file"""
        candidates = self.get_password_candidates(file_path)
        
        for password in candidates:
            if crypto_handler.test_password(file_path, password):
                return password
        
        return None
```

**What's Actually Happening:**
- **C1: File Format Analysis & Tool Mapping**
  - Process validated file manifest: `for file_entry in self.file_manifest:`
  - Extension-to-tool mapping:
    ```python
    tool_mapping = {
        '.docx': 'msoffcrypto', '.xlsx': 'msoffcrypto', '.pptx': 'msoffcrypto',
        '.doc': 'msoffcrypto', '.xls': 'msoffcrypto', '.ppt': 'msoffcrypto',  
        '.pdf': 'PyPDF2'
    }
    ```
  - Assign crypto tool: `file_entry['crypto_tool'] = tool_mapping[file_entry['extension']]`
  - Group by tool: `self.tool_groups = {'msoffcrypto': [], 'PyPDF2': []}`
  - Availability check: ensure required tools are available for file types present
  - If tool missing: `sys.exit(1)` with "Required crypto tool not available: {tool_name}"

- **C2: Crypto Tool Handler Initialization**
  - **msoffcrypto Handler**:
    ```python
    class OfficeHandler:
        def __init__(self):
            self.tool_path = 'python -m msoffcrypto.cli'
            self.temp_files = []
        
        def encrypt(self, input_path, output_path, password):
            # Implementation using msoffcrypto
        
        def decrypt(self, input_path, output_path, password):
            # Implementation using msoffcrypto
    ```
  - **PyPDF2 Handler**:
    ```python
    class PDFHandler:
        def __init__(self):
            self.pdf_library = 'PyPDF2'
        
        def encrypt(self, input_path, output_path, password):
            # Implementation using PyPDF2 library
    ```

- **C4: msoffcrypto-tool Configuration**
  - Test tool availability: `subprocess.run(['python', '-m', 'msoffcrypto.cli', '--version'])`
  - Configure encryption options:
    ```python
    office_config = {
        'password_method': 'standard',  # Use standard Office encryption
        'temp_dir': self.temp_working_dir,
        'preserve_metadata': True
    }
    ```
  - Set handler methods: `self.office_handler.set_config(office_config)`
  - Store in pipeline: `self.crypto_handlers['msoffcrypto'] = office_handler`

- **C5: PyPDF2 Configuration** 
  - Initialize PDF library:
    ```python
    import PyPDF2
    self.pdf_library = 'PyPDF2'
    # Verify version compatibility for encryption features
    if hasattr(PyPDF2, 'PdfWriter'):  # Check for newer API
        self.writer_class = PyPDF2.PdfWriter
    else:
        self.writer_class = PyPDF2.PdfFileWriter  # Legacy API
    ```
  - Configure PDF encryption settings:
    ```python
    pdf_config = {
        'encryption_algorithm': 'AES-256',
        'permissions': {'print': True, 'modify': False, 'copy': True},
        'user_password': None,  # Will be set per operation
        'owner_password': None  # Same as user password by default
    }
    ```


- **C7: Tool-Specific Option Configuration**
  - **Office Documents**: Set metadata preservation, compatible encryption methods
  - **PDF Files**: Configure user/owner passwords, permission settings
  - Password validation: ensure passwords meet tool-specific requirements
  - Error handling: configure timeout values, retry attempts for each tool
  - Logging: set up per-tool debug logging if enabled

- **C8: Processing Pipeline Creation**
  - Build processing queue: `self.processing_queue = []`
  - For each file, create processing task:
    ```python
    task = {
        'file_path': Path,
        'operation': 'encrypt' | 'decrypt',
        'crypto_handler': handler_object,
        'password': str,
        'output_path': Path,
        'temp_files': []
    }
    ```
  - Sort by file size: process smaller files first for faster feedback
  - Dependency resolution: if files depend on each other, order appropriately
  - Pipeline validation: ensure all tasks have required inputs and handlers
  - Ready state: `self.pipeline_ready = True`, `self.total_tasks = len(processing_queue)`

---

## Section D: File Processing & Operations

> **PROCESSING CRITICAL**: Each step must handle errors gracefully with proper cleanup. Map every processing step to exact code implementation.

```python
# D1: SECURE TEMPORARY DIRECTORY SETUP
def create_secure_temporary_directory() -> Path:
    """Create secure temporary working directory with proper permissions"""
    import tempfile
    import os
    from datetime import datetime
    
    # D1a: Generate unique temp directory name
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    pid = os.getpid()
    temp_name = f"{FastPassConfig.TEMP_DIR_PREFIX}{timestamp}_{pid}"
    
    # D1b: Create temp directory with secure permissions
    temp_dir = Path(tempfile.mkdtemp(prefix=temp_name))
    os.chmod(temp_dir, 0o700)  # Owner read/write/execute only
    
    # D1c: Create subdirectories
    (temp_dir / 'processing').mkdir()
    (temp_dir / 'output').mkdir()
    
    return temp_dir

# D1d: ENHANCED TEMPORARY FILE MANAGEMENT WITH CLEANUP TRACKING
class TempFileManager:
    """Centralized temporary file management with guaranteed cleanup"""
    
    def __init__(self):
        self.temp_directories = []
        self.temp_files = []
        self.cleanup_registered = False
    
    def create_temp_directory(self) -> Path:
        """Create tracked temporary directory with automatic cleanup registration"""
        temp_dir = create_secure_temporary_directory()
        self.temp_directories.append(temp_dir)
        
        if not self.cleanup_registered:
            import atexit
            atexit.register(self.emergency_cleanup)
            self.cleanup_registered = True
            
        return temp_dir
    
    def emergency_cleanup(self):
        """Emergency cleanup for atexit registration"""
        for temp_dir in self.temp_directories:
            try:
                cleanup_temporary_directory(temp_dir)
            except Exception:
                pass  # Silent emergency cleanup

# D1e: CONTEXT MANAGER FOR SECURE TEMPORARY DIRECTORIES
class SecureTempDirectory:
    """Context manager ensuring automatic cleanup even on exceptions"""
    
    def __init__(self):
        self.temp_dir = None
    
    def __enter__(self) -> Path:
        self.temp_dir = create_secure_temporary_directory()
        return self.temp_dir
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.temp_dir:
            cleanup_temporary_directory(self.temp_dir)

# D2: FILE PROCESSING PIPELINE
def process_files_with_crypto_operations(
    validated_files: List[FileManifest], 
    crypto_handlers: Dict[str, Any],
    args: argparse.Namespace
) -> ProcessingResults:
    """Main file processing pipeline with crypto operations"""
    
    # D2a: Create secure temporary directory
    temp_dir = create_secure_temporary_directory()
    
    try:
        processing_results = ProcessingResults()
        
        for file_manifest in validated_files:
            try:
                # D2b: Process individual file
                result = process_single_file(
                    file_manifest, 
                    crypto_handlers[file_manifest.crypto_tool],
                    temp_dir,
                    args
                )
                processing_results.successful_files.append(result)
                
            except Exception as e:
                error_info = FileProcessingError(
                    file_path=file_manifest.path,
                    error_message=str(e),
                    error_type=type(e).__name__
                )
                # Sanitize error message before storing
                error_info.error_message = sanitize_error_message(error_info.error_message)
                processing_results.failed_files.append(error_info)
                
                # Clean up any partial processing for this file
                cleanup_failed_file_processing(file_manifest.path)
        
        return processing_results
        
    finally:
        # D2c: Guaranteed cleanup with error isolation
        try:
            cleanup_temporary_directory(temp_dir)
        except Exception as cleanup_error:
            # Log cleanup failure but don't mask processing results
            print(f"Warning: Cleanup failed for {temp_dir}: {cleanup_error}")

def process_single_file(
    file_manifest: FileManifest,
    crypto_handler: Any,
    temp_dir: Path,
    args: argparse.Namespace
) -> FileProcessingResult:
    """D3: Process a single file through crypto operations"""
    
    # D3a: Find working password
    password = crypto_handler.password_manager.find_working_password(
        file_manifest.path, crypto_handler
    )
    
    if not password:
        raise ProcessingError(f"No working password found for {file_manifest.path}")
    
    # D3b: Setup temporary file paths
    temp_input = temp_dir / 'processing' / f"input_{file_manifest.path.name}"
    temp_output = temp_dir / 'output' / f"output_{file_manifest.path.name}"
    
    # D3c: Copy input to temp location
    shutil.copy2(file_manifest.path, temp_input)
    
    # D3d: Perform crypto operation
    if args.operation == 'encrypt':
        crypto_handler.encrypt_file(temp_input, temp_output, password)
    else:  # decrypt
        crypto_handler.decrypt_file(temp_input, temp_output, password)
    
    # D3e: Validate output file
    validate_processed_file(temp_output, args.operation, crypto_handler)
    
    # D3f: Atomic move to final destination with error handling
    final_path = determine_output_path(file_manifest.path, args.output_dir)
    
    try:
        # Ensure target directory exists
        final_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Atomic move to final destination
        shutil.move(temp_output, final_path)
    except Exception as e:
        # Clean up temp output file if move fails
        if temp_output.exists():
            temp_output.unlink()
        raise ProcessingError(f"Failed to move processed file to destination: {e}")
    
    return FileProcessingResult(
        original_path=file_manifest.path,
        final_path=final_path,
        operation=args.operation,
        password_used=password,
        file_size_before=file_manifest.size,
        file_size_after=final_path.stat().st_size
    )

def validate_processed_file(output_path: Path, operation: str, crypto_handler: Any) -> None:
    """D4: Validate that processed file is correct"""
    
    # D4a: Check file exists and has reasonable size
    if not output_path.exists():
        raise ProcessingError("Output file was not created")
    
    if output_path.stat().st_size == 0:
        raise ProcessingError("Output file is empty")
    
    # D4b: Format-specific validation
    file_format = output_path.suffix.lower()
    
    if file_format in ['.docx', '.xlsx', '.pptx']:
        validate_office_document(output_path, operation)
    elif file_format == '.pdf':
        validate_pdf_document(output_path, operation)

def validate_office_document(file_path: Path, operation: str) -> None:
    """D4c: Validate Office document integrity"""
    import msoffcrypto
    
    try:
        with open(file_path, 'rb') as f:
            office_file = msoffcrypto.OfficeFile(f)
            
            if operation == 'encrypt':
                # After encryption, file should be encrypted
                if not office_file.is_encrypted():
                    raise ProcessingError("File was not properly encrypted")
            else:  # decrypt
                # After decryption, file should not be encrypted
                if office_file.is_encrypted():
                    raise ProcessingError("File was not properly decrypted")
    except Exception as e:
        raise ProcessingError(f"Office document validation failed: {e}")

def validate_pdf_document(file_path: Path, operation: str) -> None:
    """D4d: Validate PDF document integrity"""
    import PyPDF2
    
    try:
        with open(file_path, 'rb') as f:
            pdf_reader = PyPDF2.PdfReader(f)
            
            if operation == 'encrypt':
                # After encryption, PDF should be encrypted
                if not pdf_reader.is_encrypted:
                    raise ProcessingError("PDF was not properly encrypted")
            else:  # decrypt
                # After decryption, PDF should not be encrypted
                if pdf_reader.is_encrypted:
                    raise ProcessingError("PDF was not properly decrypted")
                    
            # Test that we can read at least one page
            if len(pdf_reader.pages) == 0:
                raise ProcessingError("PDF has no readable pages")
                
    except Exception as e:
        raise ProcessingError(f"PDF validation failed: {e}")

@dataclass
class ProcessingResults:
    successful_files: List[FileProcessingResult] = field(default_factory=list)
    failed_files: List[FileProcessingError] = field(default_factory=list)

@dataclass  
class FileProcessingResult:
    original_path: Path
    final_path: Path
    operation: str
    password_used: str
    file_size_before: int
    file_size_after: int

@dataclass
class FileProcessingError:
    file_path: Path
    error_message: str
    error_type: str

def cleanup_failed_file_processing(file_path: Path) -> None:
    """Clean up processing artifacts for a failed file"""
    import tempfile
    import shutil
    
    try:
        # Remove any temporary files associated with this file
        temp_patterns = [
            f"*{file_path.stem}*",
            f"temp_{file_path.name}*",
            f"processing_{file_path.name}*"
        ]
        
        # Clean up from common temp locations
        temp_dirs = [Path.cwd() / 'temp', Path('/tmp'), Path(tempfile.gettempdir())]
        
        for temp_dir in temp_dirs:
            if temp_dir.exists():
                for pattern in temp_patterns:
                    for temp_file in temp_dir.glob(pattern):
                        try:
                            if temp_file.is_file():
                                temp_file.unlink()
                            elif temp_file.is_dir():
                                shutil.rmtree(temp_file)
                        except Exception:
                            # Continue cleanup even if some files can't be removed
                            pass
                            
    except Exception:
        # Don't let cleanup errors propagate
        pass
```

**What's Actually Happening:**
- **D1: Secure Temporary Directory Setup**
  - Generate unique temp directory: `temp_name = f'FastPass_{datetime.now():%Y%m%d_%H%M%S}_{os.getpid()}'`
  - Create with secure permissions: `tempfile.mkdtemp(prefix=temp_name)` then `os.chmod(temp_dir, 0o700)`
  - Directory structure: `temp_dir/processing/` for input files, `temp_dir/output/` for processed files
  - Cleanup tracking: `self.temp_directories_created = [temp_dir]` for later cleanup

- **D2: Processing Pipeline Execution**
  - Queue processing: `for task in self.processing_queue:`
  - File isolation: copy each file to `temp_dir/processing/` before processing
  - Tool routing: select appropriate crypto handler based on file format
  - Password application: use `password_manager.find_working_password()` for each file
  - Operation dispatch: call `handler.encrypt()` or `handler.decrypt()` based on mode
  - Output validation: verify processed file integrity and correct encryption status
  - Error handling: collect failures in `failed_files = []`, continue processing remaining files

- **D3: Individual File Processing**
  - **Input preparation**: Copy file to temp location with `shutil.copy2(original, temp_input)`
  - **Password validation**: Test password with crypto tool before processing
  - **Processing execution**: 
    - For Office files: use msoffcrypto library via subprocess or direct API
    - For PDF files: use PyPDF2 with PdfReader/PdfWriter classes
  - **Output verification**: Confirm processed file has correct encryption status
  - **File movement**: Move from temp location to final destination (in-place or output directory)

- **D4: File Integrity Validation**
  - **Existence check**: Verify output file was created and is non-empty
  - **Format validation**: Ensure file still opens correctly with appropriate tool
  - **Encryption status**: Verify encrypt/decrypt operation achieved expected result:
    - After encryption: file should be password-protected
    - After decryption: file should not require password
  - **Content integrity**: For PDFs, verify at least one page readable; for Office docs, verify document structure intact
  - **Size sanity check**: File size should be reasonable (not 0 bytes, not dramatically different unless expected)

- **D5: Enhanced Temporary File Management**
  - **Cleanup tracking**: `TempFileManager` class tracks all temporary files and directories
  - **Emergency cleanup**: `atexit.register()` ensures cleanup even on unexpected termination
  - **Context managers**: `SecureTempDirectory` provides automatic cleanup with `try`/`finally`
  - **Retry logic**: Multiple cleanup attempts with exponential backoff for permission issues
  - **Secure deletion**: Overwrite sensitive temporary files with zeros before deletion
  - **Error isolation**: Cleanup failures don't mask original processing errors

- **D6: Error Handling & Recovery**
  - **Per-file errors**: Collect in `processing_errors = []` with details, continue processing other files
  - **Critical errors**: Stop processing, restore all backups, cleanup temp files
  - **Password errors**: Distinguish between wrong password vs crypto tool failure
  - **File corruption**: Detect if input file becomes corrupted during processing
  - **Partial success**: Some files succeed, some fail - report both with detailed status

---

## Section E: Cleanup & Results Reporting

> **CLEANUP CRITICAL**: All temporary files, passwords in memory, and system state must be properly cleaned up. Map every cleanup operation to code.

```python
# E1: RESULTS SUMMARIZATION AND CLEANUP
def cleanup_and_generate_final_report(processing_results: ProcessingResults) -> int:
    """Generate final report and determine exit code"""
    
    # E1a: Calculate summary statistics
    total_files = len(processing_results.successful_files) + len(processing_results.failed_files)
    successful_count = len(processing_results.successful_files)
    failed_count = len(processing_results.failed_files)
    
    # E1b: Generate report
    generate_operation_report(processing_results, total_files, successful_count, failed_count)
    
    # E1c: Clear sensitive data from memory
    clear_sensitive_data()
    
    # E1d: Determine exit code
    if failed_count == 0 and successful_count > 0:
        return 0  # Success
    elif failed_count > 0 and successful_count > 0:
        return 1  # Partial success
    elif failed_count > 0 and successful_count == 0:
        return 1  # Complete failure
    else:
        return 2  # No files processed

def generate_operation_report(
    processing_results: ProcessingResults,
    total_files: int,
    successful_count: int, 
    failed_count: int,
    report_format: str = 'text'
) -> None:
    """E2: Generate comprehensive operation report in specified format"""
    
    if report_format == 'json':
        generate_json_report(processing_results, total_files, successful_count, failed_count)
    elif report_format == 'csv':
        generate_csv_report(processing_results, total_files, successful_count, failed_count)
    else:  # text format (default)
        generate_text_report(processing_results, total_files, successful_count, failed_count)

def generate_text_report(
    processing_results: ProcessingResults,
    total_files: int,
    successful_count: int,
    failed_count: int
) -> None:
    """Generate human-readable text report"""
    
    print("\n" + "="*50)
    print("FastPass Operation Complete")
    print("="*50)
    
    # E2a: Summary statistics
    print(f"Total files processed: {total_files}")
    print(f"Successful: {successful_count}")
    print(f"Failed: {failed_count}")
    
    # E2b: List successful files
    if processing_results.successful_files:
        print(f"\nâœ“ Successful files:")
        for result in processing_results.successful_files:
            size_change = result.file_size_after - result.file_size_before
            size_indicator = f"({size_change:+d} bytes)" if size_change != 0 else ""
            print(f"  â€¢ {result.original_path.name} â†’ {result.final_path.name} {size_indicator}")
    
    # E2c: List failed files
    if processing_results.failed_files:
        print(f"\nâœ— Failed files:")
        for error in processing_results.failed_files:
            print(f"  â€¢ {error.file_path.name}: {error.error_message}")
    
    # E2d: Next steps
    if failed_count > 0:
        print(f"\nTroubleshooting:")
        print("- Verify passwords are correct")
        print("- Check file permissions")
        print("- Ensure files are not corrupted")

def generate_json_report(
    processing_results: ProcessingResults,
    total_files: int,
    successful_count: int,
    failed_count: int
) -> None:
    """Generate machine-readable JSON report"""
    import json
    from datetime import datetime
    
    report = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total_files": total_files,
            "successful": successful_count,
            "failed": failed_count,
            "success_rate": successful_count / total_files if total_files > 0 else 0
        },
        "successful_files": [
            {
                "original_path": str(result.original_path),
                "final_path": str(result.final_path),
                "operation": result.operation,
                "file_size_before": result.file_size_before,
                "file_size_after": result.file_size_after,
                "size_change": result.file_size_after - result.file_size_before
            }
            for result in processing_results.successful_files
        ],
        "failed_files": [
            {
                "file_path": str(error.file_path),
                "error_message": error.error_message,
                "error_type": error.error_type
            }
            for error in processing_results.failed_files
        ]
    }
    
    print(json.dumps(report, indent=2))

def generate_csv_report(
    processing_results: ProcessingResults,
    total_files: int,
    successful_count: int,
    failed_count: int
) -> None:
    """Generate CSV format report"""
    import csv
    import sys
    
    writer = csv.writer(sys.stdout)
    
    # Write header
    writer.writerow(['file_path', 'status', 'operation', 'size_before', 'size_after', 'error_message'])
    
    # Write successful files
    for result in processing_results.successful_files:
        writer.writerow([
            str(result.original_path),
            'success',
            result.operation,
            result.file_size_before,
            result.file_size_after,
            ''
        ])
    
    # Write failed files
    for error in processing_results.failed_files:
        writer.writerow([
            str(error.file_path),
            'failed',
            '',
            '',
            '',
            error.error_message
        ])

def clear_sensitive_data() -> None:
    """E3: Clear passwords and sensitive data from memory"""
    import gc
    
    # E3a: This would be implemented to overwrite password variables
    # In practice, Python doesn't provide direct memory overwriting
    # but we can delete variables and force garbage collection
    
    # Clear any global password variables
    globals_to_clear = [k for k in globals().keys() if 'password' in k.lower()]
    for var_name in globals_to_clear:
        if var_name in globals():
            del globals()[var_name]
    
    # Force garbage collection
    gc.collect()

def cleanup_temporary_directory(temp_dir: Path) -> None:
    """E4: Secure cleanup with retry logic and secure file deletion"""
    import shutil
    import time
    import os
    
    if not temp_dir.exists():
        return
    
    # E4a: Multiple cleanup attempts with exponential backoff
    max_attempts = 3
    for attempt in range(max_attempts):
        try:
            # E4b: Secure deletion of sensitive files (attempt to overwrite)
            for file_path in temp_dir.rglob('*'):
                if file_path.is_file():
                    try:
                        file_size = file_path.stat().st_size
                        # Only attempt secure deletion for reasonably sized files
                        if 0 < file_size < 10 * 1024 * 1024:  # < 10MB
                            with open(file_path, 'r+b') as f:
                                f.write(b'\x00' * file_size)
                                f.flush()
                                os.fsync(f.fileno())
                    except Exception:
                        # Secure deletion failed, continue with normal deletion
                        pass
            
            # E4c: Remove entire directory tree
            shutil.rmtree(temp_dir)
            return  # Success - exit retry loop
            
        except (PermissionError, OSError) as e:
            if attempt < max_attempts - 1:
                # Exponential backoff for retry
                time.sleep(0.1 * (2 ** attempt))
                continue
            else:
                print(f"Warning: Could not clean up temp directory {temp_dir}: {e}")
                break
```

**What's Actually Happening:**
- **E1: Operation Summary & Statistics Calculation**
  - Count files: `total_files = len(self.processing_results)`
  - Success rate: `successful_files = len([r for r in results if r.status == 'success'])`
  - Failure breakdown: categorize failures by type (password, permission, corruption, tool failure)
  - Processing time: `total_time = datetime.now() - self.operation_start_time`
  - Performance stats: files per second, total bytes processed, average file size

- **E2: Comprehensive Results Report Generation**
  - **Header section**: FastPass version, operation mode, timestamp
  - **Summary statistics**: Total files, success count, failure count, processing time
  - **Successful files list**: 
    ```
    âœ“ Successful files:
      â€¢ document1.docx â†’ document1.docx (encrypted, +1,247 bytes)
      â€¢ report.pdf â†’ secured/report.pdf (decrypted, -892 bytes)
      â€¢ data.xlsx â†’ data.xlsx (encrypted, +2,156 bytes)
    ```
  - **Failed files list**: 
    ```
    âœ— Failed files:
      â€¢ protected.pdf: Wrong password
      â€¢ corrupt.docx: File format error
      â€¢ readonly.xlsx: Permission denied
    ```
  - **Troubleshooting section**: If failures occurred, provide specific guidance based on failure types

- **E3: Sensitive Data Memory Cleanup**
  - **Password variables**: Explicitly delete all password variables from memory
  - **Command line args**: Clear args.passwords, args.password_list contents  
  - **Processing state**: Clear password_manager internal state
  - **Garbage collection**: Force `gc.collect()` to ensure memory cleanup
  - **Note**: Python doesn't guarantee memory overwriting, but this is best effort cleanup

- **E4: Temporary File & Directory Cleanup**
  - **Temp directory removal**: `shutil.rmtree(temp_dir)` for each temp directory created
  - **Intermediate files**: Clean up any partial processing files left behind
  - **Lock files**: Remove any file locks or temp markers created during processing
  - **Error handling**: Log warnings for cleanup failures but don't fail the operation

- **E5: Final Exit Code Determination**
  - **Exit Code 0**: All files processed successfully, no errors
  - **Exit Code 1**: Some files failed, some succeeded (partial success)
  - **Exit Code 2**: All files failed to process, or no files processed
  - **Exit Code 3**: Security violation detected, operation aborted
  - **Exit Code 4**: Authentication failure (wrong passwords for all files)

- **E6: Operation State Reset**
  - Clear processing queues: `self.processing_queue = []`
  - Reset file manifests: `self.file_manifest = []`
  - Clear handler references: `self.crypto_handlers = {}`
  - Reset application state: `self.ready_for_processing = False`
  - Final log entry: `logger.info(f"FastPass operation completed in {total_time} with {successful_count}/{total_files} files successful")`

---

## Security Implementation Summary

### **Comprehensive Security Hardening Implemented**

FastPass includes enterprise-grade security hardening based on comprehensive threat analysis and attack vector identification. All security measures are mandatory and must be implemented exactly as specified.

#### **Security Mitigations by Attack Vector**

| **Attack Vector** | **Mitigation Implemented** | **Security Function** |
|-------------------|---------------------------|----------------------|
| **Path Traversal** | Hardened path validation with symlink detection | `validate_path_security_hardened()` |
| **Command Injection** | Direct library calls + secure subprocess | `encrypt_file_secure()` |
| **Password Exposure** | Memory clearing + secure input handling | `SecurePasswordManager` |
| **Race Conditions** | Atomic operations + secure temp files | `SecureTempFileManager` |
| **XXE Injection** | XML entity detection + content validation | `validate_xml_security()` |
| **ZIP Bombs** | Compression ratio analysis + size limits | `validate_office_document_security()` |
| **Malicious PDFs** | JavaScript detection + content scanning | `validate_pdf_document_security()` |
| **Symlink Attacks** | Symlink detection + strict path resolution | `validate_path_security_hardened()` |
| **DoS Attacks** | Input size limits + resource constraints | Multiple validation functions |
| **File Format Confusion** | Magic number validation + strict matching | `validate_file_format_secure()` |

#### **Security Configuration Options**

```python
# CLI Security Flags
--allow-cwd           # Explicitly enable current directory access (default: disabled)

# Environment Variables
FASTPASS_ALLOW_CWD=false              # Default: restrict to home directory only
FASTPASS_MAX_PASSWORD_LENGTH=1024     # Password length limit
FASTPASS_MAX_JSON_SIZE=1048576        # 1MB JSON input limit
FASTPASS_ENABLE_SECURE_DELETION=true  # Overwrite files before deletion
FASTPASS_SYMLINK_PROTECTION=true      # Block symlink access
FASTPASS_XML_ENTITY_PROTECTION=true   # XXE protection enabled
```

#### **Security-First Design Principles**

1. **Principle of Least Privilege**: By default, only allow access to user home directory
2. **Defense in Depth**: Multiple layers of validation and sanitization
3. **Fail Secure**: Security violations result in immediate termination
4. **Input Validation**: All user inputs validated against strict criteria
5. **Secure by Default**: Most restrictive settings enabled by default
6. **Memory Protection**: Best-effort password clearing and secure handling
7. **Atomic Operations**: Prevent race conditions and partial state corruption
8. **Content Validation**: Deep inspection of file contents for malicious patterns

#### **Critical Security Requirements**

**MANDATORY IMPLEMENTATION**: The following security measures are not optional and must be implemented exactly as specified:

- âœ… **Path Traversal Protection**: `validate_path_security_hardened()` with symlink detection
- âœ… **Command Injection Prevention**: Direct library calls or secure subprocess with argument validation
- âœ… **Password Memory Protection**: `SecurePasswordManager` with memory clearing
- âœ… **Secure Temporary Files**: Cryptographically secure naming and restrictive permissions (0o600)
- âœ… **File Format Validation**: Magic number + extension cross-validation with attack detection
- âœ… **Input Sanitization**: All user inputs validated for length, content, and dangerous patterns
- âœ… **Error Sanitization**: No sensitive information disclosed in error messages
- âœ… **Resource Limits**: File size, path length, and processing time constraints

#### **Security Testing Requirements**

Each security measure must be tested with specific attack scenarios:

```python
# Security Test Cases (Required)
test_path_traversal_attacks()          # ../../../../etc/passwd
test_symlink_attacks()                 # Symlink to sensitive files  
test_command_injection()               # ; rm -rf / in file paths
test_password_exposure()               # Process list monitoring
test_xxe_injection()                   # XML external entity attacks
test_zip_bomb_detection()              # Compression ratio attacks
test_malicious_pdf_content()           # JavaScript/launch actions
test_race_condition_prevention()       # Concurrent file operations
test_dos_via_large_inputs()            # Oversized files and inputs
test_file_format_confusion()           # Polyglot and mismatched formats
```

#### **Security Audit Checklist**

Before deployment, verify each security control:

- [ ] Path validation blocks `../../../etc/passwd` access attempts
- [ ] Symlink access denied with clear error message  
- [ ] Subprocess calls use argument arrays, never shell execution
- [ ] Passwords not visible in `ps aux` output during processing
- [ ] JSON password input validated for size and content
- [ ] Temporary files created with 0o600 permissions
- [ ] File format mismatches rejected (e.g., .pdf with .docx magic number)
- [ ] ZIP bomb detection triggers on high compression ratios
- [ ] PDF JavaScript content blocked
- [ ] XXE entity declarations in Office documents blocked
- [ ] Memory clearing attempted for password variables
- [ ] Error messages sanitized of sensitive information

---

## Implementation Status & Next Steps

### Current Development Phase
- **Phase**: Architecture specification complete
- **Status**: Ready for implementation
- **Next Priority**: Begin implementation of Section A (CLI Parsing & Initialization)

### Implementation Order
1. **Section A**: CLI parsing and basic application structure
2. **Section B**: Security validation and file format detection  
3. **Section C**: Crypto tool integration and handler classes
4. **Section D**: File processing pipeline with error handling
5. **Section E**: Cleanup, reporting, and finalization

### Key Implementation Notes
- Each code section must be labeled with exact IDs from this specification (e.g., `# A1a`, `# B3c`)
- All error handling must follow the patterns defined in the pseudocode
- Security validations are mandatory and cannot be simplified or skipped
- Password handling must implement the complete priority system as specified
- File processing must use the secure temporary directory approach

### Comprehensive Testing Strategy

#### Unit Testing Framework
- **Framework**: pytest with coverage reporting (pytest-cov)
- **Test Structure**: Mirror source code structure in tests/ directory
- **Coverage Target**: Minimum 85% code coverage for all modules
- **Mocking**: Use unittest.mock for external dependencies and file system operations

#### Test Categories

**1. Security Testing (Critical Priority)**
```python
# tests/test_security.py
class TestPathTraversalSecurity:
    def test_reject_parent_directory_traversal(self):
        """Test rejection of '../' path traversal attempts"""
    
    def test_reject_absolute_paths_outside_allowed(self):
        """Test rejection of paths outside user home/current directory"""
    
    def test_symlink_resolution_security(self):
        """Test proper handling of symbolic links"""
    
    def test_windows_path_traversal_patterns(self):
        """Test Windows-specific path traversal patterns"""
    
    def test_url_encoded_path_injection(self):
        """Test rejection of URL-encoded traversal attempts"""

class TestPasswordSecurity:
    def test_password_memory_clearing(self):
        """Test password variables are cleared from memory"""
    
    def test_password_not_logged(self):
        """Test passwords never appear in log outputs"""
    
    def test_error_message_sanitization(self):
        """Test sensitive data removed from error messages"""

class TestFileFormatSecurity:
    def test_magic_number_validation(self):
        """Test file format detection via magic numbers"""
    
    def test_malicious_file_rejection(self):
        """Test rejection of files with mismatched extensions"""
    
    def test_large_file_rejection(self):
        """Test rejection of files exceeding size limits"""
```

**2. Crypto Handler Testing**
```python
# tests/test_crypto_handlers.py
class TestOfficeDocumentHandler:
    def test_encrypt_docx_file(self):
        """Test DOCX encryption with valid password"""
    
    def test_decrypt_protected_xlsx(self):
        """Test XLSX decryption with correct password"""
    
    def test_wrong_password_handling(self):
        """Test graceful handling of incorrect passwords"""
    
    def test_corrupted_file_detection(self):
        """Test detection and handling of corrupted Office files"""

class TestPDFHandler:
    def test_pdf_encryption_standard(self):
        """Test PDF encryption with standard security"""
    
    def test_pdf_decryption_validation(self):
        """Test PDF decryption and integrity validation"""
    
    def test_pdf_permission_handling(self):
        """Test handling of PDF permission restrictions"""
```

**3. Integration Testing**
```python
# tests/test_integration.py
class TestEndToEndWorkflows:
    def test_full_encryption_workflow(self):
        """Test complete file encryption from CLI to output"""
    
    def test_batch_processing_mixed_formats(self):
        """Test processing multiple file types in single operation"""
    
    def test_recursive_directory_processing(self):
        """Test recursive directory processing with filters"""
    
    def test_error_recovery_and_cleanup(self):
        """Test system recovery from processing errors"""

class TestPasswordManagement:
    def test_password_priority_system(self):
        """Test CLI > list file priority order"""
    
    
    def test_stdin_json_password_input(self):
        """Test JSON password input via stdin"""
```

**4. Error Handling Testing**
```python
# tests/test_error_handling.py
class TestErrorScenarios:
    def test_missing_file_handling(self):
        """Test graceful handling of missing input files"""
    
    def test_permission_denied_scenarios(self):
        """Test handling of read/write permission failures"""
    
    def test_disk_space_exhaustion(self):
        """Test behavior when disk space runs out during processing"""
    
    def test_crypto_tool_unavailable(self):
        """Test fallback when required crypto tools missing"""
    
    def test_partial_processing_cleanup(self):
        """Test cleanup of partially processed files on failure"""
```

**5. Performance Testing**
```python
# tests/test_performance.py
class TestPerformanceBenchmarks:
    def test_large_file_processing_time(self):
        """Test processing time for files up to size limit"""
    
    def test_batch_processing_scalability(self):
        """Test performance with increasing number of files"""
    
    def test_memory_usage_monitoring(self):
        """Test memory usage stays within reasonable bounds"""
```

#### Test Data Management
- **Test Fixtures**: Create representative Office/PDF files for testing
- **Encrypted Samples**: Pre-encrypted files with known passwords
- **Malicious Samples**: Files designed to test security vulnerabilities
- **Large Files**: Test files of various sizes up to the limit
- **Corrupted Files**: Intentionally corrupted files for error testing

#### Continuous Integration
- **GitHub Actions**: Run tests on multiple Python versions (3.8+)
- **Platform Testing**: Test on Windows, macOS, and Linux
- **Security Scanning**: Integrate SAST tools (bandit, safety)
- **Coverage Reporting**: Automated coverage reports and enforcement

#### Manual Testing Checklist
- **User Acceptance Testing**: Manual testing of CLI workflows
- **Cross-Platform Testing**: Verify behavior across operating systems
- **Edge Cases**: Manual testing of unusual file combinations
- **Documentation Validation**: Ensure examples in docs actually work

#### Test Execution Commands
```bash
# Run all tests with coverage
pytest tests/ --cov=src --cov-report=html --cov-report=term

# Run only security tests
pytest tests/test_security.py -v

# Run performance benchmarks
pytest tests/test_performance.py --benchmark-only

# Run integration tests
pytest tests/test_integration.py -v
```

### Implementation Quality Gates

**Phase 1 - Security Foundation (Must Pass)**
- All security tests pass (path traversal, file validation, password handling)
- Error message sanitization verified
- Temporary file cleanup confirmed

**Phase 2 - Core Functionality (Must Pass)**  
- All crypto handler tests pass
- File processing pipeline tests pass
- Configuration management tests pass

**Phase 3 - Integration & Performance (Must Pass)**
- End-to-end workflow tests pass
- Performance benchmarks meet targets
- Error recovery tests pass

**Phase 4 - Production Readiness (Must Pass)**
- 85%+ code coverage achieved
- All manual test scenarios pass
- Documentation examples verified

---

This specification serves as the complete blueprint for FastPass implementation. All code must conform to this architecture, implement the exact pseudocode patterns shown above, and pass the comprehensive testing strategy before deployment.
</file>

</files>
